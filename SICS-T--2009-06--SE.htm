<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:m="http://schemas.microsoft.com/office/2004/12/omml"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=gb2312">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 15">
<meta name=Originator content="Microsoft Word 15">
<link rel=File-List href="SICS-T--2009-06--SE.files/filelist.xml">
<link rel=Edit-Time-Data href="SICS-T--2009-06--SE.files/editdata.mso">
<!--[if !mso]>
<style>
v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style>
<![endif]-->
<title>A literature survey of active machine learning in the context of natural
language processing</title>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Fredrik Olsson</o:Author>
  <o:Keywords>active learning, natural language processing, machine learning, language engineering</o:Keywords>
  <o:LastAuthor>Zhu Peng</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>3</o:TotalTime>
  <o:Created>2018-11-05T08:56:00Z</o:Created>
  <o:LastSaved>2018-11-05T08:56:00Z</o:LastSaved>
  <o:Pages>10</o:Pages>
  <o:Words>17761</o:Words>
  <o:Characters>101238</o:Characters>
  <o:Lines>843</o:Lines>
  <o:Paragraphs>237</o:Paragraphs>
  <o:CharactersWithSpaces>118762</o:CharactersWithSpaces>
  <o:Version>16.00</o:Version>
 </o:DocumentProperties>
</xml><![endif]-->
<link rel=themeData href="SICS-T--2009-06--SE.files/themedata.thmx">
<link rel=colorSchemeMapping
href="SICS-T--2009-06--SE.files/colorschememapping.xml">
<!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:TrackMoves>false</w:TrackMoves>
  <w:TrackFormatting/>
  <w:PunctuationKerning/>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:DoNotPromoteQF/>
  <w:LidThemeOther>EN-US</w:LidThemeOther>
  <w:LidThemeAsian>ZH-CN</w:LidThemeAsian>
  <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
   <w:DontGrowAutofit/>
   <w:SplitPgBreakAndParaMark/>
   <w:EnableOpenTypeKerning/>
   <w:DontFlipMirrorIndents/>
   <w:OverrideTableStyleHps/>
   <w:UseFELayout/>
  </w:Compatibility>
  <w:DoNotOptimizeForBrowser/>
  <m:mathPr>
   <m:mathFont m:val="Cambria Math"/>
   <m:brkBin m:val="before"/>
   <m:brkBinSub m:val="&#45;-"/>
   <m:smallFrac m:val="off"/>
   <m:dispDef/>
   <m:lMargin m:val="0"/>
   <m:rMargin m:val="0"/>
   <m:defJc m:val="centerGroup"/>
   <m:wrapIndent m:val="1440"/>
   <m:intLim m:val="subSup"/>
   <m:naryLim m:val="undOvr"/>
  </m:mathPr></w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" DefUnhideWhenUsed="false"
  DefSemiHidden="false" DefQFormat="false" DefPriority="99"
  LatentStyleCount="375">
  <w:LsdException Locked="false" Priority="0" QFormat="true" Name="Normal"/>
  <w:LsdException Locked="false" Priority="9" QFormat="true" Name="heading 1"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 2"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 3"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 4"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 5"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 6"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 7"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 8"/>
  <w:LsdException Locked="false" Priority="9" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="heading 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index 9"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 1"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 2"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 3"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 4"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 5"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 6"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 7"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 8"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" Name="toc 9"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="header"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footer"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="index heading"/>
  <w:LsdException Locked="false" Priority="35" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="caption"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of figures"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="envelope return"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="footnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="line number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="page number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote reference"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="endnote text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="table of authorities"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="macro"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="toa heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Bullet 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Number 5"/>
  <w:LsdException Locked="false" Priority="10" QFormat="true" Name="Title"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Closing"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Signature"/>
  <w:LsdException Locked="false" Priority="1" SemiHidden="true"
   UnhideWhenUsed="true" Name="Default Paragraph Font"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="List Continue 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Message Header"/>
  <w:LsdException Locked="false" Priority="11" QFormat="true" Name="Subtitle"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Salutation"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Date"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text First Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Note Heading"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Body Text Indent 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Block Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="FollowedHyperlink"/>
  <w:LsdException Locked="false" Priority="22" QFormat="true" Name="Strong"/>
  <w:LsdException Locked="false" Priority="20" QFormat="true" Name="Emphasis"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Document Map"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Plain Text"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="E-mail Signature"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Top of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Bottom of Form"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal (Web)"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Acronym"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Address"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Cite"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Code"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Definition"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Keyboard"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Preformatted"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Sample"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Typewriter"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="HTML Variable"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Normal Table"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="annotation subject"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="No List"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Outline List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Simple 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Classic 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Colorful 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Columns 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Grid 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 4"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 5"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 7"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table List 8"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table 3D effects 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Contemporary"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Elegant"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Professional"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Subtle 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 1"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 2"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Web 3"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Balloon Text"/>
  <w:LsdException Locked="false" Priority="39" Name="Table Grid"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Table Theme"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Placeholder Text"/>
  <w:LsdException Locked="false" Priority="1" QFormat="true" Name="No Spacing"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 1"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 1"/>
  <w:LsdException Locked="false" SemiHidden="true" Name="Revision"/>
  <w:LsdException Locked="false" Priority="34" QFormat="true"
   Name="List Paragraph"/>
  <w:LsdException Locked="false" Priority="29" QFormat="true" Name="Quote"/>
  <w:LsdException Locked="false" Priority="30" QFormat="true"
   Name="Intense Quote"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 1"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 1"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 1"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 1"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 1"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 2"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 2"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 2"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 2"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 2"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 2"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 3"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 3"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 3"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 3"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 3"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 3"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 4"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 4"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 4"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 4"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 4"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 4"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 5"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 5"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 5"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 5"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 5"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 5"/>
  <w:LsdException Locked="false" Priority="60" Name="Light Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="61" Name="Light List Accent 6"/>
  <w:LsdException Locked="false" Priority="62" Name="Light Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="63" Name="Medium Shading 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="64" Name="Medium Shading 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="65" Name="Medium List 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="66" Name="Medium List 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="67" Name="Medium Grid 1 Accent 6"/>
  <w:LsdException Locked="false" Priority="68" Name="Medium Grid 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="69" Name="Medium Grid 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="70" Name="Dark List Accent 6"/>
  <w:LsdException Locked="false" Priority="71" Name="Colorful Shading Accent 6"/>
  <w:LsdException Locked="false" Priority="72" Name="Colorful List Accent 6"/>
  <w:LsdException Locked="false" Priority="73" Name="Colorful Grid Accent 6"/>
  <w:LsdException Locked="false" Priority="19" QFormat="true"
   Name="Subtle Emphasis"/>
  <w:LsdException Locked="false" Priority="21" QFormat="true"
   Name="Intense Emphasis"/>
  <w:LsdException Locked="false" Priority="31" QFormat="true"
   Name="Subtle Reference"/>
  <w:LsdException Locked="false" Priority="32" QFormat="true"
   Name="Intense Reference"/>
  <w:LsdException Locked="false" Priority="33" QFormat="true" Name="Book Title"/>
  <w:LsdException Locked="false" Priority="37" SemiHidden="true"
   UnhideWhenUsed="true" Name="Bibliography"/>
  <w:LsdException Locked="false" Priority="39" SemiHidden="true"
   UnhideWhenUsed="true" QFormat="true" Name="TOC Heading"/>
  <w:LsdException Locked="false" Priority="41" Name="Plain Table 1"/>
  <w:LsdException Locked="false" Priority="42" Name="Plain Table 2"/>
  <w:LsdException Locked="false" Priority="43" Name="Plain Table 3"/>
  <w:LsdException Locked="false" Priority="44" Name="Plain Table 4"/>
  <w:LsdException Locked="false" Priority="45" Name="Plain Table 5"/>
  <w:LsdException Locked="false" Priority="40" Name="Grid Table Light"/>
  <w:LsdException Locked="false" Priority="46" Name="Grid Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="Grid Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="Grid Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="Grid Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="Grid Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="Grid Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="Grid Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="Grid Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="Grid Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="Grid Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="46" Name="List Table 1 Light"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark"/>
  <w:LsdException Locked="false" Priority="51" Name="List Table 6 Colorful"/>
  <w:LsdException Locked="false" Priority="52" Name="List Table 7 Colorful"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 1"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 1"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 1"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 1"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 1"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 1"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 2"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 2"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 2"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 2"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 2"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 2"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 3"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 3"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 3"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 3"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 3"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 3"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 4"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 4"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 4"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 4"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 4"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 4"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 5"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 5"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 5"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 5"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 5"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 5"/>
  <w:LsdException Locked="false" Priority="46"
   Name="List Table 1 Light Accent 6"/>
  <w:LsdException Locked="false" Priority="47" Name="List Table 2 Accent 6"/>
  <w:LsdException Locked="false" Priority="48" Name="List Table 3 Accent 6"/>
  <w:LsdException Locked="false" Priority="49" Name="List Table 4 Accent 6"/>
  <w:LsdException Locked="false" Priority="50" Name="List Table 5 Dark Accent 6"/>
  <w:LsdException Locked="false" Priority="51"
   Name="List Table 6 Colorful Accent 6"/>
  <w:LsdException Locked="false" Priority="52"
   Name="List Table 7 Colorful Accent 6"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Mention"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Smart Hyperlink"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Hashtag"/>
  <w:LsdException Locked="false" SemiHidden="true" UnhideWhenUsed="true"
   Name="Unresolved Mention"/>
 </w:LatentStyles>
</xml><![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536869121 1107305727 33554432 0 415 0;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:-536859905 -1073732485 9 0 511 0;}
@font-face
	{font-family:Cambria;
	panose-1:2 4 5 3 5 4 6 3 2 4;
	mso-font-charset:0;
	mso-generic-font-family:roman;
	mso-font-pitch:variable;
	mso-font-signature:-536869121 1107305727 33554432 0 415 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:.25pt;
	margin-left:.5pt;
	text-align:justify;
	text-justify:inter-ideograph;
	text-indent:-.5pt;
	line-height:110%;
	mso-pagination:widow-orphan;
	font-size:11.0pt;
	font-family:"Cambria",serif;
	mso-fareast-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	mso-font-kerning:1.0pt;}
h1
	{mso-style-priority:9;
	mso-style-unhide:no;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-style-link:"标题 1 字符";
	mso-style-next:正文;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:22.45pt;
	margin-left:.5pt;
	text-indent:-.5pt;
	line-height:106%;
	mso-pagination:widow-orphan lines-together;
	page-break-after:avoid;
	mso-outline-level:1;
	font-size:25.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Cambria",serif;
	mso-fareast-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	mso-font-kerning:1.0pt;
	mso-bidi-font-weight:normal;}
h2
	{mso-style-priority:9;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-style-link:"标题 2 字符";
	mso-style-next:正文;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:8.95pt;
	margin-left:.5pt;
	text-indent:-.5pt;
	line-height:107%;
	mso-pagination:widow-orphan lines-together;
	page-break-after:avoid;
	mso-outline-level:2;
	font-size:14.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Cambria",serif;
	mso-fareast-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	mso-font-kerning:1.0pt;
	mso-bidi-font-weight:normal;}
h3
	{mso-style-priority:9;
	mso-style-qformat:yes;
	mso-style-parent:"";
	mso-style-link:"标题 3 字符";
	mso-style-next:正文;
	margin-top:0cm;
	margin-right:0cm;
	margin-bottom:6.65pt;
	margin-left:.5pt;
	text-indent:-.5pt;
	line-height:107%;
	mso-pagination:widow-orphan lines-together;
	page-break-after:avoid;
	mso-outline-level:3;
	font-size:12.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Cambria",serif;
	mso-fareast-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	mso-font-kerning:1.0pt;
	mso-bidi-font-weight:normal;}
span.3
	{mso-style-name:"标题 3 字符";
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-parent:"";
	mso-style-link:"标题 3";
	mso-ansi-font-size:12.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
span.2
	{mso-style-name:"标题 2 字符";
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-parent:"";
	mso-style-link:"标题 2";
	mso-ansi-font-size:14.5pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
span.1
	{mso-style-name:"标题 1 字符";
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-parent:"";
	mso-style-link:"标题 1";
	mso-ansi-font-size:25.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	font-weight:bold;
	mso-bidi-font-weight:normal;}
p.footnotedescription, li.footnotedescription, div.footnotedescription
	{mso-style-name:"footnote description";
	mso-style-unhide:no;
	mso-style-parent:"";
	mso-style-link:"footnote description Char";
	mso-style-next:正文;
	margin:0cm;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	text-indent:12.45pt;
	line-height:107%;
	mso-pagination:widow-orphan;
	font-size:9.0pt;
	mso-bidi-font-size:11.0pt;
	font-family:"Cambria",serif;
	mso-fareast-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	mso-font-kerning:1.0pt;}
span.footnotedescriptionChar
	{mso-style-name:"footnote description Char";
	mso-style-unhide:no;
	mso-style-locked:yes;
	mso-style-parent:"";
	mso-style-link:"footnote description";
	mso-ansi-font-size:9.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;}
span.footnotemark
	{mso-style-name:"footnote mark";
	mso-style-unhide:no;
	mso-style-parent:"";
	mso-ansi-font-size:9.0pt;
	font-family:"Cambria",serif;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	vertical-align:super;}
.MsoChpDefault
	{mso-style-type:export-only;
	mso-default-props:yes;
	mso-bidi-font-family:"Times New Roman";
	mso-bidi-theme-font:minor-bidi;}
 /* Page Definitions */
 @page
	{mso-mirror-margins:yes;
	mso-page-border-surround-header:no;
	mso-page-border-surround-footer:no;
	mso-footnote-separator:url("SICS-T--2009-06--SE.files/header.htm") fs;
	mso-footnote-continuation-separator:url("SICS-T--2009-06--SE.files/header.htm") fcs;
	mso-endnote-separator:url("SICS-T--2009-06--SE.files/header.htm") es;
	mso-endnote-continuation-separator:url("SICS-T--2009-06--SE.files/header.htm") ecs;
	mso-facing-pages:yes;}
@page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 142.7pt 72.0pt 93.9pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh1;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h1;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh1;
	mso-paper-source:0;}
div.WordSection1
	{page:WordSection1;}
@page WordSection2
	{size:595.3pt 841.9pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh2;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h2;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh2;
	mso-paper-source:0;}
div.WordSection2
	{page:WordSection2;}
@page WordSection3
	{size:595.3pt 841.9pt;
	margin:95.85pt 142.7pt 91.55pt 93.9pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh3;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h3;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh3;
	mso-paper-source:0;}
div.WordSection3
	{page:WordSection3;}
@page WordSection4
	{size:595.3pt 841.9pt;
	margin:127.25pt 90.45pt 118.95pt 5.0cm;
	mso-header-margin:95.85pt;
	mso-footer-margin:36.0pt;
	mso-page-numbers:4;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh4;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h4;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh4;
	mso-paper-source:0;}
div.WordSection4
	{page:WordSection4;}
@page WordSection5
	{size:595.3pt 841.9pt;
	margin:95.85pt 94.85pt 91.55pt 5.0cm;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-title-page:yes;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh5;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h5;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh5;
	mso-paper-source:0;}
div.WordSection5
	{page:WordSection5;}
@page WordSection6
	{size:595.3pt 841.9pt;
	margin:130.65pt 142.7pt 118.95pt 93.9pt;
	mso-header-margin:95.85pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh6;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h6;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh6;
	mso-paper-source:0;}
div.WordSection6
	{page:WordSection6;}
@page WordSection7
	{size:595.3pt 841.9pt;
	margin:72.0pt 72.0pt 72.0pt 72.0pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh7;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h7;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh7;
	mso-paper-source:0;}
div.WordSection7
	{page:WordSection7;}
@page WordSection8
	{size:595.3pt 841.9pt;
	margin:95.85pt 107.25pt 91.55pt 93.9pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-columns:2 even 11.9pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh8;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h8;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh8;
	mso-paper-source:0;}
div.WordSection8
	{page:WordSection8;}
@page WordSection9
	{size:595.3pt 841.9pt;
	margin:72.0pt 142.7pt 72.0pt 93.9pt;
	mso-header-margin:36.0pt;
	mso-footer-margin:36.0pt;
	mso-even-header:url("SICS-T--2009-06--SE.files/header.htm") eh8;
	mso-header:url("SICS-T--2009-06--SE.files/header.htm") h8;
	mso-first-header:url("SICS-T--2009-06--SE.files/header.htm") fh8;
	mso-paper-source:0;}
div.WordSection9
	{page:WordSection9;}
 /* List Definitions */
 @list l0
	{mso-list-id:69036816;
	mso-list-type:hybrid;
	mso-list-template-ids:467572916 -1016450150 367278514 -1089058140 -424874444 -360039826 279460334 -1075564328 360094130 -1233846706;}
@list l0:level1
	{mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:26.5pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level2
	{mso-level-number-format:alpha-lower;
	mso-level-text:%2;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:68.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level3
	{mso-level-number-format:roman-lower;
	mso-level-text:%3;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:104.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level4
	{mso-level-text:%4;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:140.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level5
	{mso-level-number-format:alpha-lower;
	mso-level-text:%5;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:176.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level6
	{mso-level-number-format:roman-lower;
	mso-level-text:%6;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:212.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level7
	{mso-level-text:%7;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:248.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level8
	{mso-level-number-format:alpha-lower;
	mso-level-text:%8;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:284.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l0:level9
	{mso-level-number-format:roman-lower;
	mso-level-text:%9;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:320.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1
	{mso-list-id:432868268;
	mso-list-type:hybrid;
	mso-list-template-ids:273685516 1947651216 925003650 1228584984 83421462 -1324574672 -567258218 487758338 -1461790954 -551517698;}
@list l1:level1
	{mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:26.5pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level2
	{mso-level-number-format:alpha-lower;
	mso-level-text:%2;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:68.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level3
	{mso-level-number-format:roman-lower;
	mso-level-text:%3;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:104.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level4
	{mso-level-text:%4;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:140.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level5
	{mso-level-number-format:alpha-lower;
	mso-level-text:%5;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:176.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level6
	{mso-level-number-format:roman-lower;
	mso-level-text:%6;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:212.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level7
	{mso-level-text:%7;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:248.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level8
	{mso-level-number-format:alpha-lower;
	mso-level-text:%8;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:284.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l1:level9
	{mso-level-number-format:roman-lower;
	mso-level-text:%9;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:320.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2
	{mso-list-id:833109782;
	mso-list-type:hybrid;
	mso-list-template-ids:-372837140 -881838574 -1163754622 2007637646 -1954150506 -2011502920 -1440192932 1062082754 539106870 1663597346;}
@list l2:level1
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:26.5pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:70.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level3
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:106.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level4
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:142.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level5
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:178.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level6
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:214.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level7
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:250.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level8
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:286.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l2:level9
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:322.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3
	{mso-list-id:1218779897;
	mso-list-type:hybrid;
	mso-list-template-ids:111565132 1360179902 -769752632 1878663730 1074556100 817634148 426937962 -84123876 733911790 1131840496;}
@list l3:level1
	{mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:26.5pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level2
	{mso-level-number-format:alpha-lower;
	mso-level-text:%2;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:68.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level3
	{mso-level-number-format:roman-lower;
	mso-level-text:%3;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:104.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level4
	{mso-level-text:%4;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:140.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level5
	{mso-level-number-format:alpha-lower;
	mso-level-text:%5;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:176.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level6
	{mso-level-number-format:roman-lower;
	mso-level-text:%6;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:212.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level7
	{mso-level-text:%7;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:248.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level8
	{mso-level-number-format:alpha-lower;
	mso-level-text:%8;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:284.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l3:level9
	{mso-level-number-format:roman-lower;
	mso-level-text:%9;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:320.05pt;
	text-indent:0cm;
	mso-ansi-font-size:10.0pt;
	mso-bidi-font-size:10.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4
	{mso-list-id:1405833167;
	mso-list-type:hybrid;
	mso-list-template-ids:-254748024 606086738 -1803907080 -1450380978 -419012236 66853412 567844874 1053593386 -1017998534 2110559562;}
@list l4:level1
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:27.25pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level2
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:70.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level3
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:106.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level4
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:142.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level5
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:178.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level6
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:214.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level7
	{mso-level-number-format:bullet;
	mso-level-text:\2022;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:250.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level8
	{mso-level-number-format:bullet;
	mso-level-text:o;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:286.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l4:level9
	{mso-level-number-format:bullet;
	mso-level-text:\25AA;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:322.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:black;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5
	{mso-list-id:2127893756;
	mso-list-template-ids:1745531606;}
@list l5:level1
	{mso-level-text:%1;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:16.35pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:bold;
	mso-bidi-font-weight:bold;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level2
	{mso-level-text:"%1\.%2";
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:25.1pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level3
	{mso-level-text:"%1\.%2\.%3";
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:34.9pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level4
	{mso-level-text:%4;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:95.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level5
	{mso-level-number-format:alpha-lower;
	mso-level-text:%5;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:131.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level6
	{mso-level-number-format:roman-lower;
	mso-level-text:%6;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:167.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level7
	{mso-level-text:%7;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:203.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level8
	{mso-level-number-format:alpha-lower;
	mso-level-text:%8;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:239.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
@list l5:level9
	{mso-level-number-format:roman-lower;
	mso-level-text:%9;
	mso-level-tab-stop:none;
	mso-level-number-position:left;
	margin-left:275.45pt;
	text-indent:0cm;
	mso-ansi-font-size:11.0pt;
	mso-bidi-font-size:11.0pt;
	mso-ascii-font-family:Cambria;
	mso-fareast-font-family:Cambria;
	mso-hansi-font-family:Cambria;
	mso-bidi-font-family:Cambria;
	color:red;
	border:none;
	mso-ansi-font-weight:normal;
	mso-ansi-font-style:normal;
	text-underline:black;
	text-decoration:none;
	text-underline:none;
	text-decoration:none;
	text-line-through:none;
	vertical-align:baseline;}
ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:普通表格;
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-priority:99;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.5pt;
	mso-bidi-font-size:11.0pt;
	font-family:等线;
	mso-ascii-font-family:等线;
	mso-ascii-theme-font:minor-latin;
	mso-fareast-font-family:等线;
	mso-fareast-theme-font:minor-fareast;
	mso-hansi-font-family:等线;
	mso-hansi-theme-font:minor-latin;
	mso-font-kerning:1.0pt;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="1043"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body lang=ZH-CN style='tab-interval:21.0pt'>

<div class=WordSection1>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.15pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>SICS Technical Report T2009:06</span></p>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:68.0pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>ISSN: 1100-3154</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:26.65pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:90%'><span lang=EN-US style='font-size:14.5pt;mso-bidi-font-size:
11.0pt;line-height:90%'>A literature survey of active machine learning in the
context of natural language processing</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:264.35pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Fredrik Olsson April 17, 2009</span></p>

<p class=MsoNormal align=left style='margin:0cm;margin-bottom:.0001pt;
text-align:left;text-indent:0cm;line-height:107%'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri;
color:#E72582'>fredrik.olsson@sics.se</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Swedish
Institute of Computer Science</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:16.0pt;
margin-left:-.25pt'><span lang=EN-US>Box 1263, SE-164 29 Kista, Sweden</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><b style='mso-bidi-font-weight:
normal'><span lang=EN-US>Abstract. </span></b><span lang=EN-US>Active learning
is a supervised machine learning technique in which the learner is in control
of the data used for learning. That control is utilized by the learner to ask
an oracle, typically a human with extensive knowledge of the domain at hand,
about the classes of the instances for which the model learned so far makes
unreliable predictions. The active learning process takes as input a set of
labeled examples, as well as a larger set of unlabeled examples, and produces a
classifier and a relatively small set of newly labeled data. The overall goal
is to create as good a classifier as possible, without having to mark-up and
supply the learner with more data than necessary. The learning process aims at
keeping the human annotation effort to a minimum, only asking for advice where
the training utility of the result of such a query is high.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:16.05pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Active learning has
been successfully applied to a number of natural language processing tasks,
such as, information extraction, named entity recognition, text categorization,
part-of-speech tagging, parsing, and word sense disambiguation. This report is
a literature survey of active learning from the perspective of natural language
processing.</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><b style='mso-bidi-font-weight:
normal'><span lang=EN-US>Keywords. </span></b><span lang=EN-US>Active learning,
machine learning, natural language processing, literature survey</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection2>

<p class=MsoNormal align=left style='margin:0cm;margin-bottom:.0001pt;
text-align:left;text-indent:0cm;line-height:107%'><span lang=EN-US><o:p>&nbsp;</o:p></span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection3>

<h1 style='margin-top:0cm;margin-right:0cm;margin-bottom:21.15pt;margin-left:
-.25pt'><span lang=EN-US>Contents</span></h1>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Introduction<span
style='mso-tab-count:1'> </span></span><span lang=EN-US>1</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Approaches
to Active Learning<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>3</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Query by uncertainty </span><span lang=EN-US>. . .
. . . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>5</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Query by committee </span><span lang=EN-US>. . . .
. . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp; </span>6</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:34.9pt;text-align:left;text-indent:-34.9pt;
line-height:107%;mso-list:l5 level3 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.2.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US style='color:red'>Query by
bagging and boosting </span><span lang=EN-US>. . . . . . . . . . . . .<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span>7</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:34.9pt;text-align:left;text-indent:-34.9pt;
line-height:107%;mso-list:l5 level3 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.2.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US style='color:red'>ActiveDecorate
</span><span lang=EN-US>. . . . . . . . . . . . . . . . . . . . . .<span
style='mso-tab-count:1'> </span>8</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Active learning with redundant views<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span></span><span lang=EN-US>. . .
. . . . . . . . . .<span style='mso-tab-count:1'>&nbsp; </span>9</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:34.9pt;text-align:left;text-indent:-34.9pt;
line-height:107%;mso-list:l5 level3 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>2.3.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US style='color:red'>How to split
a feature set </span><span lang=EN-US>. . . . . . . . . . . . . . . .<span
style='mso-tab-count:1'>&nbsp; </span>13</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Quantifying
disagreement<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>17</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Margin-based disagreement </span><span lang=EN-US>.
. . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp; </span>17</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Uncertainty sampling-based disagreement </span><span
lang=EN-US>. . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>18</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Entropy-based disagreement </span><span
lang=EN-US>. . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:
1'> </span>18</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>The K¨orner-Wrobel disagreement measure </span><span
lang=EN-US>. . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>19</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.5<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Kullback-Leibler divergence </span><span
lang=EN-US>. . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp; </span>19</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.6<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Jensen-Shannon divergence<span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span lang=EN-US>. . . . . . .
. . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>20</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.7<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Vote entropy<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>. . . . . . . . . . . . . . . . . . . . . . . . . . .<span
style='mso-tab-count:1'> </span>20</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>3.8<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>F-complement </span><span lang=EN-US>. . . . . . .
. . . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>21</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Data
access<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>23</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>4.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Selecting the seed set </span><span lang=EN-US>. .
. . . . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>23</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>4.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Stream-based and pool-based data access<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>. . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>24</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>4.3<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Processing singletons and batches </span><span
lang=EN-US>. . . . . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>25</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>5<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>The
creation and re-use of annotated data<span style='mso-tab-count:1'>&nbsp; </span></span><span
lang=EN-US>27</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>5.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Data re-use </span><span lang=EN-US>. . . . . . .
. . . . . . . . . . . . . . . . . . . . .<span style='mso-tab-count:1'> </span>27</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>5.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Active learning as annotation support </span><span
lang=EN-US>. . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span>28</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>6<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Cost-sensitive
active learning<span style='mso-tab-count:1'> </span></span><span lang=EN-US>31</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:16.35pt;text-align:left;text-indent:-16.35pt;
line-height:107%;mso-list:l5 level1 lfo1'><![if !supportLists]><b><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>7<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span></b><![endif]><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Monitoring
and terminating the learning process<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>35</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>7.1<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Measures for monitoring learning progress </span><span
lang=EN-US>. . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>35</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:25.1pt;text-align:left;text-indent:-25.1pt;
line-height:107%;mso-list:l5 level2 lfo1'><![if !supportLists]><span
lang=EN-US style='color:red'><span style='mso-list:Ignore'>7.2<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='color:red'>Assessing and terminating the learning </span><span
lang=EN-US>. . . . . . . . . . . . .<span style='mso-tab-count:1'>&nbsp; </span>36</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>iii</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.4pt;
margin-left:48.3pt'><span lang=EN-US>iv</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
107%;tab-stops:center 77.25pt 400.2pt'><span lang=EN-US style='font-family:
"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>References<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>41</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.0pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
107%;tab-stops:center 84.7pt 400.2pt'><span lang=EN-US style='font-family:"Calibri",sans-serif;
mso-fareast-font-family:Calibri'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='color:red'>Author
index<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>52</span></b></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 1</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Introduction</span></h1>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.05pt;margin-left:-.25pt;text-align:left;line-height:106%'><span
lang=EN-US>This report is a survey of the literature relevant to active machine
learning in the context of natural language processing. The intention is for it
to act as an overview and introductory source of information on the subject.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The survey is partly called for by the results of an on-line
questionnaire concerning the nature of annotation projects targeting
information access in general, and the use of active learning as annotation
support in particular (</span><span lang=EN-US style='color:blue'>Tomanek and
Olsson 2009</span><span lang=EN-US>). The questionnaire was announced to a
number of emailing lists, including Corpora, BioNLP, UAI List, ML-news,
SIGIRlist, and Linguist list, in February of 2009. One of the main findings was
that active learning is not widely used; only 20% of the participants responded
positively to the question “Have you ever used active learning in order to
speed up annotation/labeling work of any linguistic data?”. Thus, one of the
reasons to compile this survey is simply to help spread the word about the
fundamentals of active learning to the practitioners in the field of natural
language processing.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Since active learning is a vivid research area and thus constitutes
a moving target, I strive to revise and update the web version of the survey
periodically.</span><a style='mso-footnote-id:ftn1' href="#_ftn1"
name="_ftnref1" title=""><sup><span lang=EN-US style='color:red'><span
style='mso-special-character:footnote'><![if !supportFootnotes]><sup><span
lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:red;
mso-font-kerning:0pt;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[1]</span></sup><![endif]></span></span></sup></a><sup><span
lang=EN-US style='color:red'> </span></sup><span lang=EN-US>Please direct
suggestions for improvements, papers to include, and general comments to </span><span
lang=EN-US style='font-family:"Calibri",sans-serif;mso-fareast-font-family:
Calibri;color:#E72582'>fredrik.olsson@sics.se</span><span lang=EN-US>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:120.15pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>In the following, the
reader is assumed to have general knowledge of machine learning such as
provided by, for instance, </span><span lang=EN-US style='color:blue'>Mitchell </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>1997</span><span
lang=EN-US>), and </span><span lang=EN-US style='color:blue'>Witten and Frank </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2005</span><span
lang=EN-US>). I would also like to point the curious reader to the survey of
the literature of active learning by Settles (</span><span lang=EN-US
style='color:blue'>Settles 2009</span><span lang=EN-US>).</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>1</span></p>

<p class=MsoNormal style='margin-left:48.3pt'><span lang=EN-US>2<br clear=all
style='mso-special-character:line-break;page-break-before:always'>
</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 2</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Approaches to Active Learning</span></h1>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Active machine
learning is a supervised learning method in which the learner is in control of
the data from which it learns. That control is used by the learner to ask an
oracle, a teacher, typically a human with extensive knowledge of the domain at
hand, about the classes of the instances for which the model learned so far
makes unreliable predictions. The active learning process takes as input a set
of labeled examples, as well as a larger set of unlabeled examples, and
produces a classifier and a relatively small set of newly labeled data. The
overall goal is to produce as good a classifier as possible, without having to
mark-up and supply the learner with more data than necessary. The learning
process aims at keeping the human annotation effort to a minimum, only asking
for advice where the training utility of the result of such a query is high.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>On those occasions where it is necessary to distinguish between
“ordinary” machine learning and active learning, the former is sometimes
referred to as <i style='mso-bidi-font-style:normal'>passive learning </i>or
learning by <i style='mso-bidi-font-style:normal'>random sampling </i>from the
available set of labeled training data.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.3pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>A prototypical active
learning algorithm is outlined in Figure </span><span lang=EN-US
style='color:red'>2.1</span><span lang=EN-US>. Active learning has been
successfully applied to a number of language technology tasks, such as</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;
margin-left:26.5pt;text-indent:-10.9pt;line-height:119%;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>information extraction (</span><span
lang=EN-US style='color:blue'>Scheffer, Decomain and Wrobel 2001</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Finn and Kushmerick
2003</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Jones
et al. 2003</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Culotta
et al. 2006</span><span lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;
margin-left:26.5pt;text-indent:-10.9pt;line-height:119%;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>named entity recognition (</span><span
lang=EN-US style='color:blue'>Shen et al. 2004</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Hachey, Alex and Becker 2005</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Becker et al. 2005</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Vlachos 2006</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Kim et al. 2006</span><span
lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;
margin-left:26.5pt;margin-bottom:.0001pt;text-indent:-10.9pt;line-height:119%;
mso-list:l2 level1 lfo2'><![if !supportLists]><span lang=EN-US><span
style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>text categorization (</span><span
lang=EN-US style='color:blue'>Lewis and Gale 1994</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Lewis 1995</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Liere and Tadepalli 1997</span><span lang=EN-US>;
</span><span lang=EN-US style='color:blue'>McCallum and Nigam 1998</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Nigam and Ghani 2000</span><span
lang=EN-US>;</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:.15pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
107%;tab-stops:center 85.45pt 208.6pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='color:blue'>Schohn and Cohn 2000</span><span lang=EN-US>;<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='color:blue'>Tong and Koller 2002</span><span lang=EN-US>;<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='color:blue'>Hoi, Jin and Lyu</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:27.25pt;text-indent:0cm;line-height:119%'><span lang=EN-US
style='color:blue'>2006</span><span lang=EN-US>);</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>3</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection4>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:26.5pt;text-indent:-10.9pt;line-height:119%;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>part-of-speech tagging (</span><span
lang=EN-US style='color:blue'>Dagan and Engelson 1995</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Argamon-Engelson and Dagan 1999</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Ringger et al. 2007</span><span
lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;
margin-left:26.5pt;margin-bottom:.0001pt;text-indent:-10.9pt;line-height:119%;
mso-list:l2 level1 lfo2'><![if !supportLists]><span lang=EN-US><span
style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>parsing (</span><span
lang=EN-US style='color:blue'>Thompson, Califf and Mooney 1999</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Hwa 2000</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Tang, Luo and Roukos
2002</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Steedman
et al. 2003</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Hwa
et al. 2003</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Osborne
and Baldridge 2004</span><span lang=EN-US>; </span><span lang=EN-US
style='color:blue'>Becker and Osborne 2005</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Reichart and Rappoport</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:27.25pt;text-indent:0cm;line-height:119%'><span lang=EN-US
style='color:blue'>2007</span><span lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:26.5pt;text-indent:-10.9pt;line-height:119%;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>word sense disambiguation (</span><span
lang=EN-US style='color:blue'>Chen et al. 2006</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Chan and Ng 2007</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Zhu and Hovy 2007</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Zhu, Wang and Hovy 2008a</span><span lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:26.5pt;text-indent:-10.9pt;line-height:119%;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>spoken language understanding (</span><span
lang=EN-US style='color:blue'>Tur, Hakkani-Tu¨r and Schapire 2005</span><span
lang=EN-US>; </span><span lang=EN-US style='color:blue'>Wu et al. 2006</span><span
lang=EN-US>);</span></p>

<p class=MsoNormal style='margin-left:26.5pt;text-indent:-10.9pt;line-height:
223%;mso-list:l2 level1 lfo2'><![if !supportLists]><span lang=EN-US><span
style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>phone sequence recognition (</span><span
lang=EN-US style='color:blue'>Douglas 2003</span><span lang=EN-US>); &#8226; automatic
transliteration (</span><span lang=EN-US style='color:blue'>Kuo, Li and Yang
2006</span><span lang=EN-US>); and</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.35pt;
margin-left:26.5pt;text-indent:-10.9pt;mso-list:l2 level1 lfo2'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>sequence segmentation (</span><span
lang=EN-US style='color:blue'>Sassano 2002</span><span lang=EN-US>).</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>One of the first
attempts to make expert knowledge an integral part of learning is that of query
construction (</span><span lang=EN-US style='color:blue'>Angluin 1988</span><span
lang=EN-US>). Angluin introduces a range of queries that the learner is allowed
to ask the teacher, such as queries regarding <i style='mso-bidi-font-style:
normal'>membership </i>(“Is this concept an example of the target concept?”), <i
style='mso-bidi-font-style:normal'>equivalence </i>(“Is X equivalent to Y?”),
and <i style='mso-bidi-font-style:normal'>disjointness </i>(“Are X and Y
disjoint?”). Besides a simple <i style='mso-bidi-font-style:normal'>yes </i>or <i
style='mso-bidi-font-style:normal'>no</i>, the full answer from the teacher can
contain counterexamples, except in the case of membership queries. The learner
constructs queries by altering the attribute values of instances in such a way
that the answer to the query is as informative as possible. Adopting this generative
approach to active learning leads to problems in domains where changing the
values of attributes are not guaranteed to make sense to the human expert;
consider the example of text categorization using a bag-of-word approach. If
the learner first replaces some of the words in the representation, and then
asks the teacher whether the new artificially created document is a member of a
certain class, it is not likely that the new document makes sense to the
teacher.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>In contrast to the theoretically interesting generative approach to
active learning, current practices are based on example-driven means to
incorporate the teacher into the learning process; the instances that the
learner asks (queries) the teacher to classify all stem from existing,
unlabeled data. The <i style='mso-bidi-font-style:normal'>selective sampling </i>method
introduced by </span><span lang=EN-US style='color:blue'>Cohn, Atlas and Ladner
</span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>1994</span><span
lang=EN-US>) builds on the concept of membership queries, albeit from an
example-driven perspective; the learner queries the teacher about the data at
hand for which it is uncertain, that is, for which it believes
misclassifications are possible.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:11.0pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_44236" o:spid="_x0000_s1041" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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">
 <v:shape id="Shape_x0020_57899" o:spid="_x0000_s1042" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQB/UTmvxgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9Ba8JA
FITvBf/D8oTe6kbBNkZXqYLgpUKj3h/Z1yQ0+zZkX3Xtr+8WCj0OM/MNs9pE16krDaH1bGA6yUAR
V962XBs4n/ZPOaggyBY7z2TgTgE269HDCgvrb/xO11JqlSAcCjTQiPSF1qFqyGGY+J44eR9+cChJ
DrW2A94S3HV6lmXP2mHLaaHBnnYNVZ/llzMg39NSuvwS3+L8iLP7ZZsdjltjHsfxdQlKKMp/+K99
sAbmL/liAb930hXQ6x8AAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEAf1E5r8YAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=2
src="SICS-T--2009-06--SE.files/image001.gif" v:shapes="Group_x0020_44236 Shape_x0020_57899"><![endif]><!--[if gte vml 1]><v:shapetype
 id="_x0000_t75" coordsize="21600,21600" o:spt="75" o:preferrelative="t"
 path="m@4@5l@4@11@9@11@9@5xe" filled="f" stroked="f">
 <v:stroke joinstyle="miter"/>
 <v:formulas>
  <v:f eqn="if lineDrawn pixelLineWidth 0"/>
  <v:f eqn="sum @0 1 0"/>
  <v:f eqn="sum 0 0 @1"/>
  <v:f eqn="prod @2 1 2"/>
  <v:f eqn="prod @3 21600 pixelWidth"/>
  <v:f eqn="prod @3 21600 pixelHeight"/>
  <v:f eqn="sum @0 0 1"/>
  <v:f eqn="prod @6 1 2"/>
  <v:f eqn="prod @7 21600 pixelWidth"/>
  <v:f eqn="sum @8 21600 0"/>
  <v:f eqn="prod @7 21600 pixelHeight"/>
  <v:f eqn="sum @10 21600 0"/>
 </v:formulas>
 <v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>
 <o:lock v:ext="edit" aspectratio="t"/>
</v:shapetype><![endif]--></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1039" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>1.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Initialize
the process by applying base learner <i style='mso-bidi-font-style:normal'>B </i>to
labeled training data set <i style='mso-bidi-font-style:normal'>D<sub>L </sub></i>to
obtain classifier <i style='mso-bidi-font-style:normal'>C</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>2.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Apply
<i style='mso-bidi-font-style:normal'>C </i>to unlabeled data set <i
style='mso-bidi-font-style:normal'>D<sub>U </sub></i>to obtain <i
style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>0</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>3.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>From
<i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>0</sup>, select the
most informative <i style='mso-bidi-font-style:normal'>n </i>instances to learn
from, <i style='mso-bidi-font-style:normal'>I</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>4.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Ask
the teacher for classifications of the instances in <i style='mso-bidi-font-style:
normal'>I</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>5.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Move
<i style='mso-bidi-font-style:normal'>I</i>, with supplied classifications,
from <i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>0 </sup>to <i
style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>6.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Re-train
using <i style='mso-bidi-font-style:normal'>B </i>on <i style='mso-bidi-font-style:
normal'>D<sub>L </sub></i>to obtain a new classifier, <i style='mso-bidi-font-style:
normal'>C</i><sup>0</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.45pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>7.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Repeat
steps 2 through 6, until <i style='mso-bidi-font-style:normal'>D<sub>U </sub></i>is
empty or until some stopping criterion is met.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.55pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l1 level1 lfo3'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>8.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Output
a classifier that is trained on <i style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:15.95pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_44237" o:spid="_x0000_s1039" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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=
">
 <v:shape id="Shape_x0020_57901" o:spid="_x0000_s1040" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQAfzK+zxgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9BSwMx
FITvQv9DeAVvNtlCta5NSysIvVhwtffH5rm7uHlZNq9t6q83guBxmJlvmNUm+V6daYxdYAvFzIAi
roPruLHw8f5ytwQVBdlhH5gsXCnCZj25WWHpwoXf6FxJozKEY4kWWpGh1DrWLXmMszAQZ+8zjB4l
y7HRbsRLhvtez4251x47zgstDvTcUv1VnbwF+S4q6ZfH9JoWB5xfjzuzP+ysvZ2m7RMooST/4b/2
3llYPDyaAn7v5Cug1z8AAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEAH8yvs8YAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=2
src="SICS-T--2009-06--SE.files/image002.gif" v:shapes="Group_x0020_44237 Shape_x0020_57901"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1038" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal align=center style='margin-bottom:27.75pt;text-align:center;
line-height:110%'><span lang=EN-US>Figure 2.1: A prototypical active learning
algorithm.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:10.3pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 64.9pt'><span lang=EN-US>2.1<span
style='mso-tab-count:1'> </span>Query by uncertainty</span></h2>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Building on the
ideas introduced by Cohn and colleagues concerning selective sampling (</span><span
lang=EN-US style='color:blue'>Cohn, Atlas and Ladner 1994</span><span
lang=EN-US>), in particular the way the learner selects what instances to ask
the teacher about, <i style='mso-bidi-font-style:normal'>query by uncertainty </i>(<i
style='mso-bidi-font-style:normal'>uncertainty sampling, uncertainty reduction</i>)
queries the learning instances for which the current hypothesis is least
confident. In query by uncertainty, a single classifier is learned from labeled
data and subsequently utilized for examining the unlabeled data. Those
instances in the unlabeled data set that the classifier is least certain about
are subject to classification by a human annotator. The use of confidence
scores pertains to the third step in Figure </span><span lang=EN-US
style='color:red'>2.1</span><span lang=EN-US>. This straightforward method
requires the base learner to provide a score indicating how confident it is in
each prediction it performs.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.5pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Query by uncertainty
has been realized using a range of base learners, such as logistic regression (</span><span
lang=EN-US style='color:blue'>Lewis and Gale 1994</span><span lang=EN-US>),
Support Vector Machines (</span><span lang=EN-US style='color:blue'>Schohn and
Cohn 2000</span><span lang=EN-US>), and Markov Models (</span><span lang=EN-US
style='color:blue'>Scheffer, Decomain and Wrobel 2001</span><span lang=EN-US>).
They all report results indicating that the amount of data that require
annotation in order to reach a given performance, compared to passively
learning from examples provided in a random order, is heavily reduced using
query by uncertainty.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Becker and Osborne </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) report on a
two-stage model for actively learning statistical grammars. They use
uncertainty sampling for selecting the sentences for which the parser provides
the lowest confidence scores. The problem with this approach, they claim, is
that the confidence score says nothing about the state of the statistical model
itself; if the estimate of the parser’s confidence in a certain parse tree is
based on rarely occurring</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:11.0pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_44306" o:spid="_x0000_s1037" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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=
">
 <v:shape id="Shape_x0020_57903" o:spid="_x0000_s1038" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQCAUpRfxgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9BSwMx
FITvgv8hvII3m7RSrWvTYgWhFwtd7f2xee4u3bwsm2eb+utNoeBxmJlvmMUq+U4daYhtYAuTsQFF
XAXXcm3h6/P9fg4qCrLDLjBZOFOE1fL2ZoGFCyfe0bGUWmUIxwItNCJ9oXWsGvIYx6Enzt53GDxK
lkOt3YCnDPednhrzqD22nBca7OmtoepQ/ngL8jsppZvv00eabXF63q/NZru29m6UXl9ACSX5D1/b
G2dh9vRsHuByJ18BvfwDAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEAgFKUX8YAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=2
src="SICS-T--2009-06--SE.files/image003.gif" v:shapes="Group_x0020_44306 Shape_x0020_57903"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1037" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.0pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>1.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Initialize
the process by applying <i style='mso-bidi-font-style:normal'>EnsembleGenerationMethod
</i>using base learner <i style='mso-bidi-font-style:normal'>B </i>on labeled
training data set <i style='mso-bidi-font-style:normal'>D<sub>L </sub></i>to
obtain a committee of classifiers <i style='mso-bidi-font-style:normal'>C</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>2.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Have
each classifier in <i style='mso-bidi-font-style:normal'>C </i>predict a label
for every instance in the unlabeled data set <i style='mso-bidi-font-style:
normal'>D<sub>U</sub></i>, obtaining labeled set <i style='mso-bidi-font-style:
normal'>D<sub>U</sub></i><sup>0</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.4pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>3.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>From
<i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>0</sup>, select the
most informative <i style='mso-bidi-font-style:normal'>n </i>instances to learn
from, obtaining <i style='mso-bidi-font-style:normal'>D<sub>U</sub></i></span><span
lang=EN-US style='font-size:7.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>00</span><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.0pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>4.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Ask
the teacher for classifications of the instances <i style='mso-bidi-font-style:
normal'>I </i>in <i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>00</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>5.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Move
<i style='mso-bidi-font-style:normal'>I</i>, with supplied classifications,
from <i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>00 </sup>to <i
style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.8pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>6.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Re-train
using <i style='mso-bidi-font-style:normal'>EnsembleGenerationMethod </i>and
base learner <i style='mso-bidi-font-style:normal'>B </i>on <i
style='mso-bidi-font-style:normal'>D<sub>L </sub></i>to obtain a new committee,
<i style='mso-bidi-font-style:normal'>C</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.1pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>7.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Repeat
steps 2 through 6 until <i style='mso-bidi-font-style:normal'>D<sub>U </sub></i>is
empty or some stopping criterion is met.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.25pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l3 level1 lfo4'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>8.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Output
a classifier learned using <i style='mso-bidi-font-style:normal'>EnsembleGenerationMethod
</i>and base learner <i style='mso-bidi-font-style:normal'>B </i>on <i
style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:15.95pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_44308" o:spid="_x0000_s1035" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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=
">
 <v:shape id="Shape_x0020_57905" o:spid="_x0000_s1036" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQBg96mwxgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9BSwMx
FITvgv8hPMGbTVrYWtempRWEXiy42vtj89xd3Lwsm9c29debguBxmJlvmOU6+V6daIxdYAvTiQFF
XAfXcWPh8+P1YQEqCrLDPjBZuFCE9er2ZomlC2d+p1MljcoQjiVaaEWGUutYt+QxTsJAnL2vMHqU
LMdGuxHPGe57PTNmrj12nBdaHOilpfq7OnoL8jOtpF8c0lsq9ji7HLZmt99ae3+XNs+ghJL8h//a
O2eheHwyBVzv5CugV78AAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEAYPepsMYAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=2
src="SICS-T--2009-06--SE.files/image004.gif" v:shapes="Group_x0020_44308 Shape_x0020_57905"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1036" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:4.45pt;
margin-bottom:26.0pt;margin-left:.5pt;text-align:center;line-height:110%'><span
lang=EN-US>Figure 2.2: A prototypical query by committee algorithm.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:4.45pt;margin-bottom:
27.9pt;margin-left:-.25pt'><span lang=EN-US>information in the underlying data,
the confidence in the confidence score is low, and should thus be avoided. The
first stage in Becker and Osborne’s two-stage method aims at identifying and
singling out those instances (sentences) for which the parser cannot provide
reliable confidence measures. In the second stage, query by uncertainty is
applied to the remaining set of instances. Becker and Osborne (</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) report that their
method performs better than the original form of uncertainty sampling, and that
it exhibits results competitive with a standard query by committee method.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 109.4pt'><span
lang=EN-US>2.2<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Query
by committee</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:17.9pt;
margin-left:-.25pt'><i style='mso-bidi-font-style:normal'><span lang=EN-US>Query
by committee</span></i><span lang=EN-US>, like query by uncertainty, is a
selective sampling method, the fundamental difference between the two being
that query by committee is a multi-classifier approach. In the original
conception of query by committee, several hypotheses are randomly sampled from
the version space (</span><span lang=EN-US style='color:blue'>Seung, Opper and
Sompolinsky 1992</span><span lang=EN-US>). The committee thus obtained is used
to examine the set of unlabeled data, and the disagreement between the hypotheses
with respect to the class of a given instance is utilized to decide whether
that instance is to be classified by the human annotator. The idea with using a
decision committee relies on the assumption that in order for approaches
combining several classifiers to work, the ensemble needs to be made up from
diverse classifiers. If all classifiers are identical, there will be no
disagreement between them as to how a given instance should be classified, and
the whole idea of voting (or averaging) is invalidated. Query by committee, in
the original sense, is possible only with base learners for which it is
feasible to access and sample from the version space; learners reported to work
in such a setting include Winnow (</span><span lang=EN-US style='color:blue'>Liere
and Tadepalli 1997</span><span lang=EN-US>), and perceptrons (</span><span
lang=EN-US style='color:blue'>Freund et al. 1997</span><span lang=EN-US>). A
prototypical query by committee algorithm is shown in Figure </span><span
lang=EN-US style='color:red'>2.2</span><span lang=EN-US>.</span></p>

<h3 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 86.0pt'><span
lang=EN-US>2.2.1<span style='mso-tab-count:1'> </span>Query by bagging and
boosting</span></h3>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US
style='color:blue'>Abe and Mamitsuka </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) introduce an
alternative way of generating multiple hypotheses; they build on <i
style='mso-bidi-font-style:normal'>bagging </i>and <i style='mso-bidi-font-style:
normal'>boosting </i>to generate committees of classifiers from the same
underlying data set.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Bagging, short for bootstrap aggregating (</span><span lang=EN-US
style='color:blue'>Breiman 1996</span><span lang=EN-US>), is a technique
exploiting the bias-variance decomposition of classification errors (see, for
instance, </span><span lang=EN-US style='color:blue'>Domingos 2000 </span><span
lang=EN-US>for an overview of the decomposition problem). Bagging aims at
minimizing the variance part of the error by randomly sampling C with
replacement C from the data set, thus creating several data sets from the
original one. The same base learner is then applied to each data set in order
to create a committee of classifiers. In the case of classification, an
instance is assigned the label that the majority of the classifiers predicted
(majority vote). In the case of regression, the value assigned to an instance
is the average of the predictions made by the classifiers.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.5pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Like bagging, boosting
(</span><span lang=EN-US style='color:blue'>Freund and Schapire 1997</span><span
lang=EN-US>) is a way of combining classifiers obtained from the same base
learner. Instead of building classifiers independently, boosting allows for
classifiers to influence each other during training. Boosting is based on the
assumption that several classifiers learned using a weak</span><a
style='mso-footnote-id:ftn2' href="#_ftn2" name="_ftnref2" title=""><sup><span
lang=EN-US style='color:red'><span style='mso-special-character:footnote'><![if !supportFootnotes]><sup><span
lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:red;
mso-font-kerning:0pt;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[2]</span></sup><![endif]></span></span></sup></a><sup><span
lang=EN-US style='color:red'> </span></sup><span lang=EN-US>base learner, over
a varying distribution of the target classes in the training data, can be
combined into one strong classifier. The basic idea is to let classifiers
concentrate on the cases in which previously built classifiers failed to
correctly classify data. Furthermore, in classifying data, boosting assigns
weights to the classifiers according to their performance; the better the performance,
the higher valued is the classifier’s contribution in voting (or averaging). </span><span
lang=EN-US style='color:blue'>Schapire </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2003</span><span lang=EN-US>) provides an
overview of boosting.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:5.45pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Abe
and Mamitsuka </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>1998</span><span lang=EN-US>) claim that query by committee,
query by bagging, and query by boosting form a natural progression; in query by
committee, the variance in performance among the hypotheses is due to the
randomness exhibited by the base learner. In query by bagging, the variance is
a result of the randomization introduced when sampling from the data set.
Finally, the variance in query by boosting is a result of altering the sampling
according to the weighting of the votes given by the hypotheses involved. A
generalized variant of query by bagging is obtained if the <i style='mso-bidi-font-style:
normal'>EnsembleGenerationMethod </i>in Figure </span><span lang=EN-US
style='color:red'>2.2 </span><span lang=EN-US>is substituted with bagging.
Essentially, query by bagging applies bagging in order to generate a set of
hypotheses that is then used to decide whether it is worth querying the teacher
for classification of a given unlabeled instance. Query by boosting proceeds
similarly to query by bagging, with boosting applied to the labeled data set in
order to generate a committee of classifiers instead of bagging, that is,
boosting is used as <i style='mso-bidi-font-style:normal'>EnsembleGenerationMethod
</i>in Figure </span><span lang=EN-US style='color:red'>2.2</span><span
lang=EN-US>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:43.15pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Abe
and Mamitsuka </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>1998</span><span lang=EN-US>) report results from experiments
using the decision tree learner C4.5 as base learner and eight data sets from
the UCI Machine Learning Repository, the latest release of which is described
in (</span><span lang=EN-US style='color:blue'>Asuncion and Newman 2007</span><span
lang=EN-US>). They find that query by bagging and query by boosting significantly
outperformed a single C4.5 decision tree, as well as boosting using C4.5.</span></p>

<h3 style='margin-top:0cm;margin-right:0cm;margin-bottom:16.35pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 86.35pt'><span lang=EN-US>2.2.2<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>ActiveDecorate</span></h3>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:5.9pt;
margin-left:-.25pt'><span lang=EN-US style='color:blue'>Melville and Mooney </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2004</span><span
lang=EN-US>) introduce ActiveDecorate, an extension to the Decorate method (</span><span
lang=EN-US style='color:blue'>Melville and Mooney 2003</span><span lang=EN-US>)
for constructing diverse committees by enhancing available data with
artificially generated training examples. Decorate C short for <i
style='mso-bidi-font-style:normal'>Diverse Ensemble Creation by Oppositional
Relabeling of Artificial Training Examples </i>C is an iterative method
generating one classifier at a time. In each iteration, artificial training
data is generated in such a way that the labels of the data are maximally
different from the predictions made by the current committee of classifiers. A
strong base learner is then used to train a classifier on the union of the artificial
data set and the available labeled set. If the resulting classifier increases
the prediction error on the training set, it is rejected as a member of the
committee, and added otherwise. In ActiveDecorate, the Decorate method is
utilized for generating the committee of classifiers, which is then used to
decide which instances from the unlabeled data set are up for annotation by the
human oracle. In terms of the prototypical query by committee algorithm in
Figure </span><span lang=EN-US style='color:red'>2.2</span><span lang=EN-US>,
ActiveDecorate is used as <i style='mso-bidi-font-style:normal'>EnsembleGenerationMethod</i>.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Melville and Mooney </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2004</span><span lang=EN-US>) carry out
experiments on 15 data sets from the UCI repository (</span><span lang=EN-US
style='color:blue'>Asuncion and Newman 2007</span><span lang=EN-US>). They show
that their algorithm outperforms query by bagging and query by boosting as
introduced by Abe and Mamitsuka (</span><span lang=EN-US style='color:blue'>1998</span><span
lang=EN-US>) both in terms of accuracy reached, and in terms of the amount of
data needed to reach top accuracy. Melville and Mooney conclude that the
superiority of ActiveDecorate is due to the diversity of the generated
ensembles.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:7.65pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 122.0pt'><span lang=EN-US>2.3<span
style='mso-tab-count:1'> </span>Active learning with redundant views</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.25pt;
margin-left:-.25pt'><span lang=EN-US>Roughly speaking, utilizing redundant
views is similar to the query by committee approach described above. The
essential difference is that instead of randomly sampling the version space, or
otherwise tamper with the existing training data with the purpose of extending
it to obtain a committee, using redundant views involves splitting the feature
set into several sub-sets or <i style='mso-bidi-font-style:normal'>views</i>,
each of which is enough, to some extent, to describe the underlying problem.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Blum and Mitchell (</span><span lang=EN-US style='color:blue'>1998</span><span
lang=EN-US>) introduce a semi-supervised bootstrapping technique called <i
style='mso-bidi-font-style:normal'>Co-training </i>in which two classifiers are
trained on the same data, but utilizing different views of it. The example of
views provided by </span><span lang=EN-US style='color:blue'>Blum and Mitchell </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>1998</span><span
lang=EN-US>) is from the task of categorizing texts on the web. One way of
learning how to do that is by looking at the links to the target document from
other documents on the web, another way is to consider the contents of the
target document alone. These two ways correspond to two separate views of
learning the same target concept.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>As in active learning, Co-training starts off with a small set of
labeled data, and a large set of unlabeled data. The classifiers are first
trained on the labeled part, and subsequently used to tag an unlabeled set. The
idea is then that during the learning process, the predictions made by the
first classifier on the unlabeled data set, and for which it has the highest
confidence, are added to the training set of the second classifier, and
viceversa. The classifiers are then retrained on the newly extended training
set, and the bootstrapping process continues with the remainder of the
unlabeled data.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.7pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>A drawback with the
Co-training method as it is originally described by Blum and Mitchell (</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) is that it requires
the views of data to be conditionally independent and compatible given the
class, that is, each view should be enough for producing a strong learner
compatible with the target concept. In practice, however, finding such a split
of features may be hard; the problem is further discussed in Section </span><span
lang=EN-US style='color:red'>2.3.1</span><span lang=EN-US>.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Co-training <i style='mso-bidi-font-style:normal'>per se </i>is not
within the active learning paradigm since it does not involve a teacher, but
the work by Blum and Mitchell (</span><span lang=EN-US style='color:blue'>1998</span><span
lang=EN-US>) forms the basis for other approaches. One such approach is that of
<i style='mso-bidi-font-style:normal'>Corrected Co-training </i>(</span><span
lang=EN-US style='color:blue'>Pierce and Cardie 2001</span><span lang=EN-US>).
Corrected Co-training is a way of remedying the degradation in performance that
can occur when applying Co-training to large data sets. The concerns of </span><span
lang=EN-US style='color:blue'>Pierce and Cardie </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2001</span><span lang=EN-US>) include that of
scalability of the original Co-training method. Pierce and Cardie investigate
the task of noun phrase chunking, and they find that when hundreds of thousands
of examples instead of hundreds, are needed to learn a target concept, the
successive degradation of the quality of the bootstrapped data set becomes an issue.
When increasing the amount of unlabeled data, and thus also increasing the
number of iterations during which Co-training</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:11.0pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_49462" o:spid="_x0000_s1033" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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=
">
 <v:shape id="Shape_x0020_57907" o:spid="_x0000_s1034" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQD/aZJcxgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9BawIx
FITvQv9DeIXeNFGw6tYotVDwUqGr3h+b192lm5dl86qxv74pFHocZuYbZr1NvlMXGmIb2MJ0YkAR
V8G1XFs4HV/HS1BRkB12gcnCjSJsN3ejNRYuXPmdLqXUKkM4FmihEekLrWPVkMc4CT1x9j7C4FGy
HGrtBrxmuO/0zJhH7bHlvNBgTy8NVZ/ll7cg39NSuuU5vaX5AWe3887sDztrH+7T8xMooST/4b/2
3lmYL1ZmAb938hXQmx8AAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEA/2mSXMYAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=1
src="SICS-T--2009-06--SE.files/image005.gif" v:shapes="Group_x0020_49462 Shape_x0020_57907"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1035" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.8pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>1.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Initialize
the process by applying base learner <i style='mso-bidi-font-style:normal'>B </i>using
each <i style='mso-bidi-font-style:normal'>v </i>in views <i style='mso-bidi-font-style:
normal'>V </i>to labeled training set <i style='mso-bidi-font-style:normal'>D<sub>L
</sub></i>to obtain a committee of classifiers <i style='mso-bidi-font-style:
normal'>C</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>2.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Have
each classifier in <i style='mso-bidi-font-style:normal'>C </i>predict a label
for every instance in the unlabeled data set <i style='mso-bidi-font-style:
normal'>D<sub>U</sub></i>, obtaining labeled set <i style='mso-bidi-font-style:
normal'>D<sub>U</sub></i><sup>0</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.05pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>3.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>From
<i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>0</sup>, select
those instances for which the classifiers in <i style='mso-bidi-font-style:
normal'>C </i>predicted different labels to obtain the <i style='mso-bidi-font-style:
normal'>contention set</i></span><a style='mso-footnote-id:ftn3' href="#_ftn3"
name="_ftnref3" title=""><sup><span lang=EN-US style='font-size:10.0pt;
mso-bidi-font-size:11.0pt;line-height:111%;color:red'><span style='mso-special-character:
footnote'><![if !supportFootnotes]><sup><span lang=EN-US style='font-size:10.0pt;
mso-bidi-font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:red;
mso-font-kerning:0pt;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[3]</span></sup><![endif]></span></span></sup></a><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:10.0pt;
mso-bidi-font-size:11.0pt;line-height:111%'>D<sub>U</sub></span></i><sup><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>00</span></sup><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.3pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>4.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Select
instances <i style='mso-bidi-font-style:normal'>I </i>from <i style='mso-bidi-font-style:
normal'>D<sub>U</sub></i><sup>00 </sup>and ask the teacher for their labels.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>5.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Move
instances <i style='mso-bidi-font-style:normal'>I</i>, with supplied
classifications, from <i style='mso-bidi-font-style:normal'>D<sub>U</sub></i><sup>00
</sup>to <i style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.9pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>6.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Re-train
by applying base learner <i style='mso-bidi-font-style:normal'>B </i>using each
<i style='mso-bidi-font-style:normal'>v </i>in views <i style='mso-bidi-font-style:
normal'>V </i>to <i style='mso-bidi-font-style:normal'>D<sub>L </sub></i>to
obtain committe <i style='mso-bidi-font-style:normal'>C</i><sup>0</sup>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:6.1pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>7.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Repeat
steps 2 through 6 until <i style='mso-bidi-font-style:normal'>D<sub>U </sub></i>is
empty or some stopping criterion is met.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.2pt;
margin-left:26.5pt;text-indent:-13.2pt;line-height:111%;mso-list:l0 level1 lfo5'><![if !supportLists]><span
lang=EN-US style='font-size:10.0pt;line-height:111%'><span style='mso-list:
Ignore'>8.<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span></span><![endif]><span
lang=EN-US style='font-size:10.0pt;mso-bidi-font-size:11.0pt;line-height:111%'>Output
the final classifier learned by combining base learner <i style='mso-bidi-font-style:
normal'>B</i>, views in <i style='mso-bidi-font-style:normal'>V </i>, and data <i
style='mso-bidi-font-style:normal'>D<sub>L</sub></i>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:15.95pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:107%'><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span><span
style='mso-spacerun:yes'>&nbsp;</span>SHAPE <span
style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span style='mso-element:
field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_49463" o:spid="_x0000_s1031" style='width:358.65pt;height:1.4pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="45549,179" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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">
 <v:shape id="Shape_x0020_57909" o:spid="_x0000_s1032" style='position:absolute;
  width:45549;height:179;visibility:visible;mso-wrap-style:square;
  v-text-anchor:top' coordsize="4554919,17996" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQDhuqO1xgAAAN4AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI9BawIx
FITvBf9DeIK3mijY6tYotVDwUqFrvT82r7tLNy/L5lWjv74pFHocZuYbZr1NvlNnGmIb2MJsakAR
V8G1XFv4OL7eL0FFQXbYBSYLV4qw3Yzu1li4cOF3OpdSqwzhWKCFRqQvtI5VQx7jNPTE2fsMg0fJ
cqi1G/CS4b7Tc2MetMeW80KDPb00VH2V396C3GaldMtTekuLA86vp53ZH3bWTsbp+QmUUJL/8F97
7ywsHldmBb938hXQmx8AAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEA4bqjtcYAAADeAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l4554919,r,17996l,17996,,e" fillcolor="black" stroked="f"
  strokeweight="0">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,4554919,17996"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=478 height=2
src="SICS-T--2009-06--SE.files/image002.gif" v:shapes="Group_x0020_49463 Shape_x0020_57909"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1034" type="#_x0000_t75" style='width:358.65pt;
 height:1.4pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--></p>

<p class=MsoNormal align=center style='margin-bottom:26.0pt;text-align:center;
line-height:110%'><span lang=EN-US>Figure 2.3: A prototypical multiple view
active learning algorithm.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.7pt;
margin-left:-.25pt'><span lang=EN-US>will be in effect, the risk of errors
introduced by the classifiers into each view increases. In Corrected
Co-training a human annotator reviews and edits, as found appropriate, the data
produced by both view classifiers in each iteration, prior to adding the data
to the pool of labeled training data. This way, Pierce and Cardie point out,
the quality of the labeled data is maintained with only a moderate effort
needed on behalf of the human annotator. Figure </span><span lang=EN-US
style='color:red'>2.3 </span><span lang=EN-US>shows a prototypical algorithm
for multi-view active learning. It is easy to see how Corrected Co-training
fits into it; if, instead of having the classifiers select the instances on
which they disagree (step 3 in Figure </span><span lang=EN-US style='color:
red'>2.3</span><span lang=EN-US>), each classifier selects the instances for
which it makes highly confident predictions, and have the teacher correct them
in step 4, the algorithm in Figure </span><span lang=EN-US style='color:red'>2.3
</span><span lang=EN-US>would describe Corrected Co-training.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.3pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Hwa
et al. </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2003</span><span
lang=EN-US>) adopt a Corrected Co-training approach to statistical parsing. In
pursuing their goal C to further decrease the amount of corrections of parse
trees a human annotator has to perform C they introduce <i style='mso-bidi-font-style:
normal'>single-sided corrected Co-training</i>. Single-sided Corrected
Co-training is like Corrected Co-training, with the difference that the
annotator only reviews the data, parse trees, produced by one of the view
classifiers. </span><span lang=EN-US style='color:blue'>Hwa et al. </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2003</span><span
lang=EN-US>) conclude that in terms of parsing performance, parsers trained
using some form of sample selection technique are better off than parsers
trained in a pure Co-training setting, given the cost of human annotation.
Furthermore, Hwa and colleagues point out that even though parsing performance
achieved using single-sided Corrected Co-training is not as good as that
resulting from Corrected Co-training, some corrections are better than none.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>In their work, </span><span lang=EN-US style='color:blue'>Pierce and
Cardie </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2001</span><span
lang=EN-US>) note that corrected Co-training does not help their noun phrase
chunker to reach the expected performance. Their hypothesis as to why the
performance gap occurs, is that Co-training does not lend itself to finding the
most informative examples available in the unlabeled data set. Since each
classifier selects the examples it is most confident in, the examples are
likely to represent aspects of the task at hand already familiar to the
classifiers, rather than representing potentially new and more informative
ones. Thus, where Co-training promotes confidence in the selected examples over
finding examples that would help incorporating new information about the task,
active learning works the other way around. A method closely related to
Co-training, but which is more exploratory by nature, is <i style='mso-bidi-font-style:
normal'>Co-testing </i>(</span><span lang=EN-US style='color:blue'>Muslea,
Minton and Knoblock 2000</span><span lang=EN-US>, </span><span lang=EN-US
style='color:blue'>2006</span><span lang=EN-US>). Cotesting is an iterative
process that works under the same premises as active learning in general, that
is, it has access to a small set of labeled data, as well as a large set of
unlabeled data. Co-testing proceeds by first learning a hypothesis using each
view of the data, then asking a human annotator to label the unlabeled
instances for which the view classifiers’ predictions disagree on labels. Such
instances are called the <i style='mso-bidi-font-style:normal'>contention set </i>or
<i style='mso-bidi-font-style:normal'>contention point</i>. The newly annotated
instances are then added to the set of labeled training data.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:12.2pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Muslea,
Minton and Knoblock </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2006</span><span lang=EN-US>) introduce a number of variants
of Co-testing. The variations are due to choices of how to select the instances
to query the human annotator about, as well as how the final hypothesis is to
be created. The former choice pertains to step 4 in Figure </span><span
lang=EN-US style='color:red'>2.3</span><span lang=EN-US>, and the options are:</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.55pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Na¨&#305;ve </span></i><span lang=EN-US>C Randomly choose an example from
the contention set. This strategy is suitable when using a base learner that
does not provide confidence estimates for the predictions it makes.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.55pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Aggressive </span></i><span lang=EN-US>C Choose to query the example
in the contention set for which the least confident classifier makes the most
confident prediction. This strategy is suitable for situations where there is
(almost) no noise.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:12.25pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Conservative </span></i><span lang=EN-US>C Choose to query the
example in the contention set for which the classifiers makes predictions that
are as close as possible. This strategy is suitable for noisy domains.</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US
style='color:blue'>Muslea, Minton and Knoblock </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) also present three
ways of forming the final hypothesis in Co-testing, that is, the classifier to
output at the end of the process. These ways concern step 8 in Figure </span><span
lang=EN-US style='color:red'>2.3</span><span lang=EN-US>:</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.15pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Weighted vote </span></i><span lang=EN-US>C Combine the votes of all
view classifiers, weighted according to each classifier’s confidence estimate
of its own prediction.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.15pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Majority vote </span></i><span lang=EN-US>C Combine the votes of all
view classifiers so that the label predicted by the majority of the classifiers
is used.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.65pt;
margin-left:27.25pt;text-indent:-21.8pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Winner-takes-all </span></i><span lang=EN-US>C The final classifier
is the one learned in the view that made the least amount of mistakes
throughout the learning process.</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Previously
described multi-view approaches to learning all relied on the views being <i
style='mso-bidi-font-style:normal'>strong</i>. Analogously to the notion of a
strong learner in ensemblebased methods, a strong view is a view which provides
enough information about the data for a learner to learn a given target
concept. Conversely, there are <i style='mso-bidi-font-style:normal'>weak </i>views,
that is, views that are not by themselves enough to learn a given target
concept, but rather a concept more general or more specific than the concept of
interest. In the light of weak views, </span><span lang=EN-US style='color:
blue'>Muslea, Minton and Knoblock </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) redefine the notion
of contention point, or contention set, to be the set of examples, from the
unlabeled data, for which the strong view classifiers disagree. Muslea and
colleagues introduce two ways of making use of weak views in Co-testing. The
first is as tie-breakers when two strong views predict a different label for an
unlabeled instance, and the second is by using a weak view in conjunction with
two strong views in such a way that the weak view would indicate a mistake made
by both strong views. The latter is done by detecting the set of contention
points for which the weak view disagrees with both strong views. Then the next
example to ask the human annotator to label, is the one for which the weak view
makes the most confident prediction. This example is likely to represent a mistake
made by both strong views, </span><span lang=EN-US style='color:blue'>Muslea,
Minton and Knoblock </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2006</span><span lang=EN-US>) claim, and leads to faster
convergence of the classifiers learned.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The experimental set-up in used by </span><span lang=EN-US
style='color:blue'>Muslea, Minton and Knoblock </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) is targeted at
testing whether Co-testing converges faster than the corresponding single-view
active learning methods when applied to problems in which there exist several
views. The tasks are of two types: classification, including text
classification, advertisement removal, and discourse tree parsing; and wrapper
induction. For all tasks in their empirical validation, </span><span
lang=EN-US style='color:blue'>Muslea, Minton and Knoblock </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>) show that the Co-testing variants employed outperform the
single-view, state-of-the art approaches to active learning that were also part
of the investigation.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The advantages of using Co-testing include its ability to use any
base learner suitable for the particular problem at hand. This seems to be a
rather unique feature among the active learning methods reviewed in this
chapter. Nevertheless, there are a couple of concerns regarding the
shortcomings of Co-testing aired by Muslea and colleagues that need to be
mentioned. Both concerns relate to the use of multiple views. The first is that
Co-testing can obviously only be applied to tasks where there exist two views.
The other of their concerns is that the views of data have to be uncorrelated
(independent) and compatible, that is, the same assumption brought up by </span><span
lang=EN-US style='color:blue'>Blum and Mitchell </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) in their original
work on Co-training. If the views are correlated, the classifier learned in
each view may turn out so similar that no contention set is generated when both
view classifiers are run on the unlabeled data. In this case, there is no way
of selecting an example for which to query the human annotator. If the views are
incompatible, the view classifiers will learn two different tasks and the
process will not converge.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:18.75pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Just as with
committee-based methods, utilizing multiple views seems like a viable way to
make the most of a situation that is caused by having access to a small amount
of labeled data. Though, the question remains of how one should proceed in
order to define multiple views in a way so that the they are uncorrelated and
compatible with the target concept.</span></p>

<h3 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 68.65pt'><span
lang=EN-US>2.3.1<span style='mso-tab-count:1'> </span>How to split a feature
set</span></h3>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Acquiring a
feature set split adhering to the assumptions underlying the multi-view
learning paradigm is a non-trivial task requiring knowledge about the learning
situation, the data, and the domain. Two approaches to the view detection and
validation problem form the extreme ends of a scale; randomly splitting a given
feature set and hope for the best at one end, and adopting a very cautions view
on the matter by computing the correlation and compatibility for every
combination of the features in a given set at the other end.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Nigam and Ghani </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2000</span><span lang=EN-US>) report on randomly
splitting the feature set for tasks where there exists no natural division of
the features into separate views. The task is text categorization, using Na¨&#305;ve
Bayes as base learner. Nigam and Ghani argue that, if the features are sufficiently
redundant, and one can identify a reasonable division of the feature set, the
application of Co-training using such a non-natural feature set split should
exhibit the same advantages as applying Co-training to a task in which there
exists natural views.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Concerning the ability to learn a desired target concept in each
view, </span><span lang=EN-US style='color:blue'>Collins and Singer </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>1999</span><span
lang=EN-US>) introduce a Co-training algorithm that utilizes a boosting-like
step to optimize the compatibility between the views. The algorithm, called
CoBoost, favors hypotheses that predict the same label for most of the
unlabeled examples.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Muslea, Minton and Knoblock </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2002a</span><span
lang=EN-US>) suggest a method for validating the compatibility of views, that
is, given two views, the method should provide an answer to whether each view is
enough to learn the target concept. The way Muslea and colleagues go about is
by collecting information about a number of tasks solved using the same views
as the ones under investigation. Given this information, a classifier for
discriminating between the tasks in which the views were compatible, and the
tasks in which they were not, is trained and applied. The obvious drawback of
this approach is that the first time the question of whether a set of views is
compatible with a desired concept, the method by </span><span lang=EN-US
style='color:blue'>Muslea, Minton and Knoblock </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2002a</span><span lang=EN-US>) is not applicable.
In all fairness, it should be noted that the authors clearly state the proposed
view validation method to be but one step towards automatic view detection.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Muslea, Minton and Knoblock </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2002b</span><span
lang=EN-US>) investigate view dependence and compatibility for several
semi-supervised algorithms along with one algorithm combining semi-supervised
and active learning (Co-testing), CoEMT. The conclusions made by Muslea and
colleagues are interesting, albeit perhaps not surprising. For instance, the
performance of all multi-view algorithms under investigation degrades as the
views used become less compatible, that is, when the target concept learned by
view classifiers are not the same in each view. A second, very important point
made in (</span><span lang=EN-US style='color:blue'>Muslea, Minton and Knoblock
2002a</span><span lang=EN-US>) is that the robustness of the active learning
algorithm with respect to view correlation is suggested to be due to the usage
of an active learning component; being able to ask a teacher for advice seems
to compensate for the views not being entirely uncorrelated.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Balcan, Blum and Yang </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) argue that, for the
kind of Co-training presented by </span><span lang=EN-US style='color:blue'>Blum
and Mitchell </span><span lang=EN-US>(</span><span lang=EN-US style='color:
blue'>1998</span><span lang=EN-US>), the original assumption of conditional
independence between views is overly strong. Balcan and colleagues claim that
the views do not have to denote conditionally independent ways of representing
the task to be useful to Co-training, if the base learner is able to correctly
learn the target concept using positive training examples only.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Zhang et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) present an
algorithm called <i style='mso-bidi-font-style:normal'>Correlation and
Compatibility based Feature Partitioner, CCFP </i>for computing, from a given
set of features, independent and compatible views. CCFP makes use of feature
pair-wise symmetric uncertainty and feature-wise information gain to detect the
views. Zhang and colleagues point out that in order to employ CCFP, a fairly
large number of labeled examples are needed. Exactly how large a number is
required is undisclosed. CCFP is empirically tested and </span><span
lang=EN-US style='color:blue'>Zhang et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) report on somewhat
satisfactory results.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Finally, one way of circumventing the assumptions of view
independence and compatibility is simply not to employ different views at all.
Goldman and Zhou (</span><span lang=EN-US style='color:blue'>2000</span><span
lang=EN-US>) propose a variant of Co-training which assumes no redundant views
of the data; instead, a single view is used by differently biased base
learners. </span><span lang=EN-US style='color:blue'>Chawla and Karakoulas </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2005</span><span
lang=EN-US>) make empirical studies on this version of Co-training. Since the
methods of interest to the present thesis are those containing elements of
active learning, which the original Co-training approach does not, the
single-view multiple-learner approach to Co-training will not be further
elaborated.</span></p>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.15pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>In the literature, there is to my knowledge no report on automatic
means</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>to discover, from
a given set of features, views that satisfy the original Cotraining assumptions
concerning independence and compatibility. Although the Co-training method as
such is not of primary interest to this thesis, offsprings of the method are.
The main approach to active multi-view learning, Co-testing and its variants
rely on the same assumptions as does Co-training. </span><span lang=EN-US
style='color:blue'>Muslea, Minton and Knoblock </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2002b</span><span lang=EN-US>) show that
violating the compatibility assumption in the context of an active learning
component, does not necessarily lead to failure; the active learner might have
a stabilizing effect on the divergence of the target concept learned in each
view. As regards the conditional independence assumption made by </span><span
lang=EN-US style='color:blue'>Blum and Mitchell </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>), subsequent work (</span><span
lang=EN-US style='color:blue'>Balcan, Blum and Yang 2005</span><span
lang=EN-US>) shows that the independence assumption is too strong, and that
iterative Co-training, and thus also Co-testing, works under a less rigid
assumption concerning the expansion of the data in the learning process.</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection5>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>16<br clear=all
style='mso-special-character:line-break;page-break-before:always'>
</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 3</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Quantifying disagreement</span></h1>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.3pt;
margin-left:-.25pt'><span lang=EN-US>So far, the issue of disagreement has been
mentioned but deliberately not elaborated on. The algorithms for query by
committee and its variants (Figure </span><span lang=EN-US style='color:red'>2.2</span><span
lang=EN-US>) as well as those utilizing multiple views of data (Figure </span><span
lang=EN-US style='color:red'>2.3</span><span lang=EN-US>) all contain steps in
which the disagreement between classifiers concerning instances has to be
quantified. In a two-class case, such quantification is simply the difference
between the positive and negative votes given by the classifiers. Typically,
instances for which the distribution of votes is homogeneous is selected for
querying. Generalizing disagreement to a multi-class case is not trivial. </span><span
lang=EN-US style='color:blue'>K¨orner and Wrobel </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) empirically test
four approaches to measuring disagreement between members of a committee of
classifiers in a multi-class setting. The active learning approaches they
consider are query by bagging, query by boosting, ActiveDecorate, and
Co-testing. The disagreement measures investigated are <i style='mso-bidi-font-style:
normal'>margin-based disagreement</i>, <i style='mso-bidi-font-style:normal'>uncertainty
sampling-based disagreement</i>, <i style='mso-bidi-font-style:normal'>entropy-based
disagreement</i>, and finally a measure of their own dubbed <i
style='mso-bidi-font-style:normal'>specific disagreement</i>. </span><span
lang=EN-US style='color:blue'>K¨orner and Wrobel </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) strongly advocate
the use of margin-based disagreement as a standard approach to quantifying
disagreement in an ensemble-based setting.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:25.85pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Sections </span><span
lang=EN-US style='color:red'>3.1 </span><span lang=EN-US>through </span><span
lang=EN-US style='color:red'>3.4 </span><span lang=EN-US>deal with the
different measures used by K¨orner and Wrobel (</span><span lang=EN-US
style='color:blue'>2006</span><span lang=EN-US>), followed by the treatment of <i
style='mso-bidi-font-style:normal'>Kullback-Leibler divergence, Jensen-Shannon
divergence, vote entropy</i>, and <i style='mso-bidi-font-style:normal'>F-complement
</i>in Sections </span><span lang=EN-US style='color:red'>3.5 </span><span
lang=EN-US>to </span><span lang=EN-US style='color:red'>3.8</span><span
lang=EN-US>.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 86.05pt'><span
lang=EN-US>3.1<span style='mso-tab-count:1'> </span>Margin-based disagreement</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.75pt;
margin-left:-.25pt'><span lang=EN-US>Margin, as introduced by </span><span
lang=EN-US style='color:blue'>Abe and Mamitsuka </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) for binary
classification in query by boosting, is defined as the difference between the
number of votes given to the two labels. Abe and Mamitsuka base their notion of
margins on the finding that a classifier exhibiting a large margin when trained
on labeled data, performs better on unseen data than does a classifier that has
a smaller margin on the training data (</span><span lang=EN-US
style='color:blue'>Schapire et al. 1998</span><span lang=EN-US>). </span><span
lang=EN-US style='color:blue'>Melville</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>17</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.7pt;
margin-left:-.25pt'><span lang=EN-US>and Mooney (</span><span lang=EN-US
style='color:blue'>2004</span><span lang=EN-US>) extend Abe and Mamitsuka’s
definition of margin to include class probabilities given by the individual
committee members. </span><span lang=EN-US style='color:blue'>K¨orner and
Wrobel </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>), in turn, generalize Melville and Mooney’s definition of margin to
account for the multi-class setting as well. The margin-based disagreement for
a given instance is the difference between the first and second highest
probabilities with which an ensemble of classifiers assigns different class
labels to the instance.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:33.95pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>For example, if an
instance <i style='mso-bidi-font-style:normal'>X </i>is classified by committee
member 1 as belonging to class <i style='mso-bidi-font-style:normal'>A </i>with
a probability of 0.7, by member 2 as belonging class <i style='mso-bidi-font-style:
normal'>B </i>with a probability of 0.2, and by member 3 to class <i
style='mso-bidi-font-style:normal'>C </i>with 0.3, then the margin for <i
style='mso-bidi-font-style:normal'>X </i>is <i style='mso-bidi-font-style:normal'>A</i>&#8722;<i
style='mso-bidi-font-style:normal'>C </i>= 0<i style='mso-bidi-font-style:normal'>.</i>4.
If instance <i style='mso-bidi-font-style:normal'>Y </i>is classified by member
1 as class <i style='mso-bidi-font-style:normal'>A </i>with a probability of
0.8, by member 2 as class <i style='mso-bidi-font-style:normal'>B </i>with a
probability of 0.9, and by member 3 as class <i style='mso-bidi-font-style:
normal'>C </i>with 0.6, then the margin for <i style='mso-bidi-font-style:normal'>Y
</i>is <i style='mso-bidi-font-style:normal'>B </i>&#8722;<i style='mso-bidi-font-style:
normal'>A </i>= 0<i style='mso-bidi-font-style:normal'>.</i>1. A low value on
the margin indicates that the ensemble disagree regarding the classification of
the instance, while a high value signals agreement. Thus, in the above example,
instance <i style='mso-bidi-font-style:normal'>Y </i>is more informative than
instance <i style='mso-bidi-font-style:normal'>X</i>.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:10.7pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 184.2pt'><span lang=EN-US>3.2<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Uncertainty
sampling-based disagreement</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:33.5pt;
margin-left:-.25pt'><span lang=EN-US>Originally, uncertainty sampling is a
method used in conjunction with single classifiers, rather than ensembles of
classifiers (see Section </span><span lang=EN-US style='color:red'>2.1</span><span
lang=EN-US>). </span><span lang=EN-US style='color:blue'>K¨orner and Wrobel </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>), though, prefer to view it as another way of generalizing the
binary margin approach introduced in the previous section. In uncertainty
sampling, instances are preferred that receives the lowest <i style='mso-bidi-font-style:
normal'>class probability </i>estimate by the ensemble of classifiers. The
class probability is the highest probability with which an instance is assigned
a class label.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:12.05pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 136.75pt'><span lang=EN-US>3.3<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Entropy-based
disagreement</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.55pt;
margin-left:-.25pt'><span lang=EN-US>The entropy-based disagreement used in (</span><span
lang=EN-US style='color:blue'>K¨orner and Wrobel 2006</span><span lang=EN-US>)
is what they refer to as the ordinary entropy measure (<i style='mso-bidi-font-style:
normal'>information entropy </i>or <i style='mso-bidi-font-style:normal'>Shannon
entropy</i>) first introduced by </span><span lang=EN-US style='color:blue'>Shannon
</span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>1948</span><span
lang=EN-US>). The entropy <i style='mso-bidi-font-style:normal'>H </i>of a
random variable <i style='mso-bidi-font-style:normal'>X </i>is defined in
equation </span><span lang=EN-US style='color:red'>3.1 </span><span lang=EN-US>in
the case of a <i style='mso-bidi-font-style:normal'>c </i>class problem, that
is, where <i style='mso-bidi-font-style:normal'>X </i>can take on values <i
style='mso-bidi-font-style:normal'>x</i><sub>1</sub><i style='mso-bidi-font-style:
normal'>,...,x<sub>c</sub></i>.</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:80.0pt;
margin-bottom:6.5pt;margin-left:66.0pt;text-align:center;line-height:107%'><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:8.0pt;
mso-bidi-font-size:11.0pt;line-height:107%'>c</span></i></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.15pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 179.35pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US>H</span></i><span
lang=EN-US>(<i style='mso-bidi-font-style:normal'>X</i>) = &#8722;</span><sup><span
lang=EN-US style='font-size:17.0pt;mso-bidi-font-size:11.0pt;line-height:110%'>X</span></sup><i
style='mso-bidi-font-style:normal'><span lang=EN-US>p</span></i><span
lang=EN-US>(<i style='mso-bidi-font-style:normal'>x<sub>i</sub></i>)log<sub>2</sub><i
style='mso-bidi-font-style:normal'>p</i>(<i style='mso-bidi-font-style:normal'>x<sub>i</sub></i>)<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.1)</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:80.2pt;
margin-bottom:17.05pt;margin-left:66.2pt;text-align:center;line-height:110%'><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:8.0pt;
mso-bidi-font-size:11.0pt;line-height:110%'>i</span></i><span lang=EN-US
style='font-size:8.0pt;mso-bidi-font-size:11.0pt;line-height:110%'>=1</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:24.0pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>p</i>(<i
style='mso-bidi-font-style:normal'>x<sub>i</sub></i>) denotes the probability
of <i style='mso-bidi-font-style:normal'>x<sub>i</sub></i>. A lower value on <i
style='mso-bidi-font-style:normal'>H</i>(<i style='mso-bidi-font-style:normal'>X</i>)
indicates less confusion or less uncertainty concerning the outcome of the
value of <i style='mso-bidi-font-style:normal'>X</i>. 19</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 139.5pt'><span
lang=EN-US>3.4<span style='mso-tab-count:1'> </span>The K¨orner-Wrobel
disagreement measure</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:11.35pt;
margin-left:-.25pt'><span lang=EN-US>The <i style='mso-bidi-font-style:normal'>specific
disagreement </i>measure, here referred to as the <i style='mso-bidi-font-style:
normal'>K¨orner-Wrobel disagreement measure </i>is a combination of margin-based
disagreement <i style='mso-bidi-font-style:normal'>M </i>and the maximal class
probability <i style='mso-bidi-font-style:normal'>P </i>over classes <i
style='mso-bidi-font-style:normal'>C </i>in order to indicate disagreement on a
narrow subset of class values. The K¨orner-Wrobel disagreement measure, <i
style='mso-bidi-font-style:normal'>R</i>, is defined in equation </span><span
lang=EN-US style='color:red'>3.2</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:7.2pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 132.05pt 299.65pt'><span lang=EN-US style='font-family:
"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56424"
 o:spid="_x0000_i1033" type="#_x0000_t75" style='width:99.75pt;height:25.5pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image006.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=133 height=34
src="SICS-T--2009-06--SE.files/image007.gif" v:shapes="Picture_x0020_56424"><![endif]></span><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.2)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:25.2pt;
margin-left:-.25pt'><span lang=EN-US style='color:blue'>K¨orner and Wrobel </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>) find that the success of the specific disagreement measure is
closely related to which active learning method is used. Throughout the
experiments conducted by K¨orner and Wrobel, those configurations utilizing
specific disagreement as selection metric perform less well than the
margin-based and entropy-based disagreement measures investigated.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 87.3pt'><span
lang=EN-US>3.5<span style='mso-tab-count:1'> </span>Kullback-Leibler divergence</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:10.35pt;
margin-left:-.25pt'><span lang=EN-US>The Kullback-Leibler divergence (<i
style='mso-bidi-font-style:normal'>KL-divergence, information divergence</i>)
is a non-negative measure of the divergence between two probability
distributions <i style='mso-bidi-font-style:normal'>p </i>and <i
style='mso-bidi-font-style:normal'>q </i>in the same event space <i
style='mso-bidi-font-style:normal'>X </i>= {<i style='mso-bidi-font-style:normal'>x</i><sub>1</sub><i
style='mso-bidi-font-style:normal'>,...,x<sub>c</sub></i>}. The KL-divergence,
denoted <i style='mso-bidi-font-style:normal'>D</i>(・ k ・), between two
probability distributions <i style='mso-bidi-font-style:normal'>p </i>and <i
style='mso-bidi-font-style:normal'>q </i>is defined in equation </span><span
lang=EN-US style='color:red'>3.3</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:5.55pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:110%;tab-stops:center 132.8pt 299.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56425"
 o:spid="_x0000_i1032" type="#_x0000_t75" style='width:135pt;height:30.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image008.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=180 height=41
src="SICS-T--2009-06--SE.files/image009.gif" v:shapes="Picture_x0020_56425"><![endif]></span><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.3)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.65pt;
margin-left:-.25pt'><span lang=EN-US>A high value on the KL-divergence
indicates a large difference between the distributions <i style='mso-bidi-font-style:
normal'>p </i>and <i style='mso-bidi-font-style:normal'>q</i>. A zero-valued
KL-divergence signals full agreement, that is <i style='mso-bidi-font-style:
normal'>p </i>and <i style='mso-bidi-font-style:normal'>q </i>are equivalent.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:10.35pt;
margin-left:-.75pt;text-indent:16.95pt'><i style='mso-bidi-font-style:normal'><span
lang=EN-US>Kullback-Leibler divergence to the mean </span></i><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>Pereira, Tishby and Lee 1993</span><span
lang=EN-US>) quantifies the disagreement between committee members; it is the
average KL-divergence between each distribution and the mean of all
distributions. KL-divergence to the mean, <i style='mso-bidi-font-style:normal'>D<sub>mean
</sub></i>for an instance <i style='mso-bidi-font-style:normal'>x </i>is
defined in equation </span><span lang=EN-US style='color:red'>3.4</span><span
lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:7.65pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:110%;tab-stops:center 130.45pt 299.6pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56426"
 o:spid="_x0000_i1031" type="#_x0000_t75" style='width:173.25pt;height:33pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image010.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=231 height=44
src="SICS-T--2009-06--SE.files/image011.gif" v:shapes="Picture_x0020_56426"><![endif]></span><span
lang=EN-US>))<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.4)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.35pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>k
</i>is the number of classifiers involved, <i style='mso-bidi-font-style:normal'>p<sub>i</sub></i>(<i
style='mso-bidi-font-style:normal'>x</i>) is the probability distribution for <i
style='mso-bidi-font-style:normal'>x </i>given by the <i style='mso-bidi-font-style:
normal'>i</i>-th classifier, <i style='mso-bidi-font-style:normal'>p<sub>mean</sub></i>(<i
style='mso-bidi-font-style:normal'>x</i>) is the mean probability distribution
of all <i style='mso-bidi-font-style:normal'>k </i>classifiers for <i
style='mso-bidi-font-style:normal'>x</i>, and <i style='mso-bidi-font-style:
normal'>D</i>(・ k ・) is the KL-divergence as defined in equation </span><span
lang=EN-US style='color:red'>3.3</span><span lang=EN-US>.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>KL-divergence, as well as KL-divergence to the mean, has been used
for detecting and measuring disagreement in active learning, see for instance (</span><span
lang=EN-US style='color:blue'>McCallum and Nigam 1998</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Becker et al. 2005</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Becker and Osborne</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:21.4pt;
margin-left:0cm;text-indent:0cm;line-height:119%'><span lang=EN-US
style='color:blue'>2005</span><span lang=EN-US>)</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 133.4pt'><span
lang=EN-US>3.6<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Jensen-Shannon
divergence</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:15.4pt;
margin-left:-.25pt'><span lang=EN-US>The <i style='mso-bidi-font-style:normal'>Jensen-Shannon
divergence</i>, (<i style='mso-bidi-font-style:normal'>JSD</i>) is a
symmetrized and smoothed version of KL-divergence, which essentially means that
it can be used to measure the distance between two probability distributions (</span><span
lang=EN-US style='color:blue'>Lin 1991</span><span lang=EN-US>). The
Jensen-Shannon divergence for two distributions <i style='mso-bidi-font-style:
normal'>p </i>and <i style='mso-bidi-font-style:normal'>q </i>is defined in
equation </span><span lang=EN-US style='color:red'>3.5</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:9.3pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
107%;tab-stops:center 179.35pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US>JSD</span></i><span
lang=EN-US>(<i style='mso-bidi-font-style:normal'>p,q</i>) = <i
style='mso-bidi-font-style:normal'>H</i>(<i style='mso-bidi-font-style:normal'>w</i><sub>1</sub><i
style='mso-bidi-font-style:normal'>p </i>+ <i style='mso-bidi-font-style:normal'>w</i><sub>2</sub><i
style='mso-bidi-font-style:normal'>q</i>) &#8722; <i style='mso-bidi-font-style:normal'>w</i><sub>1</sub><i
style='mso-bidi-font-style:normal'>H</i>(<i style='mso-bidi-font-style:normal'>p</i>)
&#8722; <i style='mso-bidi-font-style:normal'>w</i><sub>2</sub><i style='mso-bidi-font-style:
normal'>H</i>(<i style='mso-bidi-font-style:normal'>q</i>)<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.5)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.6pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>w</i><sub>1
</sub>and <i style='mso-bidi-font-style:normal'>w</i><sub>2 </sub>are the
weights of the probability distributions such that <i style='mso-bidi-font-style:
normal'>w</i><sub>1</sub><i style='mso-bidi-font-style:normal'>,w</i><sub>2 </sub>≥
0 and <i style='mso-bidi-font-style:normal'>w</i><sub>1 </sub>+ <i
style='mso-bidi-font-style:normal'>w</i><sub>2 </sub>= 1, and <i
style='mso-bidi-font-style:normal'>H </i>is the Shannon entropy as defined in
equation </span><span lang=EN-US style='color:red'>3.1</span><span lang=EN-US>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.65pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Lin
</span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>1991</span><span
lang=EN-US>) defines the Jensen-Shannon divergence for <i style='mso-bidi-font-style:
normal'>k </i>distributions as in equation </span><span lang=EN-US
style='color:red'>3.6</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:6.5pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
107%;tab-stops:center 184.5pt 239.7pt'><span lang=EN-US style='font-family:
"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:8.0pt;
mso-bidi-font-size:11.0pt;line-height:107%'>k<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>k</span></i></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:0cm;margin-left:0cm;margin-bottom:.0001pt;text-align:left;
text-indent:0cm;line-height:107%;tab-stops:center 179.35pt right 358.65pt'><span
lang=EN-US style='font-family:"Calibri",sans-serif;mso-fareast-font-family:
Calibri'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US>JSD</span></i><span
lang=EN-US>(<i style='mso-bidi-font-style:normal'>p</i><sub>1</sub><i
style='mso-bidi-font-style:normal'>,...,p<sub>k</sub></i>) = <i
style='mso-bidi-font-style:normal'>H</i>(</span><sup><span lang=EN-US
style='font-size:17.0pt;mso-bidi-font-size:11.0pt;line-height:107%'>X</span></sup><i
style='mso-bidi-font-style:normal'><span lang=EN-US>w<sub>i</sub>p<sub>i</sub></span></i><span
lang=EN-US>) &#8722; </span><sup><span lang=EN-US style='font-size:17.0pt;mso-bidi-font-size:
11.0pt;line-height:107%'>X</span></sup><i style='mso-bidi-font-style:normal'><span
lang=EN-US>w<sub>i</sub>H</span></i><span lang=EN-US>(<i style='mso-bidi-font-style:
normal'>p<sub>i</sub></i>)<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.6)</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:8.2pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 184.6pt 239.8pt'><span lang=EN-US style='font-family:
"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:8.0pt;
mso-bidi-font-size:11.0pt;line-height:110%'>i</span></i><span lang=EN-US
style='font-size:8.0pt;mso-bidi-font-size:11.0pt;line-height:110%'>=1<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><i
style='mso-bidi-font-style:normal'>i</i>=1</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:22.3pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>p<sub>i
</sub></i>is the class probability distribution given by the <i
style='mso-bidi-font-style:normal'>i</i>-th classifier for a given instance, <i
style='mso-bidi-font-style:normal'>w<sub>i </sub></i>is the vote weight of the <i
style='mso-bidi-font-style:normal'>i</i>-th classifier among the <i
style='mso-bidi-font-style:normal'>k </i>classifiers in the set, and <i
style='mso-bidi-font-style:normal'>H</i>(<i style='mso-bidi-font-style:normal'>p</i>)
is the entropy as defined in equation </span><span lang=EN-US style='color:
red'>3.1</span><span lang=EN-US>. A Jensen-Shannon divergence value of zero
signals complete agreement among the classifiers in the committee, while
correspondingly, increasingly larger JSD values indicate larger disagreement.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 82.65pt'><span
lang=EN-US>3.7<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Vote
entropy</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.2pt;
margin-left:-.25pt'><span lang=EN-US style='color:blue'>Engelson and Dagan </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>1996</span><span
lang=EN-US>) use <i style='mso-bidi-font-style:normal'>vote entropy </i>for
quantifying the disagreement within a committee of classifiers used for active
learning in a partof-speech tagging task. Disagreement <i style='mso-bidi-font-style:
normal'>V E </i>for an instance <i style='mso-bidi-font-style:normal'>e </i>based
on vote entropy is defined as in equation </span><span lang=EN-US
style='color:red'>3.7</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:5.5pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 180.25pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56427"
 o:spid="_x0000_i1030" type="#_x0000_t75" style='width:184.5pt;height:34.5pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image012.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=246 height=46
src="SICS-T--2009-06--SE.files/image013.gif" v:shapes="Picture_x0020_56427"><![endif]></span><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.7)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:21.95pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>k
</i>is the number of members in the committee, and <i style='mso-bidi-font-style:
normal'>V </i>(<i style='mso-bidi-font-style:normal'>l<sub>i</sub>,e</i>) is
the number of members assigning label <i style='mso-bidi-font-style:normal'>l<sub>i
</sub></i>to instance <i style='mso-bidi-font-style:normal'>e</i>. Vote entropy
is computed per tagged unit, for instance per token. In tasks where the
smallest tagged 21</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.75pt;
margin-left:-.25pt'><span lang=EN-US>unit is but a part of the construction
under consideration, for instance in phrase chunking where each phrase may
contain one or more tokens, the vote entropy of the larger unit is computed as
the mean of the vote entropy of its parts (</span><span lang=EN-US
style='color:blue'>Ngai and Yarowsky 2000</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>Tomanek, Wermter and Hahn 2007a</span><span
lang=EN-US>).</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><i
style='mso-bidi-font-style:normal'><span lang=EN-US>Weighted vote entropy </span></i><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>Olsson 2008</span><span
lang=EN-US>) is applicable only in committeebased settings where the individual
members of the committee has received weights reflecting their performance. For
instance, this is the case with Boosting (Section </span><span lang=EN-US
style='color:red'>2.2.1</span><span lang=EN-US>), but not with Decorate
(Section </span><span lang=EN-US style='color:red'>2.2.2</span><span
lang=EN-US>).</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Weighted vote entropy
is calculated similarly to the original vote entropy metric (equation </span><span
lang=EN-US style='color:red'>3.7</span><span lang=EN-US>), but with the weight
of the committee members substituted for the votes. Disagreement based on weighted
vote entropy <i style='mso-bidi-font-style:normal'>WV E </i>for an instance <i
style='mso-bidi-font-style:normal'>e </i>is defined as in equation </span><span
lang=EN-US style='color:red'>3.8</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:11.65pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:110%;tab-stops:center 132.05pt 299.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56428"
 o:spid="_x0000_i1029" type="#_x0000_t75" style='width:207pt;height:33.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image014.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=276 height=45
src="SICS-T--2009-06--SE.files/image015.gif" v:shapes="Picture_x0020_56428"><![endif]></span><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.8)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:25.05pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>w
</i>is the sum of the weights of all committee members, and <i
style='mso-bidi-font-style:normal'>W</i>(<i style='mso-bidi-font-style:normal'>c<sub>i</sub>,e</i>)
is the sum of the weights of the committee members assigning label <i
style='mso-bidi-font-style:normal'>c<sub>i </sub></i>to instance <i
style='mso-bidi-font-style:normal'>e</i>.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 39.25pt'><span
lang=EN-US>3.8<span style='mso-tab-count:1'> </span>F-complement</span></h2>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US
style='color:blue'>Ngai and Yarowsky </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2000</span><span lang=EN-US>) compare the vote
entropy measure, as introduced by Engelson and Dagan, with their own measure
called <i style='mso-bidi-font-style:normal'>F-complement </i>(<i
style='mso-bidi-font-style:normal'>Fscore complement</i>). Disagreement <i
style='mso-bidi-font-style:normal'>FC </i>concerning the classification of data
<i style='mso-bidi-font-style:normal'>e </i>among a committee based on the
F-complement is defined as in equation</span></p>

<p class=MsoNormal align=left style='margin-bottom:11.0pt;text-align:left;
line-height:107%'><span lang=EN-US style='color:red'>3.9</span><span
lang=EN-US>.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:7.05pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:110%;tab-stops:center 130.1pt 299.6pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56429"
 o:spid="_x0000_i1028" type="#_x0000_t75" style='width:183.75pt;height:30.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image016.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=245 height=41
src="SICS-T--2009-06--SE.files/image017.gif" v:shapes="Picture_x0020_56429"><![endif]></span><span
lang=EN-US>)))<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.9)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.7pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>K
</i>is the committee of classifiers, <i style='mso-bidi-font-style:normal'>k<sub>i
</sub></i>and <i style='mso-bidi-font-style:normal'>k<sub>j </sub></i>are
members of <i style='mso-bidi-font-style:normal'>K</i>, and</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.75pt;
margin-left:-.25pt'><i style='mso-bidi-font-style:normal'><span lang=EN-US>F<sub>β</sub></span></i><sub><span
lang=EN-US>=1</span></sub><span lang=EN-US>(<i style='mso-bidi-font-style:normal'>k<sub>i</sub></i>(<i
style='mso-bidi-font-style:normal'>e</i>)<i style='mso-bidi-font-style:normal'>,k<sub>j</sub></i>(<i
style='mso-bidi-font-style:normal'>e</i>)) is the F-score, <i style='mso-bidi-font-style:
normal'>F<sub>β</sub></i><sub>=1 </sub>(defined in equation </span><span
lang=EN-US style='color:red'>3.10</span><span lang=EN-US>), of the classifier <i
style='mso-bidi-font-style:normal'>k<sub>i</sub></i>’s labelling of the data <i
style='mso-bidi-font-style:normal'>e </i>relative to the evaluation of <i
style='mso-bidi-font-style:normal'>k<sub>j </sub></i>on <i style='mso-bidi-font-style:
normal'>e</i>.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.3pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>In calculating the
F-complement, the output of one of the classifiers in the committee is used as
the answer key, against which all other committee members’ results are compared
and measured (in terms of F-score).</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Ngai and Yarowsky </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2000</span><span lang=EN-US>) find that the task
they are interested in, base noun phrase chunking, using F-complement to select
instances to annotate performs slightly better than using vote entropy. </span><span
lang=EN-US style='color:blue'>Hachey, Alex and Becker </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) use F-complement to
select sentences for named entity annotation; they point out that the
F-complement is equivalent to the inter-annotator agreement between |<i
style='mso-bidi-font-style:normal'>K</i>| classifiers.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.2pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>The F-score is the
harmonic mean of <i style='mso-bidi-font-style:normal'>precision </i>(equation </span><span
lang=EN-US style='color:red'>3.11</span><span lang=EN-US>) and <i
style='mso-bidi-font-style:normal'>recall </i>(equation </span><span
lang=EN-US style='color:red'>3.12</span><span lang=EN-US>) such that</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:3.25pt;margin-left:0cm;text-align:left;text-indent:0cm;
line-height:110%;tab-stops:center 179.8pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US style='mso-no-proof:yes'><!--[if gte vml 1]><v:shape id="Picture_x0020_56430"
 o:spid="_x0000_i1027" type="#_x0000_t75" style='width:106.5pt;height:27pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="SICS-T--2009-06--SE.files/image018.png" o:title=""/>
</v:shape><![endif]--><![if !vml]><img width=142 height=36
src="SICS-T--2009-06--SE.files/image019.gif" v:shapes="Picture_x0020_56430"><![endif]></span><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.10)</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.65pt;
margin-left:-.25pt'><span lang=EN-US>where <i style='mso-bidi-font-style:normal'>β
</i>is a constant used for determining the influence of precision over recall,
or vice-versa. <i style='mso-bidi-font-style:normal'>β </i>is usually set to 1,
which is commonly referred to as <i style='mso-bidi-font-style:normal'>F</i><sub>1
</sub>or <i style='mso-bidi-font-style:normal'>F<sub>β</sub></i><sub>=1</sub>.
Precision, <i style='mso-bidi-font-style:normal'>P</i>, is defined as the ratio
between the number of correctly classified instances and the number of
classified instances:</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:87.9pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>TP</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.15pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 155.05pt 193.4pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US>P </span></i><span
lang=EN-US>=<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span> SHAPE
<span style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span
style='mso-element:field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_50467" o:spid="_x0000_s1029" style='width:43.2pt;height:.45pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="5484,55" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF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">
 <v:shape id="Shape_x0020_2831" o:spid="_x0000_s1030" style='position:absolute;
  width:5484;height:0;visibility:visible;mso-wrap-style:square;v-text-anchor:top'
  coordsize="548412,0" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQCizca0xwAAAN0AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI/BasMw
EETvhf6D2EIvoZHthuI4UUJoSdNLD3H9AYu1sZ1YKyOpjvv3VaDQ4zAzb5j1djK9GMn5zrKCdJ6A
IK6t7rhRUH3tn3IQPiBr7C2Tgh/ysN3c362x0PbKRxrL0IgIYV+ggjaEoZDS1y0Z9HM7EEfvZJ3B
EKVrpHZ4jXDTyyxJXqTBjuNCiwO9tlRfym+jwO3eL6Vf7sfPc5W/LQ7ZNEuro1KPD9NuBSLQFP7D
f+0PrSDLn1O4vYlPQG5+AQAA//8DAFBLAQItABQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAAAAA
AAAAAAAAAAAAAABbQ29udGVudF9UeXBlc10ueG1sUEsBAi0AFAAGAAgAAAAhAFr0LFu/AAAAFQEA
AAsAAAAAAAAAAAAAAAAAHwEAAF9yZWxzLy5yZWxzUEsBAi0AFAAGAAgAAAAhAKLNxrTHAAAA3QAA
AA8AAAAAAAAAAAAAAAAABwIAAGRycy9kb3ducmV2LnhtbFBLBQYAAAAAAwADALcAAAD7AgAAAAA=
" path="m,l548412,e" filled="f" strokeweight=".15381mm">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,548412,0"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=59 height=2
src="SICS-T--2009-06--SE.files/image020.gif" v:shapes="Group_x0020_50467 Shape_x0020_2831"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1026" type="#_x0000_t75" style='width:43.2pt;
 height:.45pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.11)</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:87.9pt;
margin-bottom:3.1pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>TP + FP</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:7.85pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Recall, <i
style='mso-bidi-font-style:normal'>R</i>, is defined as the ratio between the
number of correctly classified instances and the total number of instances:</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:88.05pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>TP</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:.15pt;margin-left:0cm;text-align:left;text-indent:0cm;line-height:
110%;tab-stops:center 154.65pt 193.3pt right 358.65pt'><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri'><span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US>R </span></i><span
lang=EN-US>=<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp; </span></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><span style='mso-element:field-begin;mso-field-lock:yes'></span> SHAPE
<span style='mso-spacerun:yes'>&nbsp;</span>\* MERGEFORMAT <span
style='mso-element:field-separator'></span></span><![endif]--><span lang=EN-US><!--[if gte vml 1]><v:group
 id="Group_x0020_50468" o:spid="_x0000_s1027" style='width:43.95pt;height:.45pt;
 mso-position-horizontal-relative:char;mso-position-vertical-relative:line'
 coordsize="5580,55" o:gfxdata="UEsDBBQABgAIAAAAIQC2gziS/gAAAOEBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbJSRQU7DMBBF
90jcwfIWJU67QAgl6YK0S0CoHGBkTxKLZGx5TGhvj5O2G0SRWNoz/78nu9wcxkFMGNg6quQqL6RA
0s5Y6ir5vt9lD1JwBDIwOMJKHpHlpr69KfdHjyxSmriSfYz+USnWPY7AufNIadK6MEJMx9ApD/oD
OlTrorhX2lFEilmcO2RdNtjC5xDF9pCuTyYBB5bi6bQ4syoJ3g9WQ0ymaiLzg5KdCXlKLjvcW893
SUOqXwnz5DrgnHtJTxOsQfEKIT7DmDSUCaxw7Rqn8787ZsmRM9e2VmPeBN4uqYvTtW7jvijg9N/y
JsXecLq0q+WD6m8AAAD//wMAUEsDBBQABgAIAAAAIQA4/SH/1gAAAJQBAAALAAAAX3JlbHMvLnJl
bHOkkMFqwzAMhu+DvYPRfXGawxijTi+j0GvpHsDYimMaW0Yy2fr2M4PBMnrbUb/Q94l/f/hMi1qR
JVI2sOt6UJgd+ZiDgffL8ekFlFSbvV0oo4EbChzGx4f9GRdb25HMsYhqlCwG5lrLq9biZkxWOiqY
22YiTra2kYMu1l1tQD30/bPm3wwYN0x18gb45AdQl1tp5j/sFB2T0FQ7R0nTNEV3j6o9feQzro1i
OWA14Fm+Q8a1a8+Bvu/d/dMb2JY5uiPbhG/ktn4cqGU/er3pcvwCAAD//wMAUEsDBBQABgAIAAAA
IQCq7X+1XwIAANEFAAAOAAAAZHJzL2Uyb0RvYy54bWykVEtv2zAMvg/YfxB8X+xkdRsYsXtYt1yG
rVi7H6DIkm1AL0hKnPz7UfQjQYr2kOXgUBQfHz9S3DwelSQH7nxndJksF1lCuGam7nRTJn9ff3xZ
J8QHqmsqjeZlcuI+eaw+f9r0tuAr0xpZc0cgiPZFb8ukDcEWaepZyxX1C2O5hkthnKIBjq5Ja0d7
iK5kusqy+7Q3rrbOMO49aJ+Gy6TC+EJwFn4L4XkgskwAW8Cvw+8uftNqQ4vGUdt2bIRBb0ChaKch
6RzqiQZK9q57E0p1zBlvRFgwo1IjRMc41gDVLLOrarbO7C3W0hR9Y2eagNornm4Oy34dnh3p6jLJ
s7t7aJamCtqEmcmgAop62xRguXX2xT67UdEMp1j1UTgV/6EeckRyTzO5/BgIA2Wer7NVnhAGV3n+
9WGgnrXQnzc+rP3+gVc6JUwjrhlGb2GE/Jkl/38svbTUciTfx9pHllbru+VEEloQ1CAlaDcT5AsP
XN3CDk7lXCQt2N6HLTfIMD389GEY2nqSaDtJ7Kgn0cHofzj0loboFwFGkfRzi6JKmQN/NXgZrtoD
yM63Ul9aTT2eug+mgwEIMUm1GQVMDPJlaVIPGGA0CKOwC4SkAR+V6gIsCdkp2DCrhyybCJIaAsa2
D0yjFE6SR9hS/+ECBhsmb4lBvGt236QjBxpXAf7iCCJEMI0+opNy9sre9YqmVNqWjrHGMGMCDDlG
ipYct9B1WDaiGVYRPGhYTtNCAkizE8IyOsz+GtYoJryoNoo7U5/waSIh8A6QGtwbiGjccXExXZ7R
6ryJq38AAAD//wMAUEsDBBQABgAIAAAAIQBzWLG72QAAAAEBAAAPAAAAZHJzL2Rvd25yZXYueG1s
TI9BS8NAEIXvgv9hGcGb3URR25hNKUU9FcFWEG/T7DQJzc6G7DZJ/72jF70MPN7jvW/y5eRaNVAf
Gs8G0lkCirj0tuHKwMfu5WYOKkRki61nMnCmAMvi8iLHzPqR32nYxkpJCYcMDdQxdpnWoazJYZj5
jli8g+8dRpF9pW2Po5S7Vt8myYN22LAs1NjRuqbyuD05A68jjqu79HnYHA/r89fu/u1zk5Ix11fT
6glUpCn+heEHX9ChEKa9P7ENqjUgj8TfK978cQFqb2ABusj1f/LiGwAA//8DAFBLAQItABQABgAI
AAAAIQC2gziS/gAAAOEBAAATAAAAAAAAAAAAAAAAAAAAAABbQ29udGVudF9UeXBlc10ueG1sUEsB
Ai0AFAAGAAgAAAAhADj9If/WAAAAlAEAAAsAAAAAAAAAAAAAAAAALwEAAF9yZWxzLy5yZWxzUEsB
Ai0AFAAGAAgAAAAhAKrtf7VfAgAA0QUAAA4AAAAAAAAAAAAAAAAALgIAAGRycy9lMm9Eb2MueG1s
UEsBAi0AFAAGAAgAAAAhAHNYsbvZAAAAAQEAAA8AAAAAAAAAAAAAAAAAuQQAAGRycy9kb3ducmV2
LnhtbFBLBQYAAAAABAAEAPMAAAC/BQAAAAA=
">
 <v:shape id="Shape_x0020_2841" o:spid="_x0000_s1028" style='position:absolute;
  width:5580;height:0;visibility:visible;mso-wrap-style:square;v-text-anchor:top'
  coordsize="558025,0" o:gfxdata="UEsDBBQABgAIAAAAIQDb4fbL7gAAAIUBAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbHyQz07DMAyH
70i8Q+QralM4IITa7kDhCAiNB7ASt43WOlEcyvb2pNu4IODoPz9/n1xv9vOkForiPDdwXVagiI23
jocG3rdPxR0oScgWJ8/UwIEENu3lRb09BBKV0ywNjCmFe63FjDSjlD4Q50nv44wpl3HQAc0OB9I3
VXWrjedEnIq03oC27qjHjympx31un0wiTQLq4bS4shrAECZnMGVTvbD9QSnOhDInjzsyuiBXWQP0
r4R18jfgnHvJr4nOknrFmJ5xzhraRtHWf3Kkpfz/yGo5S+H73hkquyhdjr3R8m2lj09svwAAAP//
AwBQSwMEFAAGAAgAAAAhAFr0LFu/AAAAFQEAAAsAAABfcmVscy8ucmVsc2zPwWrDMAwG4Ptg72B0
X5TuUMaI01uh19I+gLGVxCy2jGSy9e1nemrHjpL4P0nD4SetZiPRyNnCruvBUPYcYp4tXC/Htw8w
Wl0ObuVMFm6kcBhfX4Yzra62kC6xqGlKVgtLreUTUf1CyWnHhXKbTCzJ1VbKjMX5LzcTvvf9HuXR
gPHJNKdgQU5hB+ZyK23zHztFL6w81c5zQp6m6P9TMfB3PtPWFCczVQtB9N4U2rp2HOA44NMz4y8A
AAD//wMAUEsDBBQABgAIAAAAIQALP9PpxgAAAN0AAAAPAAAAZHJzL2Rvd25yZXYueG1sRI/NasMw
EITvhb6D2EBvjRy3pMaNEkr/CL3FDiHHjbW1TayVa6mx8vZRoNDjMDPfMItVMJ040eBaywpm0wQE
cWV1y7WCbflxn4FwHlljZ5kUnMnBanl7s8Bc25E3dCp8LSKEXY4KGu/7XEpXNWTQTW1PHL1vOxj0
UQ611AOOEW46mSbJXBpsOS402NNrQ9Wx+DUKsnT8KT/fvnYl74uH8ukQwvw9KHU3CS/PIDwF/x/+
a6+1gjR7nMH1TXwCcnkBAAD//wMAUEsBAi0AFAAGAAgAAAAhANvh9svuAAAAhQEAABMAAAAAAAAA
AAAAAAAAAAAAAFtDb250ZW50X1R5cGVzXS54bWxQSwECLQAUAAYACAAAACEAWvQsW78AAAAVAQAA
CwAAAAAAAAAAAAAAAAAfAQAAX3JlbHMvLnJlbHNQSwECLQAUAAYACAAAACEACz/T6cYAAADdAAAA
DwAAAAAAAAAAAAAAAAAHAgAAZHJzL2Rvd25yZXYueG1sUEsFBgAAAAADAAMAtwAAAPoCAAAAAA==
" path="m,l558025,e" filled="f" strokeweight=".15381mm">
  <v:stroke miterlimit="83231f" joinstyle="miter"/>
  <v:path arrowok="t" textboxrect="0,0,558025,0"/>
 </v:shape><w:wrap type="none"/>
 <w:anchorlock/>
</v:group><![endif]--><![if !vml]><img width=61 height=2
src="SICS-T--2009-06--SE.files/image021.gif" v:shapes="Group_x0020_50468 Shape_x0020_2841"><![endif]></span><!--[if mso & !supportInlineShapes & supportFields]><span
lang=EN-US><v:shape id="_x0000_i1025" type="#_x0000_t75" style='width:43.95pt;
 height:.45pt'>
 <v:imagedata croptop="-65520f" cropbottom="65520f"/>
</v:shape><span style='mso-element:field-end'></span></span><![endif]--><span
lang=EN-US><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>(3.12)</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:88.05pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>TP + FN<br clear=all style='mso-special-character:line-break;
page-break-before:always'>
</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 4</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Data access</span></h1>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:25.65pt;
margin-left:-.25pt'><span lang=EN-US>There are several issues related to the
way that the active learner has access to the data from which it learns. First
of all, the seed set of instances used to start the process (e.g., item 1 in
Figure </span><span lang=EN-US style='color:red'>2.1</span><span lang=EN-US>)
may have impact on how the learning proceeds (Section </span><span lang=EN-US
style='color:red'>4.1</span><span lang=EN-US>). Further, the way that the
learner is provided access to the unlabeled data has implications for the
overall setting of the learning process; is the data made available as a stream
or as a pool (Section </span><span lang=EN-US style='color:red'>4.2</span><span
lang=EN-US>)? A related question is whether a batch or singletons of unlabeled
instances is processed in each learning iteration (Section </span><span
lang=EN-US style='color:red'>4.3</span><span lang=EN-US>).</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:7.85pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 64.95pt'><span lang=EN-US>4.1<span
style='mso-tab-count:1'> </span>Selecting the seed set</span></h2>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>The initial set
of labeled data used in active learning should be representative with respect
to the classes that the learning process is to handle. Omitting a class from
the initial seed set might result in trouble further down the road when the
learner fits the classes it knows of with the unlabeled data it sees. Instances
that would have been informative to the learner can go unnoticed simply because
the learner, when selecting informative instances, treat instances from several
classes as if they belong to one and the same class.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.35pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>A related issue is
that of instance distribution. Given that the learner is fed a seed set of data
in which all classes are represented, the number of examples of each class
plays a crucial role in whether the learner is able to properly learn how to
distinguish between the classes. Should the distribution of instances in the
seed set mirror the (expected) distribution of instances in the unlabeled set?</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>In the context of text
categorization, McCallum and Nigam (</span><span lang=EN-US style='color:blue'>1998</span><span
lang=EN-US>) report on a method that allows for starting the active learning
process without any labeled examples at all. They select instances (documents)
from the region of the pool of unlabeled data that has the highest density. A
dense region is one in which the distance (based on Kullback-Leibler
divergence, defined</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>23</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.5pt;
margin-left:-.25pt'><span lang=EN-US>in equation </span><span lang=EN-US
style='color:red'>3.3</span><span lang=EN-US>) between documents is small. </span><span
lang=EN-US style='color:blue'>McCallum and Nigam </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) combine expectation-maximization
(</span><span lang=EN-US style='color:blue'>Dempster, Laird and Rubin 1977</span><span
lang=EN-US>) and active learning in a pool-based setting (Section </span><span
lang=EN-US style='color:red'>4.2</span><span lang=EN-US>); their results show
that the learning in this particular setting might in fact benefit from being
initiated without the use of a labeled seed set of documents.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.6pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Tomanek,
Wermter and Hahn </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2007b</span><span lang=EN-US>) describe a three-step
approach to compiling a seed set for the task of named entity recognition in
the biomedical domain. In the first step, a list of as many named entities as
possible is gathered, the source being either a human domain expert, or some
other trusted source. The second step involves matching the listed named
entities against the sentences in the unlabeled document pool. Third, the
sentences are ranked according to the number of diverse matches of named
entities to include in the seed set. </span><span lang=EN-US style='color:blue'>Tomanek,
Wermter and Hahn </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2007b</span><span lang=EN-US>) report results from running
the same active learning experiment with three different seed sets; a randomly
selected set, a set tuned according to the above mentioned method, and no seed
set at all. Though the learning curves seem to converge, initially the tuned
seed set clearly contributes to a better progression of learning.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Olsson </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) compares random
selection of documents to include in the seed set for a named entity recognition
task, to a seed set made up from documents selected based on their distance
from the centroids of clusters obtained by K-means clustering. Olsson concludes
that neither query by uncertainty, nor query by committee produced better
classification results when the seed sets were selected based on clustering.
However, the clustering approach taken did affect the variance of the
performance of the classifier learned in a positive way.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:26.9pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>In experimental
settings, a work-around to the seed set selection problem is to run the active
learning process several times, and then present the average of the results
achieved in each round. Averaging rounds, combined with randomly selecting a
fairly large initial seed set C where its size is possibly related to the
number of classes C might prove enough to circumvent the seed set problem when
conducting controlled experiments. How the issue is best addressed in a live
setting is not clear.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 182.4pt'><span
lang=EN-US>4.2<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Stream-based
and pool-based data access</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:20.85pt;
margin-left:-.25pt'><span lang=EN-US>There are two ways in which a learner is
provided access to data, either from a stream, or by selecting from a pool. In
stream-based selection used by, among others, </span><span lang=EN-US
style='color:blue'>Liere and Tadepalli </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1997</span><span lang=EN-US>) and McCallum and
Nigam (</span><span lang=EN-US style='color:blue'>1998</span><span lang=EN-US>),
unlabeled instances are presented one by one. For each instance, the learner
has to decide whether the instance is so informative that is should be
annotated by the teacher. In the pool-based case C used by for example </span><span
lang=EN-US style='color:blue'>Lewis and Gale </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1994</span><span lang=EN-US>), and </span><span
lang=EN-US style='color:blue'>McCallum and Nigam </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) C the learner has
25</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:26.9pt;
margin-left:-.25pt'><span lang=EN-US>access to a set of instances and has the
opportunity to compare and select instances regardless of their individual
order.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 108.35pt'><span
lang=EN-US>4.3<span style='mso-tab-count:1'> </span>Processing singletons and
batches</span></h2>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>The issue of
whether the learner should process a single instance or a batch of instances in
each iteration has impact on the speed of the active learning process. Since in
each iteration, the base learner generates classifiers based on the labeled
training data available, adding only one instance at a time slows the overall
learning process down. If, on the other hand, a batch of instances is added,
the amount of data added to the training set in each iteration increases, and
the learning process progresses faster. The prototypical active learning algorithms
presented previously, see Figures </span><span lang=EN-US style='color:red'>2.1</span><span
lang=EN-US>, </span><span lang=EN-US style='color:red'>2.2 </span><span
lang=EN-US>and </span><span lang=EN-US style='color:red'>2.3</span><span
lang=EN-US>, respectively, do not advocate one approach over the other. In
practice though, it is clearly easier to fit singleton instance processing with
the algorithms. Selecting a good batch of instances is non-trivial since each
instance in the batch needs to be informative, both with respect to the other
instances in the batch, as well as with respect to the set of unlabeled data as
a whole.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>While investigating active learning for named entity recognition, Shen
et al. (</span><span lang=EN-US style='color:blue'>2004</span><span lang=EN-US>)
use the notions of <i style='mso-bidi-font-style:normal'>informativeness</i>, <i
style='mso-bidi-font-style:normal'>representativeness</i>, and <i
style='mso-bidi-font-style:normal'>diversity</i>, and propose scoring functions
for incorporating these measures when selecting batches of examples from the
pool of unlabeled data. Informativeness relates to the uncertainty of an
instance, representativeness relates an instance to the majority of instances,
while diversity is a means to avoid repetition among instances, and thus
maximize the training utility of a batch.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.55pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>The pool-based
approach to text classification adopted by McCallum and Nigam (</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) facilitates the use
of what they refer to as <i style='mso-bidi-font-style:normal'>density-weighted
pool-based sampling</i>. The density in a region around a given document C to
be understood as representativeness in the vocabulary of </span><span
lang=EN-US style='color:blue'>Shen et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2004</span><span lang=EN-US>) C is quantified as
the average distance between that document and all other documents. </span><span
lang=EN-US style='color:blue'>McCallum and Nigam </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) combine density
with disagreement, calculated as the Kullback-Leibler divergence (equation </span><span
lang=EN-US style='color:red'>3.3</span><span lang=EN-US>), such that the
document with the largest product of density and Kullback-Leibler divergence is
selected as a representative of many other documents, while retaining a
confident committee disagreement. McCallum and Nigam show that density-weighted
pool-based sampling used in conjunction with KullbackLeibler divergence yields
significantly better results than the same experiments conducted with
pool-based Kullback-Leibler divergence, stream-based Kullback-Leibler
divergence, stream-based vote entropy, and random sampling.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Tang, Luo and Roukos </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2002</span><span lang=EN-US>) also experiment
with representativeness, or density, albeit in a different setting; that of
statistical parsing. They propose to use clustering of the unlabeled data set
based on the distance between sentences, the resulting clusters are then used
to compute the density of examples. Tang and colleagues define the distance
between two sentences based on the parse trees corresponding to the sentences.
A parse tree can be uniquely represented by a series of events, each of which
is constituted by a parse action and its context. Sentence similarity is
calculated as the Hamming edit distance between two sequences of events. The
Hamming distance measures the number of substitutions (or errors) required to
turn one sequence into the other (</span><span lang=EN-US style='color:blue'>Hamming
1950</span><span lang=EN-US>). The results reported by </span><span lang=EN-US
style='color:blue'>Tang, Luo and Roukos </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2002</span><span lang=EN-US>) show that taking
density into account helps in keeping the amount of training data needed down,
compared to random sampling.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Brinker </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2003</span><span lang=EN-US>) addresses the issue
of incorporating a diversity measure when selecting batches of instances.
Brinker’s work is carried out with Support Vector Machines, and his batch
selection method is accordingly described in terms of feature vectors in a
high-dimensional space. When selecting single instances for querying, an
instance with a minimal distance to the classification hyperplane is usually
favored, since choosing such an instance will result in halving the version
space. When selecting several unlabeled instances, </span><span lang=EN-US
style='color:blue'>Brinker </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2003</span><span lang=EN-US>) argue that picking instances
such that their angles are maximal with respect to each other, rather than
relative to the decision hyperplane, is a batch selection technique which is
both computationally cheap and scalable to large data sets. </span><span
lang=EN-US style='color:blue'>Brinker </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2003</span><span lang=EN-US>) conducts empirical
investigations using a number of UCI data sets (</span><span lang=EN-US
style='color:blue'>Asuncion and Newman 2007</span><span lang=EN-US>), and
reports results indicating that previously approaches to active learning with
Support Vector Machines are outperformed by his batch selection strategy.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Hoi, Jin and Lyu </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) present work on
large-scale text categorization in which a batch of documents is selected in
each learning iteration. Hoi and colleagues report on the development of an
active learning algorithm utilizing logistic regression as base learner,
capable of selecting several documents at a time, while minimizing the
redundancy in the selected batch. The uncertainty of the logistic regression
model is measured using Fisher matrix information, something which is claimed
to allow for the batch selection problem to be re-cast as an optimization
problem in which instances from the unlabeled pool are selected in such as way
that the Fisher information is maximized. The notion of Fisher information and
Fisher matrix is described by </span><span lang=EN-US style='color:blue'>Hoi,
Jin and Lyu </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>). Hoi and colleagues carry out experiments on several document
collections, using a range of learning methods, and conclude that their active
learning approach equipped with the batch selection method is more effective
than the margin-based active learning methods tested.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 5</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>The creation and re-use of
annotated data</span></h1>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:24.9pt;
margin-left:-.25pt'><span lang=EN-US>Under some circumstances, active learning
can evidently be used to identify the most informative units in a corpus. What
really takes place is the reordering, and elicitation, of available examples
highly biased towards the preferences of the base learner and task in effect.
The data produced is often viewed as a side effect of an annotation process
that is really intended to produce a classifier with as little human effort as
possible. An effect of this classifier-centric view of active learning is that
the resulting annotated data may be hard to re-use by base learners other than
the one used in the active learning process. Research addressing the
re-usability of actively annotated data is reviewed in Section </span><span
lang=EN-US style='color:red'>5.1</span><span lang=EN-US>. Further, a number of
research efforts adopting a more data-centric approach to active learning in
that it is used as a technique when creating annotated corpora are described in
Section </span><span lang=EN-US style='color:red'>5.2</span><span lang=EN-US>.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 29.8pt'><span
lang=EN-US>5.1<span style='mso-tab-count:1'> </span>Data re-use</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.8pt;
margin-left:-.25pt'><span lang=EN-US style='color:blue'>Baldridge and Osborne </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2004</span><span
lang=EN-US>) use active learning to create a corpus on which to train parsers.
In doing that, their principal worry is whether the selected material will be
useful if used with a base learner different than the one used to select the
data. Indeed, for their particular task, they find that the gains of using
active learning may turn out minimal or even negative. The reason lies in how
complex it is for a human annotator to assign parse trees to the selected
sentences. In response to this finding, Baldridge and Osborne formulate a
strategy involving semi-automatic labeling to operate in concert with active
learning. The semi-automatic technique makes use of the fact that the parser
used can provide ranked partial parses, of which the ones with higher
probability than chance is presented to the user in a dropdown list. </span><span
lang=EN-US style='color:blue'>Baldridge and Osborne </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2004</span><span lang=EN-US>) conclude that <i
style='mso-bidi-font-style:normal'>n</i>-best automation</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>27</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.65pt;
margin-left:-.25pt'><span lang=EN-US>can be used to increase the possibility of
the annotations produced being re-usable.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.6pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Tomanek,
Wermter and Hahn </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2007a</span><span lang=EN-US>) conduct two experiments addressing
the re-usability of training material obtained by employing active learning to
annotate named entities in a biomedical domain. In their first experiment, the
base learners used for selecting data C called <i style='mso-bidi-font-style:
normal'>selectors </i>C and the learning schemes used for testing the data C
called <i style='mso-bidi-font-style:normal'>testers </i>C are varied. By
keeping the feature set fixed and using the best selector, generated by a
conditional random field base learner, Tomanek and colleagues show that feeding
the tester with data generated by faster, albeit worse performing selectors
based on maximum entropy and na¨&#305;ve Bayes, still yield results far better than
passive learning. Comparable results are reported for the variation of the
tester’s base learner.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.55pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>In the second
experiment outlined in </span><span lang=EN-US style='color:blue'>Tomanek, Wermter
and Hahn 2007a</span><span lang=EN-US>, the feature sets used by the selectors
are reduced, while that of the tester remain fixed and full. The three reduced
feature sets contain, in turn, all but the syntactic features, all but the
syntactic and morphological features, and finally, only orthographic features.
A committee of conditional random field selectors employs each of the three
reduced feature sets. </span><span lang=EN-US style='color:blue'>Tomanek,
Wermter and Hahn </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2007a</span><span lang=EN-US>) show that, even when using
selectors in concert with the most reduced feature set, a tester (also based on
conditional random fields) still can make use of the data and generate results
better than those resulting from passive learning.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:26.85pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Vlachos
</span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>) approaches the production of marked-up data slightly different
than the rest; instead of employing active learning for the purpose of
selecting sentences to annotate with names, Vlachos uses it to select the
automatically inserted named entity annotations that need to be corrected.
Vlachos finds that his approach to use active learning to select errors to
correct outperforms active learning for selecting instances to annotate in all
cases except for the one where very noisy data had been used to train the
initial pre-tagger. </span><span lang=EN-US style='color:blue'>Vlachos </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2006</span><span
lang=EN-US>) points out that his approach is likely to yield data more
re-usable than the data created using “ordinary” active learning. This claim is
based on the observation that the corpus produced by Vlachos’s method contains
all data that the initial corpus does, and although only parts of the data is
manually corrected, the errors in the uncorrected parts are possibly
non-significant to a machine learner. Since the distribution of the data in the
resulting corpus is the same as in the original one, the former is likely to be
as re-usable as the latter.</span></p>

<h2 style='margin-left:-.75pt;text-indent:0cm;tab-stops:center 171.0pt'><span
lang=EN-US>5.2<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Active
learning as annotation support</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:20.85pt;
margin-left:-.25pt'><span lang=EN-US style='color:blue'>Olsson </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) present a three-stage method called BootMark for bootstrapping the
marking up of named entities in documents. What differentiates 29</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>BootMark from
other similar methods, such as Melita (</span><span lang=EN-US
style='color:blue'>Ciravegna, Petrelli and Wilks 2002</span><span lang=EN-US>),
is that BootMark makes use of active learning to select entire documents to
annotate. The BootMark method consists of three phases: (1) Manual annotation
of a set of documents; (2) Bootstrapping C active machine learning for the
purpose of selecting which document to annotate next; (3) The remaining
unannotated documents of the original corpus are marked up using pre-tagging
with revision. Olsson identifies and emprically investigates five emerging
issues pertaining to the realization of BootMark. The issues are related to:
the characteristics of the named entity recognition task and the base learners
used in conjunction with it; the constitution of the set of documents annotated
by the human annotator in phase one in order to start the bootstrapping process;
the active selection of the documents to annotate; the monitoring and
termination of the active learning; and the applicability of the actively
learned named entity recognizer as a pre-tagger for annotating unlabeled data.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Chklovski and Mihalcea </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2002</span><span lang=EN-US>) direct their
efforts towards collecting a word sense-tagged corpus involving the general
public as annotators by using the World Wide Web as communications channel. The
active learning component used to select instances to tag is made up from two
classifiers created by two different base learners. An instance is picked out
for annotation if the labels assigned to it by the classifiers are not equal.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>In setting up the experiment, Chklovski and Mihalcea faced two
rather uncommon challenges; that of ensuring the quality of annotations
provided by a potentially very large and uncontrolled selection of annotators,
and that of drawing attention to their task in order to bring in enough
annotators. Chklovski and Mihalcea dealt with the first challenge by limiting
the number of tags of an item to two, and also by limiting the number of tags
assigned to an item to one per contributor. The authors proposed to make the
tagging task “game-like”, including awarding prizes to the winners, in order
for people to be inclined to contribute. </span><span lang=EN-US
style='color:blue'>Mihalcea and Chklovski </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2003</span><span lang=EN-US>) report that after
the first nine months of being available on the web, their system had collected
90000 high-quality tagged items.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.45pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Tomanek et al. (</span><span
lang=EN-US style='color:blue'>2007a</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>2007b</span><span lang=EN-US>) describe the Jena
annotation environment (Jane), a client-server-based workbench for
accommodating and managing the labeling of texts. The task described by Tomanek
and colleagues is that of named entity recognition in the immunogenetics
domain, although they point out that other types of tasks are possible too.
Jane contains tools supporting a single annotator, as well as for managing
teams of annotators. The administrative tool facilitating the latter include
modules for managing users, creating and editing projects, monitoring the
annotation progress and inter-annotator agreement, and deploying the data once
the annotation of it is completed. Single annotators have the option to choose
focused annotation, that is, being supported by a server-side active annotation
module that selects the sentences to be marked-up. Active learning is realized
as query by committee employing three different base learners C conditional
random fields (</span><span lang=EN-US style='color:blue'>Lafferty, McCallum
and Pereira 2001</span><span lang=EN-US>), maximum entropy, and Na¨&#305;ve Bayes C
with vote entropy as disagreement quantification. Tomanek et al. (</span><span
lang=EN-US style='color:blue'>2007a</span><span lang=EN-US>; </span><span
lang=EN-US style='color:blue'>2007b</span><span lang=EN-US>) perform a
real-world annotation experiment, indicating a reduction in the number of
annotations with between 50% and 75%. One conclusion drawn from the experiment
is that active learning is particularly advantageous when the instances of
interest are sparsely distributed in the texts. The density of named entities,
that is, the number of entities per sentence, in the corpus produced in the
experiment is almost 15 times greater than the density of names in the test
corpus. Another set of conclusions is realized as a list of requirements for
facilitating deployment of active learning in practical circumstances:</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.65pt;
margin-left:27.25pt;text-indent:-10.9pt;mso-list:l4 level1 lfo6'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>the turn-around time for
selecting what to annotate needs to be kept short;</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.65pt;
margin-left:27.25pt;text-indent:-10.9pt;mso-list:l4 level1 lfo6'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>the data produced in the
annotation process need to be re-usable by other machine learners; and,</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.35pt;
margin-left:27.25pt;text-indent:-10.9pt;mso-list:l4 level1 lfo6'><![if !supportLists]><span
lang=EN-US><span style='mso-list:Ignore'>&#8226;<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;
</span></span></span><![endif]><span lang=EN-US>the criterion for stopping the
active learning needs to be sensitive to the progress of the performance in the
annotation process.</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>The requirements
list presented by Tomanek and colleagues is one of several manifestations of
increasing awareness in the research community of the conditions under which
the human annotators operate. Concerns are raised regarding the usefulness of
the resulting data sets for tasks other than that which originally created the
data.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:26.4pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 6</span></b></p>

<h1 style='margin-top:0cm;margin-right:0cm;margin-bottom:25.15pt;margin-left:
-.25pt'><span lang=EN-US>Cost-sensitive active learning</span></h1>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.4pt;
margin-left:-.25pt'><span lang=EN-US>The performance of active learning is
often measured along the lines of how much data is required to reach some given
performance compared to reaching the same performance by learning from randomly
sampled data from the same set of unlabeled data. However, only taking the
amount of data into consideration is not always appropriate, e.g., when some
types of data are harder for the user to annotate than others, or when the
acquisition of certain types of unlabeled examples is expensive. In these
cases, it is necessary to model the cost of learning as being attributed to
other characteristics of the data and the annotation situation than simply the
sheer amount of data processed. Cost in this sense is typically derived from
monetary, temporal, or effort-based issues. A cost model should reflect the
constraints currently in effect; for instance, if annotator time is more
important than the presumed cognitive load put on the user, then the overall
time should take precedence in the evaluation of the plausibility of the method
under consideration. If on the other hand a high cognitive load causes the
users to produce annotations with too high a variance, resulting in poor data
quality, then the user situation may have to take precedence over monetary
issues in order to allow for the recruitment and training of more personnel.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.25pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Using a scale
mimicking the actions made by the user when annotating the data is one way of
facilitating a finer grained measurement of the learning progress. For
instance, </span><span lang=EN-US style='color:blue'>Hwa </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2000</span><span
lang=EN-US>) uses the number of brackets required for marking up parse trees in
the training data as a measure of cost, rather than using the sheer number of
sentences available. </span><span lang=EN-US style='color:blue'>Hwa </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2000</span><span
lang=EN-US>) uses active learning to select sentences to be marked-up with
parse trees. The corpus constructed is then used to induce a statistical
grammar. The sample selection method used by Hwa is based on a single learner
using sentence length and tree entropy as means to select the sentences to
annotate. Hwa points out that creating a statistical grammar (parser) is a
complex task which differs from the kind of classification commonly addressed
by active learning in two significant respects; where a classifier selects
labels from a fixed set</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>31</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>of categories
for each instance, in parsing, every instance has a different set of possible
parse trees. While most classification problems concern a rather limited set of
classes, the number of parse trees may be exponential with respect to the
length of the sentence to parse. These two characteristics have bearing towards
the complexity of the task faced by the human annotator acting as oracle in the
learning process. Hwa’s aim is to minimize the amount of annotation required by
the human in terms of the number of sentences processed, as well as in terms of
the number of brackets denoting the structure of each sentence.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Osborne and Baldridge (</span><span lang=EN-US style='color:blue'>Osborne
and Baldridge 2004</span><span lang=EN-US>; </span><span lang=EN-US
style='color:blue'>Baldridge and Osborne 2004</span><span lang=EN-US>)
distinguish between <i style='mso-bidi-font-style:normal'>unit cost </i>and <i
style='mso-bidi-font-style:normal'>discriminant cost </i>in their work on
ensemble-based active learning for selecting parses. In their setting, unit
cost is the absolute number of sentences selected in the learning process.
Discriminant cost assigns a variable cost per sentence and concerns the
decision an annotator has to make concerning the example parse trees provided by
the system.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Culotta et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) design their system
so that segmentation decisions are converted into classification tasks. They
use what they refer to as Expected Number of User Actions (ENUA) to measure the
effort required by the user to label each example in an information extraction
setting. The ENUA is computed as a function of four atomic labeling actions,
corresponding to annotating the start and end boundaries, the type of a field
to be extracted, as well as to an option for the user to select the correct
annotation among <i style='mso-bidi-font-style:normal'>k </i>predicted ones.
The use of ENUA reflects the authors’ goal with the system; to reduce the total
number of actions required by the user. </span><span lang=EN-US
style='color:blue'>Culotta et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2006</span><span lang=EN-US>) notice that there
is a trade-off between how large <i style='mso-bidi-font-style:normal'>k </i>is,
that is, how many choices the user is presented with, and the reduction in
amount of required user actions caused by introducing the multiple-choice
selection.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>It seems reasonable to assume that, on average, it must be harder to
annotate the units provided by active learning, than it is annotating units
randomly drawn from the same corpus simply because the former is, by
definition, more informative. Along these lines, </span><span lang=EN-US
style='color:blue'>Hachey, Alex and Becker </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2005</span><span lang=EN-US>) find that the three
selection metrics they used in a live annotation experiment yield three
distinct annotation time per token/data size curves. Hachey and colleagues
measure maximum Kullback-Leibler divergence, average Kullback-Leibler
divergence and F-complement for selecting the sentences in which the annotators
are to mark up named entities. </span><span lang=EN-US style='color:blue'>Hachey,
Alex and Becker </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2005</span><span lang=EN-US>) demonstrate that the time
spent on marking up an example is correlated with its informativeness.
Similarly, in the experiments conducted by </span><span lang=EN-US
style='color:blue'>Ringger et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2007</span><span lang=EN-US>), the selection
metric resulting in the best performance in terms of amount of data needed to
reach a given accuracy, is also the one demanding the most attention from the
user; the amount of corrections made by the oracle is clearly larger for the
most complex selection method used.</span></p>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:20.65pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>33</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Sometimes failure according to one cost model is success when
measured under different model. </span><span lang=EN-US style='color:blue'>Ganchev,
Pereira and Mandel </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2007</span><span lang=EN-US>) design their process so as to
require binary decisions only, as opposed to full annotations/corrections, from
the user. They show that the effectiveness of their approach is inferior to
that of learning from fully manually annotated data. Their semi-automatic
method requires the annotator to process more data than he would have had if he
had chosen to manually annotate it. This is an effect of reducing the load on
the user to binary decisions. On the other hand, Ganchev and colleagues show
that less effort is required by the annotator to produce annotations of a
quality superior to that of manually tagging. In all, </span><span lang=EN-US
style='color:blue'>Ganchev, Pereira and Mandel </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2007</span><span lang=EN-US>) conclude that, in
the conducted experiments, the suggested semi-automatic method reduced
annotation time by 58%.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Haertel et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) show that the
active learning strategy which performs the best depends on how the annotation
cost is measured. They examine the performance of query by uncertainty and
query by committee for the task of part-of-speech tagging under a number of
cost models. The models used include what Haertel and colleagues refer to as an
hourly cost model. As an example of how a cost model can be used in their
particular setting, </span><span lang=EN-US style='color:blue'>Haertel et al. </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) show that when a low tag accuracy is required, random selection of
what to annotate is cheapest according to the hourly cost model. On the other
hand, query by uncertainty is cost-effective (compared to a random baseline)
starting at around 91% tag accuracy, while query by committee is more effective
than both the baseline and query by uncertainty at tag accuracies starting at
around 80%.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Settles, Craven and Friedland </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) describe four active learning tasks involving human annotators;
the annotating of entities and relations from news-wire text, the
classification of images in a content-based image retrieval system, the
annotation of speculative vs. definite statements in biomedical text, and the
annotation of contact information from email text. Burr and colleagues
investigate various aspects of the time required to annotate data, and use that
as the cost model in their experiments. They ask questions such as: Are annotation
times variable for a given task or domain? Do times vary from one annotator to
the next? Can we improve active learning by utilizing cost information? Burr
and colleagues conclude that the cost, i.e., time, can vary considerably across
the instances of data annotated, that active learning can fail if the
variability of the cost of instances are not taken into account, and that, in
some domains, it is possible to learn to predict the annotation costs.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Castro et al. </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) investigate what
they refer to as human active learning. They conduct a series of experiments in
which humans are to categorize instances as belonging to one of two classes.
The conclusions made by Castro and colleagues include that humans are capable
of actively selecting informative examples from a pool of unlabeled examples,
and when doing so, the humans learn faster and better than they would have done
if the examples were provided to them based on random sampling. However, the
human active learning does not show as much improvement as that obtained by
active machine learning on the same task. Further, Castro and colleagues
conclude that human active learning sensitive to noise, and do not approach the
theoretical bounds set out in active machine learning, that is, humans are not
as good as machines in selecting informative queries from an unlabeled data
set.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Although the work by </span><span lang=EN-US style='color:blue'>Castro
et al. </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) is not directly geared towards cost-sensitive learning, my
interpretation is that it raises important questions pertaining to the cost of
the of labeling data in terms of effort required by the human annotator: Are
the examples located between the human upper bound and the machine upper bound
are too hard for the human to label? Does this mean that it is not necessary to
let the machine select the most informative queries, that is, the ones hardest
to label, in order for machine active learning (involving a human) to work
optimally? Ultimately, does this mean that the human is the weakest point in
active learning in that he cannot assimilate the most informative examples
provided to him by the active machine learning algorithm?</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The research on cost-sensitive active learning in general, and the
results obtained by </span><span lang=EN-US style='color:blue'>Castro et al. </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) in particular, indicate that we should pay more attention to the
practical situation of the human annotator when striving to make active
learning an operational tool for practitioners of NLP.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:23.65pt;margin-left:-.25pt;text-align:left;line-height:107%'><b
style='mso-bidi-font-weight:normal'><span lang=EN-US style='font-size:20.5pt;
mso-bidi-font-size:11.0pt;line-height:107%'>Chapter 7</span></b></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Monitoring, assessing and
terminating the learning process</span></h1>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>The monitoring,
assessing and terminating of the active learning process go hand in hand. The
purpose of assessing the learning process is to provide the human annotator with
means to form a picture of the learning status. Once the status is known, the
annotator has the opportunity to act accordingly, for instance, to manually
stop the active learning process.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The purpose of defining the stopping criterion is slightly different
than that of assessing the learning process. A stopping criterion is used to
automatically terminate the learning process, and ideally the realization of
the definition, e.g., the setting of any thresholds necessary, should not
hinder nor disturb the human annotator.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:22.8pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>It should be
remembered that there is a readily available way of assessing the process, and
thus also to be able to manually decide when the active learning should be
stopped; to use a marked-up, held-out test set on which the learner is evaluated
in each iteration. This is the way that active learning is usually evaluated in
experimental settings. The drawback of this method is that the user has to
manually annotate more data before the annotation process takes off. As such,
it clearly counteracts the goal of active learning and should only be
considered a last resort.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:7.0pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 138.9pt'><span lang=EN-US>7.1<span
style='mso-tab-count:1'> </span>Measures for monitoring learning progress</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.2pt;
margin-left:-.25pt'><span lang=EN-US>A very common way of monitoring how an
active learner behaves is by plotting a learning curve, typically with the
classification error or F-score along one axis, commonly the Y-axis, and
something else along the other axis. It is that <i style='mso-bidi-font-style:
normal'>something else </i>that is of interest here. The X-axis is usually
indicating the amount of data seen C depending on the granularity of choice</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>35</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>for that
particular learning task it can be for instance tokens, named entities, or
sentences C or the number of iterations made while learning. The purpose of a
learning curve is to depict the progress in the learning process; few
variations of how to measure progress exist, and consequently there are few
differences in how the axes of a graph illustrating a learning curve are
labeled.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>There are times when the graphical nature of learning curves is not
an appropriate means to describe the learning process. </span><span lang=EN-US
style='color:blue'>Abe and Mamitsuka </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) calculate the <i
style='mso-bidi-font-style:normal'>data efficiency </i>achieved by using an
active learning approach as the ratio between the number of iterations required
by a base learner to reach top performance when data is drawn at random, and
the number of iterations required for the base learner in an active learning
setting to reach the same performance.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Melville and Mooney </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2004</span><span lang=EN-US>) defines the <i
style='mso-bidi-font-style:normal'>data utilization ratio </i>C which is
similar to the data efficiency introduced by </span><span lang=EN-US
style='color:blue'>Abe and Mamitsuka </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>1998</span><span lang=EN-US>) C as the number of
instances an active learner requires to reach a target error rate divided by
the number that the base learner C Decorate C requires to reach the same error
rate. Both <i style='mso-bidi-font-style:normal'>data efficiency </i>and <i
style='mso-bidi-font-style:normal'>data utilization ratio </i>reflect how good
an active learner is at making use of the data.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:5.4pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US style='color:blue'>Baram,
El-Yaniv and Luz </span><span lang=EN-US>(</span><span lang=EN-US
style='color:blue'>2004</span><span lang=EN-US>) propose to use a
quantification of the <i style='mso-bidi-font-style:normal'>deficiency </i>of
the querying function with respect to randomly selecting instances from which
to learn. The deficiency is defined in equation </span><span lang=EN-US
style='color:red'>7.1</span><span lang=EN-US>.</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:76.0pt;
margin-bottom:2.35pt;margin-left:66.0pt;text-align:center;line-height:107%'><!--[if gte vml 1]><v:shape
 id="Picture_x0020_56431" o:spid="_x0000_s1026" type="#_x0000_t75" style='position:absolute;
 left:0;text-align:left;margin-left:118.25pt;margin-top:.6pt;width:162.95pt;
 height:26.9pt;z-index:251658240;visibility:visible;mso-wrap-style:square;
 mso-wrap-distance-left:9pt;mso-wrap-distance-top:0;mso-wrap-distance-right:9pt;
 mso-wrap-distance-bottom:0;mso-position-horizontal:absolute;
 mso-position-horizontal-relative:text;mso-position-vertical:absolute;
 mso-position-vertical-relative:text' o:allowoverlap="f">
 <v:imagedata src="SICS-T--2009-06--SE.files/image022.png" o:title=""/>
 <w:wrap type="square"/>
</v:shape><![endif]--><![if !vml]><img width=217 height=36
src="SICS-T--2009-06--SE.files/image023.gif" align=left hspace=12 v:shapes="Picture_x0020_56431"><![endif]><i
style='mso-bidi-font-style:normal'><span lang=EN-US style='font-size:8.0pt;
mso-bidi-font-size:11.0pt;line-height:107%'>n</span></i></p>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:0cm;
margin-bottom:15.4pt;margin-left:0cm;text-align:right;text-indent:0cm;
line-height:107%'><i style='mso-bidi-font-style:normal'><span lang=EN-US>Deficiency</span></i><span
lang=EN-US>(7.1)</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>where <i
style='mso-bidi-font-style:normal'>t </i>is the training set size, <i
style='mso-bidi-font-style:normal'>Acc<sub>n</sub></i>(<i style='mso-bidi-font-style:
normal'>L</i>) is the maximal achievable accuracy when using algorithm <i
style='mso-bidi-font-style:normal'>L </i>and all available training data, <i
style='mso-bidi-font-style:normal'>Acc<sub>t</sub></i>(<i style='mso-bidi-font-style:
normal'>A</i>) is the average accuracy achieved by active learning algorithm <i
style='mso-bidi-font-style:normal'>A </i>and <i style='mso-bidi-font-style:
normal'>t </i>amount of training data, and <i style='mso-bidi-font-style:normal'>Acc<sub>t</sub></i>(<i
style='mso-bidi-font-style:normal'>L</i>) is the average accuracy achieved
using random sampling and learning algorithm <i style='mso-bidi-font-style:
normal'>L </i>and <i style='mso-bidi-font-style:normal'>t </i>amount of
training data. The deficiency measure captures the global performance of active
learner <i style='mso-bidi-font-style:normal'>A </i>throughout the learning
process. Smaller values indicate more efficient learning.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:23.75pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>There are, of course,
more parameters than data-related ones to consider when using active learning
in a practical setting, such as time, money, cognitive load on the user;
Chapter </span><span lang=EN-US style='color:red'>6 </span><span lang=EN-US>brings
up a number of issues relating to the cost of annotation.</span></p>

<h2 style='margin-top:0cm;margin-right:0cm;margin-bottom:7.4pt;margin-left:
-.75pt;text-indent:0cm;tab-stops:center 174.75pt'><span lang=EN-US>7.2<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Assessing
and terminating the learning</span></h2>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:20.4pt;
margin-left:-.25pt'><span lang=EN-US>A number of different approaches for
assessing and deciding when to stop the active learning process have been
suggested in the literature. These approaches include to decide on a target
accuracy and stop when it has 37</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>been reached, to
go on for a given number of active learning iterations, or to exhaust the pool
of unlabeled data.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.25pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>Some more elaborate
methods monitor the accuracy as the learning process progresses and stop when
accuracy deterioration is detected. Schohn and Cohn (</span><span lang=EN-US
style='color:blue'>2000</span><span lang=EN-US>) observe, while working with
Support Vector Machines for document classification, that when instances are
drawn at random from the pool of unlabeled data, the classifier performance
increases monotonically. However, when Schohn and Cohn add instances according
to their active learning selection metric, classifier performance peaks at a
level above that achieved when using all available data. Thus, they obtain
better performance by training on a subset of data, than when using all data
available. </span><span lang=EN-US style='color:blue'>Schohn and Cohn </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2000</span><span
lang=EN-US>) use this observation to form the basis for a stopping criterion;
if the best, most informative instance is no closer to the decision hyperplane
than any of the support vectors, the margin has been exhausted and learning is
terminated. This is an approximation of true peak performance that seem to work
well, </span><span lang=EN-US style='color:blue'>Schohn and Cohn </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2000</span><span
lang=EN-US>) claim.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Zhu and Hovy </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2007</span><span lang=EN-US>) investigate two
strategies for deciding when to stop learning C <i style='mso-bidi-font-style:
normal'>max-confidence </i>and <i style='mso-bidi-font-style:normal'>min-error </i>C
in a word sense disambiguation task. Max-confidence relies on an entropy-based
uncertainty measure of unlabeled instances, while min-error is based on the
classification accuracy of predicted labels for instances when compared to the
labels provided by the human annotator. Thresholds for max-confidence and
min-error are set such that when the two conditions are met, the current
classifier is assumed to provide high confidence in the classification of the
remaining unlabeled data. The experiments carried out by Zhu and Hovy indicate
that min-error is a good choice of stopping criterion, and that the
max-confidence approach is not as good as min-error.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Zhu, Wang and Hovy </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008a</span><span lang=EN-US>) extend the work
presented in (</span><span lang=EN-US style='color:blue'>Zhu and Hovy 2007</span><span
lang=EN-US>) and introduce an approach called <i style='mso-bidi-font-style:
normal'>minimum expected error strategy</i>. The strategy involves estimating
the classification error on future unlabeled instances in the active learning
process. Zhu and colleagues test their stopping criterion on two tasks; word
sense disambiguation, and text classification. </span><span lang=EN-US
style='color:blue'>Zhu, Wang and Hovy </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008a</span><span lang=EN-US>) conclude that the
minimum error strategy achieves promising results.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>In addition to the max-confidence and min-error strategies, </span><span
lang=EN-US style='color:blue'>Zhu, Wang and Hovy </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008b</span><span lang=EN-US>) introduce and
evaluate <i style='mso-bidi-font-style:normal'>overall-uncertainty </i>and <i
style='mso-bidi-font-style:normal'>classification-change</i>. Overall-uncertainty
is similar to max-confidence, but instead of taking only the most informative
instances into consideration, overalluncertainty is calculated using all data
remaining in the unlabeled pool. Classification-change builds on the assumption
that the most informative instance is the one which causes the classifier to
change the predicted label of the instance. Zhu and colleagues realize the
classification-changebased stopping criterion such that the learning process is
terminated once no predicted label of the instances in the unlabeled pool
changes during two consecutive active learning iterations. </span><span
lang=EN-US style='color:blue'>Zhu, Wang and Hovy </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008b</span><span lang=EN-US>) propose ways of
combining max-confidence, min-error, and overall-uncertainty with
classification-change in order to come to terms with the problem of
pre-defining the required thresholds. Zhu and colleagues conclude that the
proposed criteria work well, and that the combination strategies can achieve
even better results.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Vlachos </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) suggests to use
classifier confidence as a means to define a stopping criterion for uncertainty
based sampling. Roughly, the idea is to stop learning when the confidence of
the classifier, on an external possibly unannotated test set, remains at the same
level or drops for a number of consecutive iterations during the learning
process. Vlachos shows that the criterion indeed is applicable to the two tasks
he investigates; text classification and named entity recognition carried out
using Support Vector Machines, maximum entropy models, and Bayesian logistic
regression.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Laws and Schu¨tze </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) investigate three
ways of terminating uncertainty-based active learning for named entity
recognition; <i style='mso-bidi-font-style:normal'>minimal absolute performance</i>,
<i style='mso-bidi-font-style:normal'>maximum possible performance</i>, and <i
style='mso-bidi-font-style:normal'>convergence</i>. The minimal absolute
performance of the system is set by the user prior to starting the active
learning process. The classifier then estimates its own performance using a
held-out unlabeled data set. Once the desired performance is reached, the
learning is terminated. The maximum possible performance strategy refers to the
optimal performance of the classifier given the data. Once the optimal
performance is achieved, the process is aborted. Finally, the convergence
criterion aims to stop the learning process when the pool of available data
does not contribute to the classifier’s performance. The convergence is
calculated as the gradient of the classifier’s estimated performance or
uncertainty. </span><span lang=EN-US style='color:blue'>Laws and Schu¨tze </span><span
lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) conclude that both gradient-based approaches, that is,
convergence, can be used as stopping criteria relative to the optimal
performance achievable on a given pool of data. Laws and Schu¨tze also show
that while their method lend itself to acceptable estimates of accuracy, it is much
harder to estimate the recall of the classifier. Thus, the stopping criteria
based on minimal absolute performance as well as maximum possible performance
are not reliable.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Tomanek and Hahn </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) examine two ways of
monitoring the progression of learning in the context of a query by committee
setting for training named entity recognizers. Their first approach relies on
the assumption that the agreement within the decision committee concerning the
most informative instance selected in each active learning iteration approaches
one as the learning process progresses. Tomanek and Hahn refer to this as the <i
style='mso-bidi-font-style:normal'>selection agreement</i>, originally
introduced in </span><span lang=EN-US style='color:blue'>Tomanek, Wermter and
Hahn 2007a</span><span lang=EN-US>. The motivation for using the selection
agreement score is that active learning should be aborted when it no longer
contributes to increasing the performance of the classifier; at that time,
active learning is nothing more than a computationally expensive way of random
sampling from the remaining data.</span></p>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:20.65pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>39</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:1.25pt;
margin-left:-.75pt;text-indent:16.95pt'><span lang=EN-US>The second approach
taken by Tomanek and Hahn is to calculate the agreement within the committee
regarding a held-out, unannotated test set. This is referred to as the <i
style='mso-bidi-font-style:normal'>validation set agreement</i>. The idea is to
calculate the agreement on a test set with a distribution of names that reflects
that of the data set on which the active learning takes place. In doing so, </span><span
lang=EN-US style='color:blue'>Tomanek and Hahn </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) aim at obtaining an
image of the learning progression that is more true than that obtained by
calculating the selection agreement, simply because the distribution of the
held-out set, and thus also the validation set agreement score, is not affected
by the progression of the learning process in the same manner as the selection
agreement score is. </span><span lang=EN-US style='color:blue'>Tomanek and Hahn
</span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) carry out two types of experiments. In the first type, the human
annotator is simulated in the sense that the active learning utilizes
pre-annotated data; the annotated training examples supplied to the system are
in fact not annotated by a human at the time the system requests assistance in
classifying them, but comes from the pre-annotated corpus. In this type of
experiment, the amount of data is typically limited. The second type of
experiment conducted by </span><span lang=EN-US style='color:blue'>Tomanek and
Hahn </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2008</span><span
lang=EN-US>) involves real human annotators who operate on a substantially
larger amount of data, approximately 2 million sentences, as opposed to the at
most 14 000 sentences used in the experiments with simulated annotators.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Tomanek and Hahn </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) find that, for the
experiments with simulated annotators (using relatively small amounts of data),
both the selection agreement curves and the validation set agreement curves can
be useful for approximating a learning curve, thus indicating the progression
of the learning process. However, for the experiments employing human
annotators and large amounts of unlabelled data, the selection agreement does
not work at all. Tomanek and Hahn conclude that monitoring the progress of
active learning should always be based on a separate validation set instead of
the data directly affected by the learning process. Thus, validation set
agreement is preferred over selection agreement.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US style='color:blue'>Olsson </span><span lang=EN-US>(</span><span
lang=EN-US style='color:blue'>2008</span><span lang=EN-US>) proposes an
intrinsic stopping criterion (ISC) for committebased active learning. The
criterion is further elaborated by </span><span lang=EN-US style='color:blue'>Olsson
and Tomanek </span><span lang=EN-US>(</span><span lang=EN-US style='color:blue'>2009</span><span
lang=EN-US>). The ISC is intrinsic, relying only on the characteristics of the
base learner and the data at hand in order to decide when the active learning
process may be terminated. The ISC does not require the user to set any
external parameters prior to initiating the active learning process. Further,
the ISC is designed to work with committees of classifiers, and as such, it is
independent of how the disagreement between the committee members is
quantified. The ISC does neither rely on a particular base learner, nor on a
particular way of creating the decision committee.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>The ISC combines the selection agreement and the validation set
agreement (</span><span lang=EN-US style='color:blue'>Tomanek, Wermter and Hahn
2007a</span><span lang=EN-US>; </span><span lang=EN-US style='color:blue'>Tomanek
and Hahn 2008</span><span lang=EN-US>) into a single stopping criterion by
relating the agreement of the committee on a held-out validation set with that
on the (remaining) pool of unlabeled data. If the selection agreement is larger
than the validation set agreement, it is a signal that the decision committee
is more in agreement concerning the most informative instances in the
(diminishing) unlabeled pool than it is concerning the validation set. This, in
turn, implies that the committee would learn more from a random sample from the
validation set (or from a data source exhibiting the same distribution of
instances), than it would from the unlabeled data pool. Based on this argument,
a stopping criterion for committee-based active learning can be formulated as:
Active learning may be terminated when the Selection Agreement is larger than,
or equal to, the Validation Set Agreement.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Olsson and Tomanek define and empirically test the ISC for
committeebased active learning. The results of the experiments in two named
entity recognition scenarios show that the stopping criterion is a viable one,
representing a fair trade-off between data use and classifier performance. In a
setting in which the unlabeled pool of data used for learning is static,
terminating the learning process by means of the ISC results in a nearly
optimal classifier. The ISC can also be used for deciding when the pool of
unlabeled data needs to be refreshed.</span></p>

<p class=MsoNormal style='margin-left:-.75pt;text-indent:16.95pt'><span
lang=EN-US>Of the approaches to defining a stopping criterion for active
learning reviewed, the work described by Tomanek and colleagues, and the work
by Olsson is explicitly directed towards committee-based active learning. The
other approaches involve single classifier active learning strategies.</span></p>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Bibliography</span></h1>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Abe, Naoki and Hiroshi Mamitsuka 1998. Query learning strategies
using boosting and bagging. <i style='mso-bidi-font-style:normal'>Proceedings
of the Fifteenth International Conference on Machine Learning</i>, 1C9.
Madison, Wisconsin, USA: Morgan Kaufmann Publishers Inc.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>8</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>17</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>36</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Angluin, Dana 1988. Queries and concept learning. <i
style='mso-bidi-font-style:normal'>Machine Learning </i>2 (4): 319C342.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Argamon-Engelson, Shlomo and Ido Dagan 1999. Committee-based sample
selection for probabilistic classifiers. <i style='mso-bidi-font-style:normal'>Journal
of Artificial Intelligence Research </i>11: 335C360.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.05pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Asuncion, Arthur and
David Newman 2007. UCI Machine Learning Repository. URL: <i style='mso-bidi-font-style:
normal'><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html"><span
style='color:black;text-decoration:none;text-underline:none'>&lt;</span></a></i></span><span
lang=EN-US style='font-family:"Calibri",sans-serif;mso-fareast-font-family:
Calibri;color:#E72582'><a
href="http://www.ics.uci.edu/~mlearn/MLRepository.html"><span style='color:
#E72582;text-decoration:none;text-underline:none'>http://www.ics.uci.edu/</span></a></span><sup><span
lang=EN-US style='color:#E72582'><a
href="http://www.ics.uci.edu/~mlearn/MLRepository.html"><span style='color:
#E72582;text-decoration:none;text-underline:none'>&#8764;</span></a></span></sup><span
lang=EN-US style='font-family:"Calibri",sans-serif;mso-fareast-font-family:
Calibri;color:#E72582'><a
href="http://www.ics.uci.edu/~mlearn/MLRepository.html"><span style='color:
#E72582;text-decoration:none;text-underline:none'>mlearn/MLRepository.html</span></a></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US><a
href="http://www.ics.uci.edu/~mlearn/MLRepository.html"><span style='color:
black;text-decoration:none;text-underline:none'>&gt;</span></a></span></i><span
lang=EN-US>. </span><span lang=EN-US style='color:red'>8</span><span
lang=EN-US>, </span><span lang=EN-US style='color:red'>26</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Balcan, Maria-Florina, Avrim Blum and Ke Yang 2005. Co-training and
expansion: Towards bridging theory and practice. <i style='mso-bidi-font-style:
normal'>Advances in neural information processing systems 17</i>, 89C96.
Cambridge, Massachusetts, USA: MIT Press.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>14</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>15</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.1pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Baldridge, Jason and
Miles Osborne 2004. Active learning and the total cost of annotation. <i
style='mso-bidi-font-style:normal'>Proceedings of the 2004 Conference on
Empirical Methods in Natural Language Processing</i>, 9C16. ACL, Barcelona,
Spain. </span><span lang=EN-US style='color:red'>27</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>32</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Baram, Yoram, Ran El-Yaniv and Kobi Luz 2004. Online choice of
active learning algorithms. <i style='mso-bidi-font-style:normal'>Journal of
Machine Learning Research </i>5 (December): 255C291.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>36</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Becker, Markus, Ben Hachey, Beatrice Alex and Claire Grover 2005.
Optimising selective sampling for bootstrapping named entity recognition.
Stefan Ru¨ping and Tobias Scheffer (eds), <i style='mso-bidi-font-style:normal'>Proceedings
of the ICML 2005 Workshop on Learning with Multiple Views</i>, 5C11. Bonn,
Germany.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:14.0pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>20</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:110.95pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>41</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Becker, Markus and Miles Osborne 2005. A two-stage method for active
learning of statistical grammars. <i style='mso-bidi-font-style:normal'>Proceedings
of the Nineteenth International Joint Conference on Artificial Intelligence</i>,
991C996. Edinburgh, Scotland, UK: Professional Book Center.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:5.25pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>5</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>6</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>20</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Blum, Avrim and Tom Mitchell 1998. Combining labeled and unlabeled
data with co-training. <i style='mso-bidi-font-style:normal'>Proceedings of the
11th Annual Conference on Computational Learning Theory</i>, 92C100. ACM,
Madison, Wisconsin, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:6.6pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>9</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>13</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>14</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>15</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Breiman, Leo 1996. Bagging predictors. <i style='mso-bidi-font-style:
normal'>Machine Learning </i>24 (2): 123C140 (August).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.7pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Brinker, Klaus 2003. Incorporating diversity in active learning with
support vector machines. <i style='mso-bidi-font-style:normal'>Proceedings of
the Twentieth International Conference on Machine Learning (ICML-2003)</i>,
59C66. Washington DC, USA: AAAI Press.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.7pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>26</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Castro, Rui, Charles Kalish, Robert Nowak, Ruichen Qian, Timothy
Rogers and Xiaojin Zhu 2008. Human active learning. <i style='mso-bidi-font-style:
normal'>Proceedings of the 22nd annual conference on neural information
processing systems</i>. Vancouver, British Columbia, Canada.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:5.25pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>33</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>34</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Chan, Yee Seng and Hwee Tou Ng 2007. Domain adaptation with active
learning for word sense disambiguation. <i style='mso-bidi-font-style:normal'>Proceedings
of the 45th Annual Meeting of the Association for Computational Linguistics
(ACL-07)</i>, 49C56. ACL, Prague, Czech Republic.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.7pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Chawla, Nitesh V. and Grigoris Karakoulas 2005. Learning from
labeled and unlabeled data: An empirical study across techniques and domains.</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:20.3pt;margin-bottom:
4.6pt;margin-left:21.8pt;text-indent:0cm;line-height:108%'><i style='mso-bidi-font-style:
normal'><span lang=EN-US>Journal of Artificial Intelligence Research </span></i><span
lang=EN-US>23 (March): 331C366. </span><span lang=EN-US style='color:red'>14</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Chen, Jinying, Andrew Schein, Lyle Ungar and Martha Palmer 2006. An
empirical study of the behavior of active learning for word sense
disambiguation. <i style='mso-bidi-font-style:normal'>Proceedings of the Human
Language Technology Conference - North American Chapter of the Association for
Computational Linguistics Annual Meeting (HLT-NAACL 2006)</i>, 120C127. ACL,
New York, New York, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.7pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Chklovski, Timothy and Rada Mihalcea 2002. Building a sense tagged
corpus with open mind word expert. <i style='mso-bidi-font-style:normal'>Proceedings
of the SIGLEX/SENSEVAL</i></span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection6>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
3.0pt;margin-left:21.8pt;text-indent:0cm;line-height:108%'><i style='mso-bidi-font-style:
normal'><span lang=EN-US>Workshop on Word Sense Disambiguation: Recent
Successes and Future Directions</span></i><span lang=EN-US>, 116C122. ACL,
Philadelphia, Pennsylvania, USA. </span><span lang=EN-US style='color:red'>29</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Ciravegna, Fabio, Daniela Petrelli and Yorick Wilks 2002.
User-system cooperation in document annotation based on information extraction.
<i style='mso-bidi-font-style:normal'>Proceedings of the 13th International
Conference on Knowledge Engineering and Knowledge Management (EKAW 2002)</i>.
Siguenza, Spain: Springer Verlag.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>29</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:3.15pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Cohn, David, Les
Atlas and Richard Ladner 1994. Improving generalization with active learning. <i
style='mso-bidi-font-style:normal'>Machine Learning </i>15 (2): 201C221 (May). </span><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>5</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Collins, Michael and Yoram Singer 1999. Unsupervised models for
named entity classification. <i style='mso-bidi-font-style:normal'>Proceedings
of Joint SIGDAT Conference on Empirical Methods in Natural Language Processing
and Very Large Corpora</i>, 100C110. ACL, University of Maryland, College Park,
Maryland, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>13</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Culotta, Aron, Trausti Kristjansson, Andrew McCallum and Paul Viola
2006. Corrective feedback and persistent learning for information extraction. <i
style='mso-bidi-font-style:normal'>Journal of Artificial Intelligence </i>170
(14): 1101C1122 (October).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>32</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Dagan, Ido and Sean P. Engelson 1995. Committee-based sampling for
training probabilistic classifiers. <i style='mso-bidi-font-style:normal'>Proceedings
of the Twelfth International Conference on Machine Learning</i>, 150C157. Tahoe
City, California, USA: Morgan Kaufmann.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Dempster, Arthur, Nan Laird and Donald Rubin 1977. Maximum
likelihood from incomplete data via the em algorithm. <i style='mso-bidi-font-style:
normal'>Journal of the Royal Statistical Society </i>39 (1): 1C38.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>24</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Domingos, Pedro 2000. A unified bias-variance decomposition and its
applications. <i style='mso-bidi-font-style:normal'>Proceedings of the
Seventeenth International Conference on Machine Learning (ICML-2000)</i>,
231C238. Stanford University, California, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Douglas, Shona 2003. Active learning for classifying phone sequences
from unsupervised phonotactic models. <i style='mso-bidi-font-style:normal'>Proceedings
of Human Language Technology Conference C North American Chapter of the
Association for Computational Linguistics Annual Meeting (HLT-NAACL 2003)</i>,
19C21. ACL, Edmonton, Alberta, Canada.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Engelson, Sean P. and Ido Dagan 1996. Minimizing manual annotation
cost in supervised training from corpora. <i style='mso-bidi-font-style:normal'>Proceedings
of the 34th Annual Meeting of the Association for Computational Linguistics</i>,
319C326.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACL, Santa Cruz,
California, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>20</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Finn, Aidan and Nicolas Kushmerick 2003. Active learning selection
strategies for information extraction. <i style='mso-bidi-font-style:normal'>Proceedings
of the International Workshop on Adaptive Text Extraction and Mining (ATEM-03)</i>,
18C25. Catvat, Dubrovnik, Croatia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Freund, Yoav and Robert E. Schapire 1997. A decision-theoretic
generalization of on-line learning and application to boosting. <i
style='mso-bidi-font-style:normal'>Journal of Computer and Systems Science </i>55
(1): 119C139 (August).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Freund, Yoav, Sebastian H. Seung, Eli Shamir and Naftali Tishby
1997. Selective sampling using the query by committee algorithm. <i
style='mso-bidi-font-style:normal'>Machine Learning </i>28 (2-3): 133C168
(August/September).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.4pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Ganchev, Kuzman,
Fernando Pereira and Mark Mandel 2007. Semiautomated named entity annotation. <i
style='mso-bidi-font-style:normal'>Proceedings of the Linguistic Annotation
Workshop</i>, 53C56. ACL, Prague, Czech Republic. </span><span lang=EN-US
style='color:red'>33</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Goldman, Sally A. and Yan Zhou 2000. Enhancing supervised learning
with unlabeled data. <i style='mso-bidi-font-style:normal'>Proceedings of the
Seventeenth International Conference on Machine Learning (ICML-2000)</i>,
327C334. Stanford, California, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>14</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Hachey, Ben, Beatrice Alex and Markus Becker 2005. Investigating the
effects of selective sampling on the annotation task. <i style='mso-bidi-font-style:
normal'>Proceedings of the Ninth Conference on Computational Natural Language
Learning (CoNLL-2005)</i>, 144C151. ACL, Ann Arbor, Michigan, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>21</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>32</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:3.75pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Haertel, Robbie, Eric
Ringger, Kevin Seppi, James Carroll and Peter McClanahan 2008. Assessing the
costs of sampling methods in active learning for annotation. <i
style='mso-bidi-font-style:normal'>Proceedings of the 46th annual meeting of
the association for computational linguistics: Human language technologies,
short papers (companion volume)</i>, 65C68. ACL, Columbus, Ohio, USA. </span><span
lang=EN-US style='color:red'>33</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Hamming, Richard W. 1950. Error detecting and error correcting
codes. <i style='mso-bidi-font-style:normal'>Bell System Technical Journal </i>26
(2): 147C160 (April).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>26</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Hoi, Steven C. H., Rong Jin and Michael R. Lyu 2006. Large-scale
text categorization by batch mode active learning. <i style='mso-bidi-font-style:
normal'>Proceedings of the 15th International World Wide Web Conference (WWW
2006)</i>, 633C642.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>Edinburgh,
Scotland.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:5.4pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>26</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Hwa, Rebecca 2000. Sample selection for statistical grammar
induction. <i style='mso-bidi-font-style:normal'>Proceedings of the 2000 Joint
SIGDAT Conference on Empirical Methods in Natural Language Processing and Very
Large Corpora</i>, 45C52. ACL, Hong-Kong.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.05pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>31</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Hwa, Rebecca, Miles Osborne, Anoop Sarkar and Mark Steedman 2003.
Corrected co-training for statistical parsers. <i style='mso-bidi-font-style:
normal'>Proceedings of the Workshop on the Continuum from Labeled to Unlabeled
Data in Machine Learning and Data Mining</i>. Washington DC, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.05pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>10</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Jones, Rosie, Rayid Ghani, Tom Mitchell and Ellen Riloff 2003.
Active learning for information extraction with multiple view feature sets. <i
style='mso-bidi-font-style:normal'>Proceedings of the 20th International
Conference on Machine Learning (ICML 2003)</i>. Washington DC, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Kim, Seokhwan, Yu Song, Kyungduk Kim, Jeong-Won Cha and Gary Geunbae
Lee 2006. MMR-based active machine learning for bio named entity recognition. <i
style='mso-bidi-font-style:normal'>Proceedings of the Human Language Technology
Conference C North American Chapter of the Association for Computational Linguistics
Annual Meeting (HLT-NAACL 2006)</i>, 69C72. ACL, New York, New York, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>K¨orner, Christine and Stefan Wrobel 2006. Multi-class
ensemble-based active learning. <i style='mso-bidi-font-style:normal'>Proceedings
of The 17th European Conference on Machine Learning and the 10th European Conference
on Principles and Practice of Knowledge Discovery in Databases</i>, 687C694.
Berlin, Germany:</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>Springer-Verlag.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.05pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>17</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>18</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>19</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Kuo, Jin-Shea, Haizhou Li and Ying-Kuei Yang 2006. Learning
transliteration lexicons from the web. <i style='mso-bidi-font-style:normal'>Proceedings
of the 21st International Conference on Computational Linguistics and 44th
Annual Meeting of the Association of Computational Linguistics</i>, 1129C1136.
ACL, Sydney, Australia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Lafferty, John, Andrew McCallum and Fernando Pereira 2001.
Conditional random fields: Probabilistic models for segmenting and labeling
sequence data. <i style='mso-bidi-font-style:normal'>Proceedings of the
Eighteenth International Confer-</i></span></p>

<p class=MsoNormal style='margin-left:22.3pt'><i style='mso-bidi-font-style:
normal'><span lang=EN-US>ence on Machine Learning (ICML-2001)</span></i><span
lang=EN-US>, 282C289. Williamstown, Massachusetts, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>30</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Laws, Florian and Hinrich Schu¨tze 2008. Stopping criteria for
active learning of named entity recognition. <i style='mso-bidi-font-style:
normal'>Proceedings of the 22nd International Conference on Computational
Linguistics (COLING 2008)</i>, 465C472.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACL, Manchester,
England.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>38</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lewis, David D.
1995. A sequential algorithm for training text classifiers:</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.4pt;
margin-left:22.3pt'><span lang=EN-US>Corrigendum and additional data. <i
style='mso-bidi-font-style:normal'>ACM SIGIR Forum </i>29 (2): 13C19. </span><span
lang=EN-US style='color:red'>3</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Lewis, David D. and William A. Gale 1994. A Sequential Algorithm for
Training Text Classifiers. <i style='mso-bidi-font-style:normal'>Proceedings of
the 17th Annual International ACM-SIGIR Conference on Research and Development in
Information Retrieval</i>, 3C12. Dublin, Ireland: ACM/Springer.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>5</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>24</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.85pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Liere, Ray and Prasad
Tadepalli 1997. Active learning with committees for text categorization. <i
style='mso-bidi-font-style:normal'>Proceedings of the fourteenth national
conference on artificial intelligence</i>, 591C597. AAAI, Providence, Rhode
Island, USA. </span><span lang=EN-US style='color:red'>3</span><span
lang=EN-US>, </span><span lang=EN-US style='color:red'>7</span><span
lang=EN-US>, </span><span lang=EN-US style='color:red'>24</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.35pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Lin, Jianhua 1991.
Divergence measures based on the Shannon entropy. <i style='mso-bidi-font-style:
normal'>IEEE Transactions on Information Theory </i>37 (1): 145C151 (January). </span><span
lang=EN-US style='color:red'>20</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>McCallum, Andrew and Kamal Nigam 1998. Employing em and pool-based
active learning for text classification. <i style='mso-bidi-font-style:normal'>Proceedings
of the 15th International Conference on Machine Learning (ICML-98)</i>,
350C358. Madison, Wisconsin, USA: Morgan Kaufmann.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>20</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>23</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>24</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>25</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Melville, Prem and Raymond J. Mooney 2003. Constructing diverse
classifier ensembles using artificial training examples. <i style='mso-bidi-font-style:
normal'>Proceedings of the Eighteenth International Joint Conference on
Artificial Intelligence (IJCAI03)</i>, 505C510. Acapulco, Mexico.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>8</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Melville, Prem and Raymond J. Mooney 2004. Diverse ensembles for
active learning. <i style='mso-bidi-font-style:normal'>Proceedings of the 21st
International Conference on Machine Learning (ICML-2004)</i>, 584C591. Banff,
Canada.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>8</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>17</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>36</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Mihalcea, Rada and Timothy Chklovski 2003. Open mind word expert:
Creating large annotated data collections with web user’s help. <i
style='mso-bidi-font-style:normal'>Proceedings of the EACL 2003 Workshop on
Linguistically Annotated Corpora (LINC 2003)</i>. EACL, Budapest, Hungary.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>29</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Mitchell, Tom
1997. <i style='mso-bidi-font-style:normal'>Machine learning</i>. McGraw-Hill.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>1</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.4pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Muslea, Ion, Steven
Minton and Craig A. Knoblock 2000. Selective sampling with redundant views. <i
style='mso-bidi-font-style:normal'>Proceedings of the Fifteenth National
Conference on Artificial Intelligence (AAAI-2000)</i>, 621C626. Austin, Texas,
USA. </span><span lang=EN-US style='color:red'>11</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Muslea, Ion, Steven Minton and Craig A. Knoblock 2002a. Adaptive
view validation: A first step towards automatic view detection. <i
style='mso-bidi-font-style:normal'>Proceedings of the 19th International
Conference on Machine Learning (ICML 2002)</i>, 443C450. Sydney, Australia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>13</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>14</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Muslea, Ion, Steven Minton and Craig A. Knoblock 2002b. Active +
semisupervised learning = robust multi-view learning. <i style='mso-bidi-font-style:
normal'>Proceedings of the 19th International Conference on Machine Learning
(ICML-02)</i>, 435C 442. Sydney, Australia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>14</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>15</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Muslea, Ion, Steven Minton and Craig A. Knoblock 2006. Active
learning with multiple views. <i style='mso-bidi-font-style:normal'>Journal of
Artificial Intelligence Research </i>27 (October): 203C233.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>11</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>12</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Ngai, Grace and David Yarowsky 2000. Rule writing or annotation:
Costefficient resource usage for base noun phrase chunking. <i
style='mso-bidi-font-style:normal'>Proceedings of the 38th Annual Meeting on
Association for Computational Linguistics</i>, 117C125. ACL, Hong-Kong.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>21</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Nigam, Kamal and Rayid Ghani 2000. Analyzing the effectiveness and
applicability of co-training. <i style='mso-bidi-font-style:normal'>Proceedings
of the Ninth International Conference on Information and Knowledge Management
(CIKM 2000)</i>, 86C93.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACM, McLean,
Virginia, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>13</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Olsson, Fredrik 2008. Bootstrapping Named Entity Annotation by means
of Active Machine Learning C A Method for Creating Corpora. Ph.D. diss.,
Department of Swedish, University of Gothenburg.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>21</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>24</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>28</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>39</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Olsson, Fredrik and Katrin Tomanek 2009. An intrinsic stopping
criterion for committee-based active learning. <i style='mso-bidi-font-style:
normal'>Proceedings of the 13th conference on computational natural language
learning</i>. ACL, Boulder, Colorado, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>39</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
1.75pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Osborne, Miles and Jason Baldridge 2004. Ensemble-based active
learning for parse selection. <i style='mso-bidi-font-style:normal'>Proceedings
of Human Language Technology Conference C the North American Chapter of the
Association for Computational Linguistics Annual Meeting (HLT-NAACL 2004)</i>,
89C96. ACL, Boston, Massachusetts, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>32</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Pereira, Fernando C. N., Naftali Tishby and Lillian Lee 1993.
Distributional clustering of English words. <i style='mso-bidi-font-style:normal'>Proceedings
of the 31st Annual Meeting of the Association for Computational Linguistics</i>,
183C190. ACL, Columbus, Ohio, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>19</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Pierce, David and Claire Cardie 2001. Limitations of co-training for
natural language learning from large datasets. <i style='mso-bidi-font-style:
normal'>Proceedings of the 2001 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2001)</i>, 1C9. Pittsburgh, Pennsylvania, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>9</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>11</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Reichart, Roi and Ari Rappoport 2007. An ensemble method for
selection of high quality parses. <i style='mso-bidi-font-style:normal'>Proceedings
of the 45th Annual Meeting of the Association for Computational Linguistics
(ACL-07)</i>, 408C415. ACL, Prague, Czech Republic.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Ringger, Eric, Peter McClanahan, Robbie Haertel, George Busby, Marc
Carmen, James Carroll, Kevin Seppi and Deryle Lonsdale 2007. Active learning
for part-of-speech tagging: Accelerating corpus annotation. <i
style='mso-bidi-font-style:normal'>Proceedings of the Linguistic Annotation
Workshop</i>, 101C108. ACL, Prague, Czech Republic.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>32</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Sassano, Manabu 2002. An empirical study of active learning with
support vector machines for Japanese word segmentation. <i style='mso-bidi-font-style:
normal'>Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL)</i>, 505C512. ACL, Philadelphia, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.0pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Schapire, Robert E. 1990. The strength of weak learnability. <i
style='mso-bidi-font-style:normal'>Machine Learning </i>5 (2): 197C227 (June).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Schapire, Robert E. 2003. The boosting approach to machine learning:
An overview. D. D. Denison, M. H. Hansen, C. Holmes, B. Mallick and B. Yu
(eds), <i style='mso-bidi-font-style:normal'>Nonlinear Estimation and
Classification</i>, Volume 171 of <i style='mso-bidi-font-style:normal'>Lecture
Notes in Statistics</i>, 149C172. Springer.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>7</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.4pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Schapire, Robert E.,
Yoav Freund, Peter Bartlett and Wee Sun Lee 1998. Boosting the margin: A new
explanation for the effectiveness of voting methods. <i style='mso-bidi-font-style:
normal'>The Annals of Statistics </i>26 (5): 1651C1686 (October). </span><span
lang=EN-US style='color:red'>17</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Scheffer,
Tobias, Christian Decomain and Stefan Wrobel 2001. Active hidden Markov models
for information extraction. <i style='mso-bidi-font-style:normal'>Proceedings
of the 4th International Conference on Advances in Intelligent Data Analysis
(IDA2001)</i>, 309C318. Lisbon, Portugal: Springer.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>5</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Schohn, Greg and David Cohn 2000. Less is more: Active learning with
support vector machines. <i style='mso-bidi-font-style:normal'>Proceedings of
the Seventeenth International Conference on Machine Learning (ICML-2000)</i>,
839C846. Stanford University, Stanford, California, USA: Morgan Kaufmann.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>5</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>37</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Settles, Burr 2009. Active learning literature survey. Computer
sciences technical report 1648, University of Wisconsin-Madison.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>1</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
2.9pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Settles, Burr, Mark Craven and Lewis Friedland 2008. Active learning
with real annotation costs. <i style='mso-bidi-font-style:normal'>Proceedings
of the workshop on cost sensitive learning held in conjunction with the 23rd
annual conference on neural information processing systems</i>. Vancouver,
British Columbia, Canada. </span><span lang=EN-US style='color:red'>33</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Seung, H. Sebastian, Manfred Opper and Haim Sompolinsky 1992. Query
by committee. <i style='mso-bidi-font-style:normal'>Proceedings of the Fifth
Annual ACM Workshop on Computational Learning Theory</i>, 287C294. Pittsburgh,
Pennsylvania, USA:</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACM.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.35pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>6</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.65pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Shannon, Claude E.
1948. A mathematical theory of communication. <i style='mso-bidi-font-style:
normal'>Bell System Technical Journal </i>27 (July and October): 379C423 and
623C656. </span><span lang=EN-US style='color:red'>18</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:3.25pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Shen, Dan, Jie Zhang,
Jian Su, Guodong Zhou and Chew-Lim Tan 2004. Multi-criteria-based active
learning for named entity recognition. <i style='mso-bidi-font-style:normal'>Proceedings
of the 42nd Annual Meeting of the Association for Computational Linguistics
(ACL-04)</i>, 589C596. ACL, Barcelona, Spain. </span><span lang=EN-US
style='color:red'>3</span><span lang=EN-US>, </span><span lang=EN-US
style='color:red'>25</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Steedman, Mark,
Rebecca Hwa, Stephen Clark, Miles Osborne, Anoop</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.8pt;
margin-left:22.3pt'><span lang=EN-US>Sarkar, Julia Hockenmaier, Paul Ruhlen,
Steven Baker and Jeremiah Crim 2003. Example selection for bootstrapping
statistical parsers. <i style='mso-bidi-font-style:normal'>Proceedings of Human
Language Technology Conference C North American Chapter of the Association for
Computational Linguistics Annual Meeting (HLT-NAACL 2003)</i>, 157C164. ACL,
Edmonton, Alberta, Canada. </span><span lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tang, Min, Xiaoqiang Luo and Salim Roukos 2002. Active learning for
statistical natural language parsing. <i style='mso-bidi-font-style:normal'>Proceedings
of the 40th Annual Meeting of the Association for Computational Linguistics
(ACL-02)</i>, 120C127.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACL,
Philadelphia, Pennsylvania, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>25</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>26</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Thompson, Cynthia A., Mary Elaine Califf and Raymond J. Mooney 1999.
Active learning for natural language parsing and information extraction. <i
style='mso-bidi-font-style:normal'>Proceedings of the Sixteenth International
Machine Learning Conference (ICML-99)</i>, 406C414. Bled, Slovenia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tomanek, Katrin and Udo Hahn 2008. Approximating learning curves for
active-learning-driven annotation. <i style='mso-bidi-font-style:normal'>Proceedings
of Sixth International Conference on Language Resources and Evaluation (LREC
2008)</i>.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ELRA, Marrakech,
Morocco.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>38</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>39</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tomanek, Katrin and Fredrik Olsson 2009. A web survey on the use of
active learning to support annotation of text data. <i style='mso-bidi-font-style:
normal'>To appear in: Proceedings of naacl hlt 2009 workshop on active learning
for natural language processing</i>. ACL, Boulder, Colorado, USA.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>1</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tomanek, Katrin, Joachim Wermter and Udo Hahn 2007a. An approach to
text corpus construction which cuts annotation costs and maintains reusability
of annotated data. <i style='mso-bidi-font-style:normal'>Proceedings of the
2007 Joint Conference on Empirical Methods in Natural Language Processing and
Computational Natural Language Learning</i>, 486C495. ACL, Prague, Czech
Republic.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>21</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>28</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>29</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>30</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>38</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>39</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:2.85pt;
margin-left:21.05pt;text-indent:-21.8pt'><span lang=EN-US>Tomanek, Katrin,
Joachim Wermter and Udo Hahn 2007b. Efficient annotation with the jena
annotation environment (JANE). <i style='mso-bidi-font-style:normal'>Proceedings
of the Linguistic Annotation Workshop</i>, 9C16. ACL, Prague, Czech Republic. </span><span
lang=EN-US style='color:red'>24</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>29</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>30</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tong, Simon and Daphne Koller 2002. Support vector machine active
learning with applications to text classification. <i style='mso-bidi-font-style:
normal'>Journal of Machine Learning </i>2 (March): 45C66.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Tur, Gokhan, Dilek Hakkani-Tu¨r and Robert E. Schapire 2005.
Combining active and semi-supervised learning for spoken language
understanding.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><i style='mso-bidi-font-style:
normal'><span lang=EN-US>Speech Communication </span></i><span lang=EN-US>45
(2): 171C186 (February).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.0pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:21.55pt;text-indent:-22.3pt;line-height:108%'><span
lang=EN-US>Vlachos, Andreas 2006. Active annotation. <i style='mso-bidi-font-style:
normal'>Proceedings of the Workshop on Adaptive Text Extraction and Mining
(ATEM 2006)</i>, 64C71. ACL,</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>Trento, Italy.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.5pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>3</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>28</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Vlachos, Andreas 2008. A stopping criterion for active learning. <i
style='mso-bidi-font-style:normal'>Computer, Speech and Language </i>22 (3):
295C312 (July).</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:4.0pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>38</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:-.75pt;margin-bottom:
.15pt;margin-left:-.75pt;text-indent:0cm;line-height:108%'><span lang=EN-US>Witten,
Ian H. and Eibe Frank 2005. <i style='mso-bidi-font-style:normal'>Data mining:
Practical machine learning tools with java implementations. 2nd edition. </i>San
Fransisco: Morgan Kaufmann.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.65pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>1</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Wu, Wei-Lin, Ru-Zhan Lu, Jian-Yong Duan, Hui Liu, Feng Gao and
YuQuan Chen 2006. A weakly supervised learning approach for spoken language
understanding. <i style='mso-bidi-font-style:normal'>Proceedings of the 2006
Conference on Empirical Methods in Natural Language Processing (EMNLP 2006)</i>,
199C207.</span></p>

<p class=MsoNormal style='margin-left:22.3pt'><span lang=EN-US>ACL, Sydney,
Australia.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.65pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Zhang, Kuo, Jie Tang, JuanZi Li and KeHong Wang 2005. Featurecorrelation
based multi-view detection. <i style='mso-bidi-font-style:normal'>Computational
Science and Its Applications (ICCSA 2005)</i>, Lecture Notes in Computer
Science, 1222C 1230. Springer-Verlag.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.65pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>14</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Zhu, Jingbo and Eduard Hovy 2007. Active learning for word sense
disambiguation with methods for addressing the class imbalance problem. <i
style='mso-bidi-font-style:normal'>Proceedings of the 2007 Joint Conference on
Empirical Methods in Natural Language Processing and Computational Natural
Language Learning</i>, 783C790. ACL, Prague, Czech Republic.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>37</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Zhu, Jingbo, Huizhen Wang and Eduard Hovy 2008a. Learning a stopping
criterion for active learning for word sense disambiguation and text
classification. <i style='mso-bidi-font-style:normal'>Proceedings of the 3rd
International Joint Conference on Natural Language Processing (IJCNLP 2008)</i>,
366C372. Hyderabad, India.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>4</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>37</span></p>

<p class=MsoNormal style='margin-left:21.05pt;text-indent:-21.8pt'><span
lang=EN-US>Zhu, Jingbo, Huizhen Wang and Eduard Hovy 2008b.
Multi-criteria-based strategy to stop active learning for data annotation. <i
style='mso-bidi-font-style:normal'>Proceedings of the 22nd International
Conference on Computational Linguistics (COLING 2008)</i>, 1129C1136. ACL,
Manchester, England.</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:2.85pt;margin-left:21.55pt;text-align:left;line-height:107%'><span
lang=EN-US style='color:red'>37</span><span lang=EN-US>, </span><span
lang=EN-US style='color:red'>38</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection7>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>52</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:always;mso-break-type:section-break'>
</span>

<div class=WordSection8>

<h1 style='margin-left:-.25pt'><span lang=EN-US>Author index</span></h1>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Abe, Naoki 7, 8,
17, 36</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Alex, Beatrice
3, 20, 21, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Angluin, Dana 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Argamon-Engelson,
Shlomo 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Asuncion, Arthur
8, 26</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:10.75pt;
margin-left:-.25pt'><span lang=EN-US>Atlas, Les 4, 5</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Baker, Steven 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Balcan,
Maria-Florina 14, 15</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Baldridge, Jason
4, 27, 32</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:37.85pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Baram, Yoram 36 Bartlett, Peter 17</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Becker, Markus
3C6, 20, 21, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Blum, Avrim 9,
13C15</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Breiman, Leo 7</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Brinker, Klaus
26</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:10.75pt;
margin-left:-.25pt'><span lang=EN-US>Busby, George 4, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Califf, Mary
Elaine 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Cardie, Claire
9, 11</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Carmen, Marc 4,
32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Carroll, James
4, 32, 33</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:53.75pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Castro, Rui 33, 34 Cha, Jeong-Won 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Chan, Yee Seng 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Chawla, Nitesh
V. 14</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Chen, Jinying 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Chen, Yu-Quan 4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:3.9pt;margin-bottom:.25pt;
margin-left:-.25pt'><span lang=EN-US>Chklovski, Timothy 29 Ciravegna, Fabio 29</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Clark, Stephen 4</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:36.05pt;
margin-bottom:.05pt;margin-left:-.25pt;text-align:left;line-height:106%'><span
lang=EN-US>Cohn, David 3C5, 37 Collins, Michael 13 Craven, Mark 33 Crim,
Jeremiah 4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:10.95pt'><span lang=EN-US>Culotta, Aron 3, 32</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Dagan, Ido 4,
20</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Decomain,
Christian 3, 5</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Dempster,
Arthur 24</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Domingos, Pedro
7</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Douglas, Shona
4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:10.95pt'><span lang=EN-US>Duan, Jian-Yong 4</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>El-Yaniv, Ran
36</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:10.95pt'><span lang=EN-US>Engelson, Sean P. 4, 20</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Finn, Aidan 3</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Frank, Eibe 1</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Freund, Yoav 7,
17</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:10.95pt'><span lang=EN-US>Friedland, Lewis 33</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Gale, William
A. 3, 5, 24</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Ganchev, Kuzman
33</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Gao, Feng 4</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Ghani, Rayid 3,
13</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:14.65pt;margin-bottom:
8.9pt;margin-left:10.95pt'><span lang=EN-US>Goldman, Sally A. 14 Grover, Claire
3, 20</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Hachey, Ben 3,
20, 21, 32</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Haertel, Robbie
4, 32, 33</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Hahn, Udo 21,
24, 28C30, 38, 39</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Hakkani-Tu¨r, Dilek
4</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Hamming,
Richard W. 26</span></p>

<p class=MsoNormal style='margin-left:10.95pt'><span lang=EN-US>Hockenmaier,
Julia 4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:15.45pt;margin-bottom:
.25pt;margin-left:10.95pt'><span lang=EN-US>Hoi, Steven C. H. 3, 26 Hovy,
Eduard 4, 37, 38</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:8.85pt;
margin-left:10.95pt'><span lang=EN-US>Hwa, Rebecca 4, 10, 31</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:13.2pt;
margin-left:10.95pt'><span lang=EN-US>Jin, Rong 3, 26</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>53</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:20.7pt;
margin-left:-.25pt'><span lang=EN-US>54</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.45pt;
margin-left:-.25pt'><span lang=EN-US>Jones, Rosie 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Kalish, Charles
33, 34</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Karakoulas,
Grigoris 14</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Kim, Kyungduk 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Kim, Seokhwan 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Knoblock, Craig
A. 11C15</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Koller, Daphne 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>K¨orner,
Christine 17C19</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Kristjansson,
Trausti 3, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Kuo, Jin-Shea 4</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.45pt;
margin-left:-.25pt'><span lang=EN-US>Kushmerick, Nicolas 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Ladner, Richard
4, 5</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lafferty, John
30</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Laird, Nan 24</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Laws, Florian 38</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lee, Gary
Geunbae 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lee, Lillian 19</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lee, Wee Sun 17</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lewis, David D.
3, 5, 24</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Li, Haizhou 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Li, JuanZi 14</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Liere, Ray 3, 7,
24</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lin, Jianhua 20</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Liu, Hui 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lonsdale, Deryle
4, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Lu, Ru-Zhan 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Luo, Xiaoqiang
4, 25, 26</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Luz, Kobi 36</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.45pt;
margin-left:-.25pt'><span lang=EN-US>Lyu, Michael R. 3, 26</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Mamitsuka,
Hiroshi 7, 8, 17, 36</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Mandel, Mark 33</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>McCallum, Andrew
3, 20, 23C25, 30,</span></p>

<p class=MsoNormal style='margin-left:11.4pt'><span lang=EN-US>32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>McClanahan,
Peter 4, 32, 33</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Melville, Prem
8, 18, 36</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Mihalcea, Rada
29</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Minton, Steven
11C15</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Mitchell, Tom 1,
3, 9, 13C15</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.5pt;
margin-left:-.25pt'><span lang=EN-US>Mooney, Raymond J. 4, 8, 18, 36 Muslea,
Ion 11C15</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Newman, David 8,
26</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Ng, Hwee Tou 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Ngai, Grace 21</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Nigam, Kamal 3,
13, 20, 23C25</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.8pt;
margin-left:-.25pt'><span lang=EN-US>Nowak, Robert 33, 34</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Olsson, Fredrik
1, 21, 24, 28, 39</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Opper, Manfred 6</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.8pt;
margin-left:-.25pt'><span lang=EN-US>Osborne, Miles 4C6, 10, 20, 27, 32</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Palmer, Martha 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Pereira,
Fernando 30, 33</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Pereira,
Fernando C. N. 19</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:37.8pt;margin-bottom:
9.85pt;margin-left:-.25pt'><span lang=EN-US>Petrelli, Daniela 29 Pierce, David
9, 11</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.8pt;
margin-left:-.25pt'><span lang=EN-US>Qian, Ruichen 33, 34</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Rappoport, Ari 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Reichart, Roi 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Riloff, Ellen 3</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Ringger, Eric 4,
32, 33</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:11.8pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Rogers, Timothy 33, 34 Roukos, Salim
4, 25, 26</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Rubin, Donald 24</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:0cm;margin-bottom:9.8pt;
margin-left:-.25pt'><span lang=EN-US>Ruhlen, Paul 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Sarkar, Anoop 4,
10</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Sassano, Manabu
4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Schapire, Robert
E. 4, 7, 17</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Scheffer, Tobias
3, 5</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Schein, Andrew 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Schohn, Greg 3,
5, 37</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Schu¨tze,
Hinrich 38</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:22.2pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Seppi, Kevin 4, 32, 33 Settles, Burr
1, 33</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Seung, H.
Sebastian 6</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Seung, Sebastian
H. 7</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Shamir, Eli 7</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:26.05pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Shannon, Claude E. 18 Shen, Dan 3,
25</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Singer, Yoram 13</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Sompolinsky,
Haim 6</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Song, Yu 3</span></p>

<p class=MsoNormal style='margin-top:0cm;margin-right:41.3pt;margin-bottom:
.25pt;margin-left:-.25pt'><span lang=EN-US>Steedman, Mark 4, 10 Su, Jian 3, 25</span></p>

</div>

<span lang=EN-US style='font-size:11.0pt;line-height:110%;font-family:"Cambria",serif;
mso-fareast-font-family:Cambria;mso-bidi-font-family:Cambria;color:black;
mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA'><br
clear=all style='page-break-before:auto;mso-break-type:section-break'>
</span>

<div class=WordSection9>

<p class=MsoNormal align=right style='margin-top:0cm;margin-right:-.75pt;
margin-bottom:21.95pt;margin-left:.5pt;text-align:right;line-height:110%'><span
lang=EN-US>55</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.3pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:right 358.65pt'><span lang=EN-US>Tadepalli, Prasad 3, 7, 24<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Wermter,
Joachim 21, 24, 28C30, 38,</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.55pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 200.65pt'><span lang=EN-US>Tan, Chew-Lim 3, 25<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>39</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.5pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 223.75pt'><span lang=EN-US>Tang, Jie 14<span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Wilks,
Yorick 29</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.65pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 224.15pt'><span lang=EN-US>Tang, Min 4, 25, 26<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Witten,
Ian H. 1</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.8pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 247.35pt'><span lang=EN-US>Thompson, Cynthia A. 4<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Wrobel,
Stefan 3, 5, 17C19</span></p>

<p class=MsoNormal align=left style='margin-left:-.75pt;text-align:left;
text-indent:0cm;tab-stops:center 219.25pt'><span lang=EN-US>Tishby, Naftali 7,
19<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Wu,
Wei-Lin 4</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Tomanek, Katrin
1, 21, 24, 28C30,</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.55pt;margin-left:0cm;text-align:left;text-indent:0cm;
tab-stops:center 25.15pt 222.5pt'><span lang=EN-US style='font-family:"Calibri",sans-serif;
mso-fareast-font-family:Calibri'><span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span><span
lang=EN-US>38, 39<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Yang,
Ke 14, 15</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.55pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 228.7pt'><span lang=EN-US>Tong, Simon 3<span style='mso-tab-count:
1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Yang,
Ying-Kuei 4</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:12.75pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 231.55pt'><span lang=EN-US>Tur, Gokhan 4<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Yarowsky,
David 21</span></p>

<p class=MsoNormal align=left style='margin-left:-.75pt;text-align:left;
text-indent:0cm;tab-stops:center 222.55pt'><sup><span lang=EN-US
style='font-size:17.0pt;mso-bidi-font-size:11.0pt;line-height:110%'>Ungar, Lyle
4<span style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></sup><span
lang=EN-US>Zhang, Jie 3, 25</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:30.1pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>Zhang, Kuo 14</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Viola, Paul 3,
32</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:0cm;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>Zhou, Guodong 3, 25</span></p>

<p class=MsoNormal style='margin-left:-.25pt'><span lang=EN-US>Vlachos, Andreas
3, 28, 38</span></p>

<p class=MsoNormal align=center style='margin-top:0cm;margin-right:36.75pt;
margin-bottom:.15pt;margin-left:111.45pt;text-align:center;line-height:110%'><span
lang=EN-US>Zhou, Yan 14</span></p>

<p class=MsoNormal align=left style='margin-top:0cm;margin-right:0cm;
margin-bottom:1.55pt;margin-left:-.75pt;text-align:left;text-indent:0cm;
tab-stops:center 235.0pt'><span lang=EN-US>Wang, Huizhen 4, 37, 38<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Zhu,
Jingbo 4, 37, 38</span></p>

<p class=MsoNormal align=left style='margin-left:-.75pt;text-align:left;
text-indent:0cm;tab-stops:center 230.5pt'><span lang=EN-US>Wang, KeHong 14<span
style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Zhu,
Xiaojin 33, 34</span></p>

</div>

<div style='mso-element:footnote-list'><![if !supportFootnotes]><br clear=all>

<hr align=left size=1 width="33%">

<![endif]>

<div style='mso-element:footnote' id=ftn1>

<p class=footnotedescription align=left style='margin-left:12.45pt;text-align:
left;text-indent:0cm'><a style='mso-footnote-id:ftn1' href="#_ftnref1"
name="_ftn1" title=""><span class=footnotemark><span lang=EN-US><span
style='mso-special-character:footnote'><![if !supportFootnotes]><span
class=footnotemark><span lang=EN-US style='font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[1]</span></span><![endif]></span></span></span></a><span
lang=EN-US> The web version is available at <i style='mso-bidi-font-style:normal'><a
href="http://www.sics.se/people/fredriko"><span style='color:black;text-decoration:
none;text-underline:none'>&lt;</span></a></i></span><span lang=EN-US
style='font-family:"Calibri",sans-serif;mso-fareast-font-family:Calibri;
color:#E72582'><a href="http://www.sics.se/people/fredriko"><span
style='color:#E72582;text-decoration:none;text-underline:none'>http://www.sics.se/people/fredriko</span></a></span><i
style='mso-bidi-font-style:normal'><span lang=EN-US><a
href="http://www.sics.se/people/fredriko"><span style='color:black;text-decoration:
none;text-underline:none'>&gt;</span></a></span></i><span lang=EN-US>.</span></p>

</div>

<div style='mso-element:footnote' id=ftn2>

<p class=footnotedescription style='line-height:121%'><a style='mso-footnote-id:
ftn2' href="#_ftnref2" name="_ftn2" title=""><span class=footnotemark><span
lang=EN-US><span style='mso-special-character:footnote'><![if !supportFootnotes]><span
class=footnotemark><span lang=EN-US style='font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[2]</span></span><![endif]></span></span></span></a><span
lang=EN-US> A learner is <i style='mso-bidi-font-style:normal'>weak </i>if it
produces a classifier that is only slightly better than random guessing, while
a learner is said to be <i style='mso-bidi-font-style:normal'>strong </i>if it
produces a classifier that achieves a low error with high confidence for a
given concept (</span><span lang=EN-US style='color:blue'>Schapire 1990</span><span
lang=EN-US>).</span></p>

</div>

<div style='mso-element:footnote' id=ftn3>

<p class=footnotedescription style='line-height:90%'><a style='mso-footnote-id:
ftn3' href="#_ftnref3" name="_ftn3" title=""><span class=footnotemark><span
lang=EN-US><span style='mso-special-character:footnote'><![if !supportFootnotes]><span
class=footnotemark><span lang=EN-US style='font-size:9.0pt;mso-bidi-font-size:
11.0pt;line-height:110%;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;
mso-bidi-language:AR-SA'>[3]</span></span><![endif]></span></span></span></a><span
lang=EN-US> The instance or set of instances for which the view classifiers
disagree is called the <i style='mso-bidi-font-style:normal'>contention point</i>,
and <i style='mso-bidi-font-style:normal'>contention set</i>, respectively.</span></p>

</div>

</div>

</body>

</html>
